{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05179c038e0c419fa61ee36054281925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56a199183774489ca36115376a0368c1",
              "IPY_MODEL_81176d69a3e64bf18fa35d63fb1b3b1f",
              "IPY_MODEL_a0a1c81ec89b4e2d84c1e3e8c6fd1f07"
            ],
            "layout": "IPY_MODEL_d17c2a785e334b97ba32609189324ae6"
          }
        },
        "56a199183774489ca36115376a0368c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a235dad335e48a7895427b1722a25d7",
            "placeholder": "​",
            "style": "IPY_MODEL_c7a7f4d9aac849ef923f31cc07b40491",
            "value": "100%"
          }
        },
        "81176d69a3e64bf18fa35d63fb1b3b1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b4c86d5557f42639c2ee8633fd51c34",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7c59e5538e044edbfe3f8ceb54fe389",
            "value": 1000
          }
        },
        "a0a1c81ec89b4e2d84c1e3e8c6fd1f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_669ce8df590b4de48f95981fe05aa6e5",
            "placeholder": "​",
            "style": "IPY_MODEL_8e96173d402e4635af98e86ee3d70685",
            "value": " 1000/1000 [03:11&lt;00:00,  7.88it/s]"
          }
        },
        "d17c2a785e334b97ba32609189324ae6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a235dad335e48a7895427b1722a25d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7a7f4d9aac849ef923f31cc07b40491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b4c86d5557f42639c2ee8633fd51c34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7c59e5538e044edbfe3f8ceb54fe389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "669ce8df590b4de48f95981fe05aa6e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e96173d402e4635af98e86ee3d70685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49361800d45a4c62bc56895f24f30bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_555beca236494b0583ca764bf6772889",
              "IPY_MODEL_42057d0a5c5d4e97a92f8172be92f8d4",
              "IPY_MODEL_f5cf2db3ec4640d68da85899c68fe7b1"
            ],
            "layout": "IPY_MODEL_c74017f69c0d48289400022658e40a69"
          }
        },
        "555beca236494b0583ca764bf6772889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a12c12bfebe14ae5b632fc50d752ae2e",
            "placeholder": "​",
            "style": "IPY_MODEL_fc85c294bd0b47b0b3693cac41dbeecd",
            "value": "100%"
          }
        },
        "42057d0a5c5d4e97a92f8172be92f8d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_359a027a8e254bd2b973c0c87c23e560",
            "max": 8000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6758a026097f4826bdc23c6ddaca7666",
            "value": 8000
          }
        },
        "f5cf2db3ec4640d68da85899c68fe7b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1d17b89492d4ce69f94f773dd69af32",
            "placeholder": "​",
            "style": "IPY_MODEL_c93cc14c9ed84da7b1310bfbf4b34f4b",
            "value": " 8000/8000 [00:22&lt;00:00, 366.07it/s]"
          }
        },
        "c74017f69c0d48289400022658e40a69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a12c12bfebe14ae5b632fc50d752ae2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc85c294bd0b47b0b3693cac41dbeecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "359a027a8e254bd2b973c0c87c23e560": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6758a026097f4826bdc23c6ddaca7666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1d17b89492d4ce69f94f773dd69af32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c93cc14c9ed84da7b1310bfbf4b34f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgozon/DLG-UROP/blob/main/Batch_DLG_Evolution_Iris_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch-DLG Evolution - Iris Dataset\n",
        "This notebook is based on the [Batch-DLG Iris Dataset](https://github.com/mgozon/DLG-UROP/blob/main/Batch_DLG_Iris_Dataset.ipynb), which implements the procedure in [Deep Leakage from Gradients](https://gist.github.com/Lyken17/91b81526a8245a028d4f85ccc9191884) on the Iris Dataset. In particular, a fully connected nueral network is trained using mini-batch gradients which are leaked."
      ],
      "metadata": {
        "id": "EFXvpWu88EO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Libaries and Utilities"
      ],
      "metadata": {
        "id": "2s36JoDvmtBQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWa7Xo6PkIl3",
        "outputId": "b2204964-7cc4-48e5-9112-5badab792d3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# setting up machine learning/visualization libraries\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad\n",
        "#torch.manual_seed(100) # for generating the same random weights\n",
        "from torch.utils.data import RandomSampler\n",
        "from torch.utils.data import random_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# setting up optimal device\n",
        "print(torch.__version__)\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "print(\"Running on %s\" % device)\n",
        "\n",
        "# utilities for testing\n",
        "from random import randint\n",
        "from random import shuffle\n",
        "from itertools import permutations\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import math\n",
        "from tqdm.notebook import trange"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116\n",
            "Running on cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Fully Connected Neural Network"
      ],
      "metadata": {
        "id": "oQsS24fvm1V3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjKWqs2akepH"
      },
      "source": [
        "# auxiliary functions for NN - convert to onehot and loss function\n",
        "def label_to_onehot(target, num_classes = 3):\n",
        "    target = torch.unsqueeze(target, 1)\n",
        "    onehot_target = torch.zeros(target.size(0), num_classes, device=target.device)\n",
        "    onehot_target.scatter_(1, target, 1)\n",
        "    return onehot_target\n",
        "\n",
        "# ***not equivalent to nn.CrossEntropyLoss(), which combines both nn.LogSoftmax() and nn.NLLLoss()\n",
        "def cross_entropy_for_onehot(pred, target):\n",
        "   return torch.mean(torch.sum(- target * torch.log(pred), 1))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AorI020iVjjS"
      },
      "source": [
        "# a fully connected neural network with random weights and biases\n",
        "class FcNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FcNet, self).__init__()\n",
        "        act = nn.Sigmoid\n",
        "        self.body = nn.Sequential(\n",
        "            nn.Linear(4, 100),\n",
        "            act(),\n",
        "            nn.Linear(100, 100),\n",
        "            act(),\n",
        "            nn.Linear(100, 100),\n",
        "            act(),\n",
        "            nn.Linear(100, 3),\n",
        "            nn.Softmax(dim=1),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.body(x)\n",
        "        return out\n",
        "\n",
        "def weights_init(m):\n",
        "    if hasattr(m, \"weight\"):\n",
        "        nn.init.xavier_normal_(m.weight.data)\n",
        "    if hasattr(m, \"bias\"):\n",
        "        nn.init.normal_(m.bias.data)\n",
        "\n",
        "# instantiation\n",
        "net = FcNet().to(device)\n",
        "net.apply(weights_init)\n",
        "criterion = cross_entropy_for_onehot"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess Iris Dataset"
      ],
      "metadata": {
        "id": "4LbUBX1Xn-TF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess Iris Dataset for training\n",
        "from sklearn.datasets import load_iris\n",
        "dst = load_iris()\n",
        "dst_length = dst.data.shape[0]\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(dst.data)\n",
        "\n",
        "train_indices, test_indices = random_split(range(dst_length), [int(dst_length*4/5), int(dst_length*1/5)])\n",
        "train_indices = train_indices.indices\n",
        "test_indices = test_indices.indices\n",
        "train_data = scaled_data[train_indices]; train_target = dst.target[train_indices]\n",
        "test_data = scaled_data[test_indices]; test_target = dst.target[test_indices]"
      ],
      "metadata": {
        "id": "LbQ-pcYsVpHt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model Normally"
      ],
      "metadata": {
        "id": "riUm6qIcovj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train NN without running batch dlg\n",
        "# Note: converges sometimes to near-optimal predictions\n",
        "def train_net_Adam(train_data, train_target, batch_size = 32, epochs = 100):\n",
        "    losses = []\n",
        "    train_dst_len = train_data.shape[0]\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-5) # regularizer may not be necessary\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        rand_subset = list(RandomSampler(range(train_dst_len), num_samples=batch_size))\n",
        "        gt_data = torch.tensor(train_data[rand_subset]).to(device)\n",
        "        gt_label = torch.tensor(train_target[rand_subset]).to(device)\n",
        "        gt_onehot_label = label_to_onehot(gt_label, num_classes=3)\n",
        "\n",
        "        output = net(gt_data.float())\n",
        "        loss = criterion(output, gt_onehot_label)\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "        #batch_accuracy = torch.sum(torch.eq(torch.argmax(output, dim=1), gt_label)) / batch_size\n",
        "        #accuracies.append(batch_accuracy)\n",
        "        losses.append(loss.detach().clone())\n",
        "    \n",
        "    return losses\n",
        "\n",
        "def test_net(test_data, test_target):\n",
        "    test_dst_len = test_data.shape[0]\n",
        "    pred = net(torch.tensor(test_data).float())\n",
        "    correct = torch.sum(torch.eq(torch.argmax(pred, dim=1), torch.tensor(test_target)))\n",
        "    print(f'score: {correct}/{test_dst_len}')"
      ],
      "metadata": {
        "id": "F96GffQPLCFz"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title train with LBFGS optimizer\n",
        "\n",
        "# NOTE: LBFGS isn't converging when using mini-batches\n",
        "def train_net_LBFGS(train_data, train_target, batch_size = 16, epochs = 100):\n",
        "    print(train_data); print(train_target)\n",
        "    train_dst_len = train_data.shape[0]\n",
        "    optimizer = torch.optim.LBFGS(net.parameters(), lr=0.001)\n",
        "    scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lambda epoch: 0.99)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        rand_subset = list(RandomSampler(range(train_dst_len), num_samples=batch_size))\n",
        "        # print('epoch, randset: ', epoch, rand_subset)\n",
        "        gt_data = torch.tensor(train_data[rand_subset]).to(device)\n",
        "        gt_label = torch.tensor(train_target[rand_subset]).to(device)\n",
        "        gt_onehot_label = label_to_onehot(gt_label, num_classes=3)\n",
        "        #print('lbfgs: ', gt_data, gt_onehot_label)\n",
        "        \n",
        "        def closure():\n",
        "            optimizer.zero_grad()\n",
        "            output = net(gt_data.float())\n",
        "            loss = criterion(output, gt_onehot_label)\n",
        "            loss.backward()\n",
        "            #print(f'output: {output}, onehot_label: {gt_onehot_label}')\n",
        "            print('loss: ', loss)\n",
        "            return loss\n",
        "      \n",
        "        optimizer.step(closure)\n",
        "        scheduler.step()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7xDEsDg5nSxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# note that parameters batch_size and epochs are tuned to yield a more accurate model\n",
        "net.apply(weights_init)\n",
        "batch_size = 32 # this affects the smoothness of the loss graph\n",
        "epochs = 200\n",
        "losses = train_net_Adam(train_data, train_target, batch_size, epochs)\n",
        "test_net(test_data, test_target)\n",
        "\n",
        "plt.plot(list(range(epochs)), losses)\n",
        "plt.title('loss over time')\n",
        "plt.xlabel('time (epochs)')\n",
        "plt.ylabel('loss (NLL)')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "hqLoSJemoSKp",
        "outputId": "4e61a7c0-6fb4-4f03-b92d-e5fe0d70d828"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score: 28/30\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch-DLG and Optimal Input Assignment"
      ],
      "metadata": {
        "id": "_VPUDx39pTRE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mSgR4GClV-8",
        "cellView": "form"
      },
      "source": [
        "#@title Batch-DLG with LBFGS\n",
        "# ***NOTE - this gives NaNs when ReLU is used since it requires a differentiable loss function\n",
        "# --> also possibly due to PyTorch implementation error - https://github.com/pytorch/pytorch/issues/5953)\n",
        "\n",
        "# DLG algorithm on a given set of flowers and returns the hypothesized input\n",
        "def batch_DLG(original_dy_dx, batch_size, gt_data_len, gt_onehot_label_len, verbose = False):\n",
        "    losses = []\n",
        "\n",
        "    # identify (data, label) using LBFGS on the squared difference between the original and guessed gradient\n",
        "    dummy_data = torch.randn(batch_size, gt_data_len).to(device).requires_grad_(True)\n",
        "    dummy_label = torch.randn(batch_size, gt_onehot_label_len).to(device).requires_grad_(True)\n",
        "    optimizer_dlg = torch.optim.LBFGS((dummy_data, dummy_label), max_iter=20)\n",
        "\n",
        "    global opt_steps; opt_steps = 0\n",
        "    for epoch in range(100):\n",
        "        # closure function needed for LBFGS optimizer\n",
        "        def closure():\n",
        "            global opt_steps; opt_steps += 1\n",
        "\n",
        "            # compute gradient of dummy data/label\n",
        "            optimizer_dlg.zero_grad()\n",
        "            pred = net(dummy_data)\n",
        "            dummy_onehot_label = F.softmax(dummy_label, dim=1)\n",
        "            dummy_loss = criterion(pred, dummy_onehot_label)\n",
        "            dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
        "            \n",
        "            # compute loss function, i.e. the SE of the gradients\n",
        "            grad_diff = 0\n",
        "            for gx, gy in zip(dummy_dy_dx, original_dy_dx):\n",
        "                grad_diff += ((gx - gy) ** 2).sum()\n",
        "            \n",
        "            grad_diff.backward()\n",
        "            return grad_diff\n",
        "        \n",
        "        # perform GD and log information\n",
        "        optimizer_dlg.step(closure)\n",
        "        current_loss = closure()\n",
        "        losses.append(current_loss.item())\n",
        "\n",
        "        if (verbose):\n",
        "            print(current_loss)\n",
        "        # if (current_loss < 1e-9):\n",
        "        #     break\n",
        "        # setting an upper limit on the number of optimization steps (e.g. limited attacking capability)\n",
        "        #if (opt_steps >= 80): \n",
        "        #    break\n",
        "    \n",
        "    return dummy_data, opt_steps, losses"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Batch-DLG with Adam\n",
        "# note: optimization should not be used on one optimizer since Adam requires gradient history to perform updates --> see code block below\n",
        "# this appears to take longer to converge but may give better results than LBFGS on batches (without using optimization)\n",
        "\n",
        "# DLG algorithm on a given set of flowers and returns the hypothesized input\n",
        "def batch_DLG_Adam(original_dy_dx, batch_size, gt_data_len, gt_onehot_label_len, verbose = False):\n",
        "    losses = []\n",
        "\n",
        "    # identify (data, label) using LBFGS on the squared difference between the original and guessed gradient\n",
        "    dummy_data = torch.randn(batch_size, gt_data_len).to(device).requires_grad_(True)\n",
        "    dummy_label = torch.randn(batch_size, gt_onehot_label_len).to(device).requires_grad_(True)\n",
        "    optimizer_dlg = torch.optim.Adam((dummy_data, dummy_label), lr=1, weight_decay=1e-12) # optimal learning rate seems to depend on the batch size of the dlg\n",
        "    #scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer_dlg, lambda epoch: 0.999)\n",
        "\n",
        "    opt_steps = 500 * batch_size\n",
        "    for epoch in trange(opt_steps):\n",
        "        optimizer_dlg.zero_grad()\n",
        "        pred = net(dummy_data)\n",
        "        dummy_onehot_label = F.softmax(dummy_label, dim=1)\n",
        "        dummy_loss = criterion(pred, dummy_onehot_label)\n",
        "        dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
        "        \n",
        "        # compute loss function, i.e. the SE of the gradients\n",
        "        grad_diff = 0\n",
        "        for gx, gy in zip(dummy_dy_dx, original_dy_dx):\n",
        "            grad_diff += ((gx - gy) ** 2).sum()\n",
        "\n",
        "        grad_diff.backward()\n",
        "\n",
        "        # Adam depends on past updates, and so this doesn't really work - loss fluctuates in dlg attack *significantly* when used\n",
        "        # only update a single dummy_data/dummy_label at a time\n",
        "        # mult = torch.zeros([batch_size, 1])\n",
        "        # mult[epoch%batch_size, 0] = 1\n",
        "        # dummy_data.grad *= mult; dummy_label.grad *= mult\n",
        "        \n",
        "        optimizer_dlg.step()\n",
        "        #scheduler.step()\n",
        "        losses.append(grad_diff.item())\n",
        "\n",
        "        if verbose:\n",
        "            print(grad_diff)\n",
        "        # if (grad_diff < 1e-9):\n",
        "        #     break\n",
        "    \n",
        "    return dummy_data, opt_steps, losses"
      ],
      "metadata": {
        "id": "bq4LG73_47oA"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Batch-DLG with Adam - individual optimizers\n",
        "# this doesn't seem to converge nearly as well as a single Adam optimizer\n",
        "\n",
        "# DLG algorithm on a given set of flowers and returns the hypothesized input\n",
        "def batch_DLG_Adam2(original_dy_dx, batch_size, gt_data_len, gt_onehot_label_len, verbose = False):\n",
        "    losses = []\n",
        "\n",
        "    dummy_data = [torch.randn(1, 4).to(device).requires_grad_(True) for i in range(batch_size)]\n",
        "    dummy_label = [torch.randn(1, 3).to(device).requires_grad_(True) for i in range(batch_size)]\n",
        "    optimizer_dlg = [torch.optim.Adam((dummy_data[i], dummy_label[i]), lr=1, weight_decay=1e-9) for i in range(batch_size)]\n",
        "    #scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer_dlg, lambda epoch: 0.999)\n",
        "\n",
        "    opt_steps = 500 * batch_size\n",
        "    for epoch in trange(opt_steps):\n",
        "        idx = epoch % batch_size\n",
        "        optimizer_dlg[idx].zero_grad()\n",
        "        pred = [net(dummy_data[i]) for i in range(batch_size)]\n",
        "        dummy_onehot_labels = [F.softmax(dummy_label[i], dim=1) for i in range(batch_size)]\n",
        "        dummy_loss = sum([criterion(pred[i], dummy_onehot_labels[i]) for i in range(batch_size)]) / batch_size\n",
        "        dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
        "        \n",
        "        # compute loss function, i.e. the SE of the gradients\n",
        "        grad_diff = 0\n",
        "        for gx, gy in zip(dummy_dy_dx, original_dy_dx):\n",
        "            grad_diff += ((gx - gy) ** 2).sum()\n",
        "\n",
        "        grad_diff.backward()\n",
        "        optimizer_dlg[idx].step()\n",
        "        #scheduler.step()\n",
        "        losses.append(grad_diff.item())\n",
        "\n",
        "        if verbose:\n",
        "            print(grad_diff)\n",
        "        # if (grad_diff < 1e-9):\n",
        "        #     break\n",
        "    \n",
        "    return dummy_data, opt_steps, losses"
      ],
      "metadata": {
        "id": "1EkoL-rgn2Nb",
        "cellView": "form"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Batch-DLG with SGD\n",
        "# this doesn't seem to converge nearly as well as LBFGS even with optimization\n",
        "\n",
        "# DLG algorithm on a given set of flowers and returns the hypothesized input\n",
        "def batch_DLG_SGD(original_dy_dx, batch_size, gt_data_len, gt_onehot_label_len, verbose = False):\n",
        "    losses = []\n",
        "\n",
        "    # identify (data, label) using LBFGS on the squared difference between the original and guessed gradient\n",
        "    dummy_data = torch.randn(batch_size, gt_data_len).to(device).requires_grad_(True)\n",
        "    dummy_label = torch.randn(batch_size, gt_onehot_label_len).to(device).requires_grad_(True)\n",
        "    optimizer_dlg = torch.optim.SGD((dummy_data, dummy_label), lr=1, weight_decay=1e-9)#, momentum=0.001)#, weight_decay=1e-9)\n",
        "    # scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer_dlg, lambda epoch: 0.99)\n",
        "\n",
        "    opt_steps = 1000 * batch_size\n",
        "    for epoch in trange(opt_steps):\n",
        "        optimizer_dlg.zero_grad()\n",
        "        pred = net(dummy_data)\n",
        "        dummy_onehot_label = F.softmax(dummy_label, dim=1)\n",
        "        dummy_loss = criterion(pred, dummy_onehot_label)\n",
        "        dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
        "        \n",
        "        # compute loss function, i.e. the SE of the gradients\n",
        "        grad_diff = 0\n",
        "        for gx, gy in zip(dummy_dy_dx, original_dy_dx):\n",
        "            grad_diff += ((gx - gy) ** 2).sum()\n",
        "\n",
        "        grad_diff.backward()\n",
        "\n",
        "        # only update a single dummy_data/dummy_label at a time\n",
        "        mult = torch.zeros([batch_size, 1])\n",
        "        mult[epoch%batch_size, 0] = 1\n",
        "        dummy_data.grad *= mult; dummy_label.grad *= mult\n",
        "        \n",
        "        optimizer_dlg.step()\n",
        "        # scheduler.step()\n",
        "        losses.append(grad_diff.item())\n",
        "\n",
        "        if verbose:\n",
        "            print(grad_diff)\n",
        "        # if (grad_diff < 1e-9):\n",
        "        #     break\n",
        "    \n",
        "    return dummy_data, opt_steps, losses"
      ],
      "metadata": {
        "id": "KDeXpMMeNuVn",
        "cellView": "form"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find best linear sum assignment\n",
        "def assign_guess(guess, gt_dataset, n, verbose = False):\n",
        "    cost_matrix = [[math.sqrt(torch.sum((guess[i]-gt_dataset[j])**2).item()) / math.sqrt(torch.sum(gt_dataset[j]**2).item()) for j in range(n)] for i in range(n)]\n",
        "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
        "    best_MSE = sum([cost_matrix[row_ind[i]][col_ind[i]] for i in range(n)]) / n\n",
        "    if (verbose):\n",
        "        print('best guessed-actual assignment: ', col_ind)\n",
        "        print('best_MSE: ', best_MSE)\n",
        "\n",
        "    guess_perm = torch.zeros(gt_dataset.shape)\n",
        "    for i in range(n):\n",
        "        guess_perm[col_ind[i]] = guess[i]\n",
        "\n",
        "    return guess_perm"
      ],
      "metadata": {
        "id": "N9F7n7IR7MdX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: this returns an array with the best corresponding gt_data since matching is not one to one\n",
        "# --> this is NOT the same format as assign_guess()\n",
        "def assign_best(guess, gt_dataset, n, verbose = False):\n",
        "    cost_matrix = torch.tensor([[math.sqrt(torch.sum((guess[i]-gt_dataset[j])**2).item()) / math.sqrt(torch.sum(gt_dataset[j]**2).item()) for j in range(n)] for i in range(n)])\n",
        "    match_idx = torch.argmin(cost_matrix, dim=1)\n",
        "    best_match = gt_dataset[match_idx]\n",
        "\n",
        "    if (verbose):\n",
        "        # print('relative error matrix:')\n",
        "        # print(cost_matrix)\n",
        "        print('assignment and relative error (%):')\n",
        "        for i in range(n):\n",
        "            RE = math.sqrt(torch.sum((best_match[i]-guess[i])**2).item()) / math.sqrt(torch.sum(best_match[i]**2).item())\n",
        "            print(guess[i], best_match[i], 100*RE)\n",
        "    \n",
        "    return best_match"
      ],
      "metadata": {
        "id": "t-uJ8u4t5wBN"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Single Batch DLG"
      ],
      "metadata": {
        "id": "66aTSs05PevQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# process specific batch gradient of flowers\n",
        "def batch_grad(flower_indices):\n",
        "    n = len(flower_indices)\n",
        "    # flower_indices = torch.tensor(flower_indices)\n",
        "\n",
        "    gt_data = torch.tensor(dst.data[flower_indices]).to(device)\n",
        "    gt_label = torch.tensor(dst.target[flower_indices]).to(device)\n",
        "    gt_onehot_label = label_to_onehot(gt_label, num_classes=3)\n",
        "\n",
        "    out = net(gt_data.float())\n",
        "    loss = criterion(out, gt_onehot_label)\n",
        "    batch_dy_dx = torch.autograd.grad(loss, net.parameters())\n",
        "    original_dy_dx = list((_.detach().clone() for _ in batch_dy_dx)) # share the gradients with other clients\n",
        "    \n",
        "    return original_dy_dx, gt_data, gt_label"
      ],
      "metadata": {
        "id": "vOPYnGgVzuD-"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing batch-DLG with Adam\n",
        "net.apply(weights_init) # see how much easier it is to attack\n",
        "batch_size = 16\n",
        "flower_indices = list(RandomSampler(range(dst.data.shape[0]), num_samples=batch_size))\n",
        "print(flower_indices)\n",
        "batch_dy_dx, gt_data, gt_label = batch_grad(flower_indices)\n",
        "\n",
        "dummy_data, _, losses = batch_DLG_Adam(batch_dy_dx, batch_size, 4, 3, verbose = False)\n",
        "guess_perm = assign_guess(dummy_data, gt_data, batch_size)\n",
        "print('gt data vs guess perm (LSA): ')\n",
        "for i in range(batch_size):\n",
        "    print(gt_data[i], guess_perm[i], 'RE (AE / TN): ', math.sqrt(torch.sum((gt_data[i]-guess_perm[i])**2).item()) / math.sqrt(torch.sum(gt_data[i]**2).item()))\n",
        "\n",
        "print('guess closest match: ')\n",
        "best_match = assign_best(dummy_data, gt_data, batch_size, verbose = True)\n",
        "\n",
        "plt.plot(torch.log(torch.tensor(losses)))\n",
        "plt.title('DLG loss over time (SGD)')\n",
        "plt.xlabel('time (epochs)')\n",
        "plt.ylabel('loss (log SE)')\n",
        "plt.savefig('dlg8-SGD.png', dpi=300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990,
          "referenced_widgets": [
            "49361800d45a4c62bc56895f24f30bff",
            "555beca236494b0583ca764bf6772889",
            "42057d0a5c5d4e97a92f8172be92f8d4",
            "f5cf2db3ec4640d68da85899c68fe7b1",
            "c74017f69c0d48289400022658e40a69",
            "a12c12bfebe14ae5b632fc50d752ae2e",
            "fc85c294bd0b47b0b3693cac41dbeecd",
            "359a027a8e254bd2b973c0c87c23e560",
            "6758a026097f4826bdc23c6ddaca7666",
            "c1d17b89492d4ce69f94f773dd69af32",
            "c93cc14c9ed84da7b1310bfbf4b34f4b"
          ]
        },
        "id": "4n-ruYei6etv",
        "outputId": "cae2d664-2734-43c8-eda6-5d4eb2846c30"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[38, 97, 28, 123, 78, 98, 110, 148, 87, 25, 135, 57, 31, 11, 94, 7]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/8000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49361800d45a4c62bc56895f24f30bff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gt data vs guess perm (LSA): \n",
            "tensor([4.4000, 3.0000, 1.3000, 0.2000], dtype=torch.float64) tensor([ 4.6675,  3.0594,  1.3155, -0.0413], grad_fn=<SelectBackward0>) RE (AE / TN):  0.0666266597713489\n",
            "tensor([6.2000, 2.9000, 4.3000, 1.3000], dtype=torch.float64) tensor([4.9030, 7.8762, 3.6815, 2.2874], grad_fn=<SelectBackward0>) RE (AE / TN):  0.6440278123409627\n",
            "tensor([5.2000, 3.4000, 1.4000, 0.2000], dtype=torch.float64) tensor([5.6560, 3.2716, 1.0321, 0.4488], grad_fn=<SelectBackward0>) RE (AE / TN):  0.10191075488115184\n",
            "tensor([6.3000, 2.7000, 4.9000, 1.8000], dtype=torch.float64) tensor([6.3218, 2.6611, 5.5272, 2.3248], grad_fn=<SelectBackward0>) RE (AE / TN):  0.09506216395216463\n",
            "tensor([6.0000, 2.9000, 4.5000, 1.5000], dtype=torch.float64) tensor([4.0889, 7.9389, 3.9586, 1.5303], grad_fn=<SelectBackward0>) RE (AE / TN):  0.6621572443941087\n",
            "tensor([5.1000, 2.5000, 3.0000, 1.1000], dtype=torch.float64) tensor([4.3498, 7.3089, 2.3993, 1.4453], grad_fn=<SelectBackward0>) RE (AE / TN):  0.7543625508077644\n",
            "tensor([6.5000, 3.2000, 5.1000, 2.0000], dtype=torch.float64) tensor([7.2154, 2.7679, 6.1769, 2.0986], grad_fn=<SelectBackward0>) RE (AE / TN):  0.15047817727874438\n",
            "tensor([6.2000, 3.4000, 5.4000, 2.3000], dtype=torch.float64) tensor([5.2460, 7.7776, 3.7553, 2.5846], grad_fn=<SelectBackward0>) RE (AE / TN):  0.5202733125910588\n",
            "tensor([6.3000, 2.3000, 4.4000, 1.3000], dtype=torch.float64) tensor([7.5607, 2.8157, 5.3301, 2.1359], grad_fn=<SelectBackward0>) RE (AE / TN):  0.22755680259524597\n",
            "tensor([5.0000, 3.0000, 1.6000, 0.2000], dtype=torch.float64) tensor([4.8831, 3.0917, 1.2185, 0.1074], grad_fn=<SelectBackward0>) RE (AE / TN):  0.06938035367495203\n",
            "tensor([7.7000, 3.0000, 6.1000, 2.3000], dtype=torch.float64) tensor([7.3094, 0.8474, 7.4934, 2.4624], grad_fn=<SelectBackward0>) RE (AE / TN):  0.24691107621728337\n",
            "tensor([4.9000, 2.4000, 3.3000, 1.0000], dtype=torch.float64) tensor([3.5207, 8.6493, 3.3538, 0.8936], grad_fn=<SelectBackward0>) RE (AE / TN):  0.9916912987228597\n",
            "tensor([5.4000, 3.4000, 1.5000, 0.4000], dtype=torch.float64) tensor([4.2043, 9.5509, 0.7443, 1.8045], grad_fn=<SelectBackward0>) RE (AE / TN):  0.984549800011201\n",
            "tensor([4.8000, 3.4000, 1.6000, 0.2000], dtype=torch.float64) tensor([ 4.7616,  3.1162,  1.3835, -0.1236], grad_fn=<SelectBackward0>) RE (AE / TN):  0.0792405781332828\n",
            "tensor([5.6000, 2.7000, 4.2000, 1.3000], dtype=torch.float64) tensor([5.7191, 4.6020, 4.6153, 2.0431], grad_fn=<SelectBackward0>) RE (AE / TN):  0.2741115760453536\n",
            "tensor([5.0000, 3.4000, 1.5000, 0.2000], dtype=torch.float64) tensor([4.9648, 3.1362, 1.2651, 0.0553], grad_fn=<SelectBackward0>) RE (AE / TN):  0.061501263316309326\n",
            "guess closest match: \n",
            "assignment and relative error (%):\n",
            "tensor([5.2460, 7.7776, 3.7553, 2.5846], grad_fn=<SelectBackward0>) tensor([6.2000, 3.4000, 5.4000, 2.3000], dtype=torch.float64) 52.02733125910588\n",
            "tensor([7.5607, 2.8157, 5.3301, 2.1359], grad_fn=<SelectBackward0>) tensor([7.7000, 3.0000, 6.1000, 2.3000], dtype=torch.float64) 7.794333686608315\n",
            "tensor([4.0889, 7.9389, 3.9586, 1.5303], grad_fn=<SelectBackward0>) tensor([6.2000, 3.4000, 5.4000, 2.3000], dtype=torch.float64) 57.30113395410697\n",
            "tensor([5.6560, 3.2716, 1.0321, 0.4488], grad_fn=<SelectBackward0>) tensor([5.4000, 3.4000, 1.5000, 0.4000], dtype=torch.float64) 8.386312498196249\n",
            "tensor([ 4.6675,  3.0594,  1.3155, -0.0413], grad_fn=<SelectBackward0>) tensor([4.4000, 3.0000, 1.3000, 0.2000], dtype=torch.float64) 6.662665977134891\n",
            "tensor([3.5207, 8.6493, 3.3538, 0.8936], grad_fn=<SelectBackward0>) tensor([6.2000, 3.4000, 5.4000, 2.3000], dtype=torch.float64) 69.59145020823243\n",
            "tensor([6.3218, 2.6611, 5.5272, 2.3248], grad_fn=<SelectBackward0>) tensor([6.2000, 3.4000, 5.4000, 2.3000], dtype=torch.float64) 8.269884224144333\n",
            "tensor([7.2154, 2.7679, 6.1769, 2.0986], grad_fn=<SelectBackward0>) tensor([7.7000, 3.0000, 6.1000, 2.3000], dtype=torch.float64) 5.500110735439762\n",
            "tensor([4.9648, 3.1362, 1.2651, 0.0553], grad_fn=<SelectBackward0>) tensor([5.0000, 3.4000, 1.5000, 0.2000], dtype=torch.float64) 6.150126331630933\n",
            "tensor([4.9030, 7.8762, 3.6815, 2.2874], grad_fn=<SelectBackward0>) tensor([6.2000, 3.4000, 5.4000, 2.3000], dtype=torch.float64) 54.05065489268094\n",
            "tensor([5.7191, 4.6020, 4.6153, 2.0431], grad_fn=<SelectBackward0>) tensor([6.2000, 3.4000, 5.4000, 2.3000], dtype=torch.float64) 16.70897144923733\n",
            "tensor([4.2043, 9.5509, 0.7443, 1.8045], grad_fn=<SelectBackward0>) tensor([6.2000, 3.4000, 5.4000, 2.3000], dtype=torch.float64) 86.87589828737464\n",
            "tensor([7.3094, 0.8474, 7.4934, 2.4624], grad_fn=<SelectBackward0>) tensor([7.7000, 3.0000, 6.1000, 2.3000], dtype=torch.float64) 24.691107621728335\n",
            "tensor([ 4.7616,  3.1162,  1.3835, -0.1236], grad_fn=<SelectBackward0>) tensor([5.0000, 3.0000, 1.6000, 0.2000], dtype=torch.float64) 7.786237823626512\n",
            "tensor([4.3498, 7.3089, 2.3993, 1.4453], grad_fn=<SelectBackward0>) tensor([6.2000, 3.4000, 5.4000, 2.3000], dtype=torch.float64) 58.029031168814846\n",
            "tensor([4.8831, 3.0917, 1.2185, 0.1074], grad_fn=<SelectBackward0>) tensor([5.0000, 3.0000, 1.6000, 0.2000], dtype=torch.float64) 6.938035367495203\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Leakage Statistics"
      ],
      "metadata": {
        "id": "I6UOgCYEdv8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_stats(n_elts, guess_perm, gt_data):\n",
        "    MSE = 0\n",
        "    SEs = []\n",
        "    n_errors = []\n",
        "    cos_angles = []\n",
        "    for i in range(n_elts):\n",
        "        SE = torch.sum((guess_perm[i]-gt_data[i])**2).item()\n",
        "        SEs.append(SE); MSE += SE\n",
        "\n",
        "        n_error = (torch.sum((guess_perm[i]-gt_data[i])**2) / (torch.linalg.norm(gt_data[i])**2)).item()\n",
        "        n_errors.append(n_error)\n",
        "\n",
        "        cos_angle = (torch.sum(guess_perm[i]*gt_data[i]).item() / (torch.linalg.norm(gt_data[i]) * torch.linalg.norm(guess_perm[i]))).item()\n",
        "        cos_angles.append(cos_angle)\n",
        "\n",
        "    MSE /= n_elts\n",
        "\n",
        "    return SEs, MSE, n_errors, cos_angles"
      ],
      "metadata": {
        "id": "RVEDyDB7d4dP"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Model with Batch-DLG"
      ],
      "metadata": {
        "id": "cdlEvF28zuF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_net_Adam_DLG(train_data, train_target, batch_size = 32, epochs = 100, verbose = False, dlg_rate = 10):\n",
        "    train_dst_len = train_data.shape[0]\n",
        "    optimizer = torch.optim.Adam(net.parameters()) #lr=0.001)\n",
        "\n",
        "    # statistics\n",
        "    losses = []\n",
        "    dlg_timestamps = []\n",
        "    dlg_SEs = []\n",
        "    dlg_MSE = []\n",
        "    dlg_n_errors = []\n",
        "    dlg_cos_angles = []\n",
        "\n",
        "    for epoch in trange(epochs):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        rand_subset = list(RandomSampler(range(train_dst_len), num_samples=batch_size))\n",
        "        # print('epoch, randset: ', epoch, rand_subset)\n",
        "        gt_data = torch.tensor(train_data[rand_subset]).to(device)\n",
        "        gt_label = torch.tensor(train_target[rand_subset]).to(device)\n",
        "        gt_onehot_label = label_to_onehot(gt_label, num_classes=3)\n",
        "\n",
        "        output = net(gt_data.float())\n",
        "        #print('adam: ', output.tolist(), gt_onehot_label.tolist())\n",
        "        loss = criterion(output, gt_onehot_label)\n",
        "\n",
        "        # Perform DLG ---------------------------------------------------------------\n",
        "\n",
        "        if (epoch%dlg_rate == 0):\n",
        "            batch_dy_dx = torch.autograd.grad(loss, net.parameters(), retain_graph = True)\n",
        "            original_dy_dx = list((_.detach().clone() for _ in batch_dy_dx)) # share the gradients with other clients\n",
        "            guess, steps, _ = batch_DLG(original_dy_dx, batch_size, 4, 3, verbose=False)\n",
        "            guess_perm = assign_guess(guess, gt_data, batch_size, verbose)\n",
        "            SEs, MSE, n_errors, cos_angles = compute_stats(batch_size, guess_perm, gt_data)\n",
        "            dlg_SEs.append(SEs)\n",
        "            dlg_MSE.append(MSE)\n",
        "            dlg_n_errors.append(n_errors)\n",
        "            dlg_cos_angles.append(cos_angles)\n",
        "            dlg_timestamps.append(epoch)\n",
        "\n",
        "            if (verbose):\n",
        "                print('dlg results at epoch', epoch, '-', scaler.inverse_transform(gt_data.detach().clone()), scaler.inverse_transform(guess_perm.detach().clone()))\n",
        "\n",
        "        # end of DLG ----------------------------------------------------------------\n",
        "\n",
        "        # issue: running batch_DLG seems to ruin the stored gradients of the parameters\n",
        "        # consider creating a separate ml model and running dlg on that\n",
        "        # inefficient - REMOVE -----------------------------------------------------------------------------\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(output, gt_onehot_label)\n",
        "        # end of REMOVE ------------------------------------------------------------------------------------\n",
        "\n",
        "        loss.backward()\n",
        "        if (verbose):\n",
        "            print('current loss: ', loss)\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "        #batch_accuracy = torch.sum(torch.eq(torch.argmax(output, dim=1), gt_label)) / batch_size\n",
        "        #accuracies.append(batch_accuracy)\n",
        "        losses.append(loss.detach().clone())\n",
        "    \n",
        "    return losses, dlg_timestamps, dlg_SEs, dlg_MSE, dlg_n_errors, dlg_cos_angles"
      ],
      "metadata": {
        "id": "G4aoyTSM-chb"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "NYHduOtfboIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# results of training a model + dlg\n",
        "net.apply(weights_init)\n",
        "epochs = 1000\n",
        "batch_size = 16\n",
        "dlg_rate = 10\n",
        "verbose = True\n",
        "losses, dlg_timestamps, dlg_SEs, dlg_MSE, dlg_n_errors, dlg_cos_angles = train_net_Adam_DLG(train_data, train_target, batch_size, epochs, verbose, dlg_rate)\n",
        "test_net(test_data, test_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "05179c038e0c419fa61ee36054281925",
            "56a199183774489ca36115376a0368c1",
            "81176d69a3e64bf18fa35d63fb1b3b1f",
            "a0a1c81ec89b4e2d84c1e3e8c6fd1f07",
            "d17c2a785e334b97ba32609189324ae6",
            "2a235dad335e48a7895427b1722a25d7",
            "c7a7f4d9aac849ef923f31cc07b40491",
            "5b4c86d5557f42639c2ee8633fd51c34",
            "d7c59e5538e044edbfe3f8ceb54fe389",
            "669ce8df590b4de48f95981fe05aa6e5",
            "8e96173d402e4635af98e86ee3d70685"
          ]
        },
        "id": "w1PLqwS2-mVW",
        "outputId": "2cd89ee8-ecff-4534-abd4-09288cf8a666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05179c038e0c419fa61ee36054281925"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best guessed-actual assignment:  [ 5  4 10  8  7  3  2  0 14 13  6 15  9 11  1 12]\n",
            "best_MSE:  2.6080824419169564\n",
            "dlg results at epoch 0 - [[5.8 2.7 5.1 1.9]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [5.1 3.5 1.4 0.2]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [5.8 2.8 5.1 2.4]] [[ 5.82094184  2.7182916   6.89461558  1.88189802]\n",
            " [ 6.15809736  2.26846363  5.79693167  2.70756936]\n",
            " [ 5.98616123  3.78274707  3.05185323  1.44837919]\n",
            " [ 7.50921764  2.35428823  5.26457077  1.76299473]\n",
            " [ 5.64310152  2.66420377  4.79605968  2.00694996]\n",
            " [ 6.42686947  2.8284191   3.48540161  2.43292089]\n",
            " [ 7.00347744  2.72353953  5.35420505  2.33489351]\n",
            " [ 6.94581984  2.0945628   3.4993789   0.56932496]\n",
            " [ 5.4654514   2.97496497  4.07163826  0.29894293]\n",
            " [ 4.54999046  4.00525532 -0.33785042  0.77413078]\n",
            " [ 7.10265054  2.92819422  5.85969053  1.89366091]\n",
            " [ 4.93457787  3.3999777  -0.168519   -0.75748724]\n",
            " [ 5.52386721  3.82430633 -1.35364344 -0.09965243]\n",
            " [ 6.81959508  3.14188103  5.29094755  2.40819627]\n",
            " [ 6.54330201  3.42364794  6.68997153  2.81065882]\n",
            " [ 6.310387    2.84535542  7.09163421  2.58062304]]\n",
            "current loss:  tensor(1.8190, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.6596, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.5033, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.3614, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.3074, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.2497, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1360, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1174, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0965, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1278, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 1 10  4  3  7  5 12 15 11 13  6 14  9  2  8  0]\n",
            "best_MSE:  3.6774235842908345\n",
            "dlg results at epoch 10 - [[5.5 4.2 1.4 0.2]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [6.  2.2 4.  1. ]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [6.  2.9 4.5 1.5]] [[ 5.45118162  3.7789377   0.47656815 -0.23452532]\n",
            " [ 4.42576564  4.05359759 -0.3475256  -0.70467106]\n",
            " [ 7.38814681  3.54969688  6.21779643  2.93539026]\n",
            " [ 5.77266663  3.67958298  2.21947743 -0.4932837 ]\n",
            " [ 5.97250484  3.21166054  3.53547925  1.53097653]\n",
            " [ 3.888256    3.83156665  0.37281886 -0.64965511]\n",
            " [ 7.40528592  2.91382815  0.55540736  1.06248878]\n",
            " [ 7.70016915  2.53885093  7.22262711  1.8739024 ]\n",
            " [ 5.10487838  3.24517764  2.78950515  1.70465619]\n",
            " [ 5.09483981  4.02283143  5.45591915  0.69742536]\n",
            " [ 5.36803901  2.6441914   7.50290873  0.37397933]\n",
            " [ 7.31181325  2.09524451  5.74203985  2.45222056]\n",
            " [ 7.24978004  3.75397978  8.40006719  3.18381312]\n",
            " [ 6.64424165  2.63122563  5.81738693  3.59907785]\n",
            " [ 4.19778816  3.8970737   0.18982306  0.67174639]\n",
            " [ 6.16395039  3.26995936  4.32003857  0.80306792]]\n",
            "current loss:  tensor(1.1447, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1587, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0709, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0893, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1205, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1518, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1060, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0898, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1993, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0610, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 5  6  9 14 10  7  2  8  1  4 13 11 15  3  0 12]\n",
            "best_MSE:  3.871276868605876\n",
            "dlg results at epoch 20 - [[5.1 3.8 1.9 0.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [7.2 3.6 6.1 2.5]] [[ 4.24539942  3.46765222  4.55023811 -0.55722131]\n",
            " [ 5.18692197  3.04793736  3.93246645  0.95982707]\n",
            " [ 5.77821139  2.67160746  4.51041141  0.92776718]\n",
            " [ 6.32707172  2.47999406  2.5844452   0.34636386]\n",
            " [ 5.22973442  2.67030021  0.83556271 -0.02414266]\n",
            " [ 5.98127543  2.7942475   4.45669795  3.20790544]\n",
            " [ 6.12925191  2.41224956  6.91972176  1.71499674]\n",
            " [ 5.52271332  3.12687178  6.40592094  1.61336556]\n",
            " [ 3.64246351  3.6974871  -3.32301091 -0.67737011]\n",
            " [ 6.87963484  1.86245501  6.8027993   1.09524376]\n",
            " [ 6.16131438  3.14589783  3.38889566  0.78157537]\n",
            " [ 4.45689617  3.27194041  1.31088555  1.42817048]\n",
            " [ 4.31888221  2.02803428 -0.22744512  0.4593436 ]\n",
            " [ 6.32751725  3.0531173   3.05894728  0.14815451]\n",
            " [ 6.35400728  2.47201962  4.50437155  2.6328569 ]\n",
            " [ 8.74158277  2.69601174  6.66827945  3.19542069]]\n",
            "current loss:  tensor(1.1474, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0704, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1264, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1125, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1291, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0955, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0724, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0861, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0655, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1206, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 3  7  9 11 15  5  6  1 10 13  2  8 12  0 14  4]\n",
            "best_MSE:  2.2862282695690044\n",
            "dlg results at epoch 30 - [[6.9 3.1 4.9 1.5]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [6.7 3.  5.  1.7]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [6.  3.  4.8 1.8]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [7.3 2.9 6.3 1.8]] [[ 6.43158775  3.13644237  5.32053099  1.79838476]\n",
            " [ 4.56313972  3.71437865 -0.05934948  0.53814418]\n",
            " [ 6.28250957  2.8665717   8.97958564  3.11940332]\n",
            " [ 6.44773294  3.15360405  5.05099852  0.98333719]\n",
            " [ 6.35095862  2.61729532  8.55274127  0.7807618 ]\n",
            " [ 4.98782179  3.58730054 -0.36131751 -0.81538452]\n",
            " [ 4.7383352   4.40309576  1.99835558 -0.35013839]\n",
            " [ 4.8459143   3.16350591  2.78843591  0.97282597]\n",
            " [ 5.19847683  2.91398523  3.96594767  0.13005969]\n",
            " [ 6.75032104  3.06393481  7.87521762  1.99648575]\n",
            " [ 6.04653321  2.92391984  3.64045809  1.27015599]\n",
            " [ 6.50161895  2.56379963  3.22655009  1.76668424]\n",
            " [ 5.79928791  2.29144276  7.221371    2.47338889]\n",
            " [ 4.41226525  3.68827492  2.98421531  0.55837333]\n",
            " [ 7.36295766  3.58936265  4.09270897  2.01253676]\n",
            " [ 6.90664261  2.70698109  7.25969357  1.83273096]]\n",
            "current loss:  tensor(1.0646, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1906, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1548, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0591, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1202, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0603, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0903, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0266, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1153, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0270, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 1  3  4 13  9  8  5 10  0  2  6 11 14 15 12  7]\n",
            "best_MSE:  2.5863188978229785\n",
            "dlg results at epoch 40 - [[6.2 2.2 4.5 1.5]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.1 2.8 4.7 1.2]] [[ 7.21840532  2.27604238  4.79785933  0.55392622]\n",
            " [ 5.79011051  1.96172347  4.69550637  1.2174225 ]\n",
            " [ 7.00138137  3.03543668  6.76936339  2.2783351 ]\n",
            " [ 5.63083565  2.07618867  0.50902793  2.90682742]\n",
            " [ 4.32398419  4.31450482 -1.42194523 -0.24515092]\n",
            " [ 5.37346816  3.5178312   4.24112596  0.64985695]\n",
            " [ 6.10239223  2.47379489  6.74030471  1.6709657 ]\n",
            " [ 4.06070864  3.11696944  0.63712479 -0.95787833]\n",
            " [ 5.199385    3.12562415  2.00038436 -0.35496609]\n",
            " [ 5.72256375  2.88333632  5.70886906  2.20100249]\n",
            " [ 5.29053296  3.41658021  1.43259401  1.13001263]\n",
            " [ 4.55913157  2.86755416  6.1131652   1.18242994]\n",
            " [ 5.8089987   4.04442591 -1.96086315  0.12823857]\n",
            " [ 5.82872919  3.00475712  4.06777912  1.05101282]\n",
            " [ 7.22190177  2.93390212  5.81176241  1.5577061 ]\n",
            " [ 5.67498844  2.94276414  4.66528186  1.1884308 ]]\n",
            "current loss:  tensor(1.0441, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1479, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0251, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0950, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1126, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0926, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1036, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1247, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0629, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1032, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [14  0  6  4  1 15  7  2  3  8 13  5  9 12 11 10]\n",
            "best_MSE:  0.6763125611155884\n",
            "dlg results at epoch 50 - [[7.7 2.6 6.9 2.3]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [7.7 2.8 6.7 2. ]] [[ 7.85433524  2.81087039  5.60465772  2.33070527]\n",
            " [ 6.26047371  2.57140153  4.67168692  1.67153914]\n",
            " [ 4.87367962  3.117666    0.74951022  0.13833175]\n",
            " [ 6.74085477  3.15575898  6.85462937  2.13126346]\n",
            " [ 5.29192298  4.01770121  1.79607338  0.0693749 ]\n",
            " [ 7.60142962  2.98705798  6.0371499   2.46524878]\n",
            " [ 4.22821899  2.02277698  1.03716787  0.30503244]\n",
            " [ 4.81890397  3.05235695  1.84824323 -0.39822776]\n",
            " [ 4.80159623  3.78333996  1.35644804  0.5820886 ]\n",
            " [ 6.04571287  4.49592526  1.21206718  0.21212174]\n",
            " [ 5.09390713  3.81774512  1.87089318  0.38456336]\n",
            " [ 7.23308277  3.39526563  6.26489651  2.19924576]\n",
            " [ 5.64426697  3.54320159  5.19056654  2.16356571]\n",
            " [ 5.05550128  3.43986923  0.87835247  0.530164  ]\n",
            " [ 4.75579877  3.72535735  1.48778533  0.43830283]\n",
            " [ 6.9931264   2.63672147  6.40932833  1.84095933]]\n",
            "current loss:  tensor(1.0073, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1108, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0663, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0608, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0940, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.9918, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.9315, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1371, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0712, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0428, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [11  4 14  1 13  7  3 10  2 12  5  0  9  8  6 15]\n",
            "best_MSE:  1.91937957365345\n",
            "dlg results at epoch 60 - [[5.4 3.9 1.3 0.4]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [5.  2.  3.5 1. ]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 4.  1.2 0.2]] [[ 5.74772603  3.57521901 -1.46453701  0.37580126]\n",
            " [ 4.57398011  3.26088145  1.25240093  0.42809282]\n",
            " [ 5.16625227  3.62331266  1.96922222 -0.72163394]\n",
            " [ 6.80604028  2.50759213  7.44912453  2.59236074]\n",
            " [ 5.10439861  2.5995594   4.64984215  1.71907142]\n",
            " [ 5.83745972  2.55162743  4.95181029  0.78166091]\n",
            " [ 8.8768295   3.21031856  6.89142401  2.60519941]\n",
            " [ 6.20716632  2.82940259  6.4019913   1.73914978]\n",
            " [ 4.22208123  3.23998346  0.34279161  0.78450597]\n",
            " [ 6.38803644  2.40541233  2.86257291  1.79356974]\n",
            " [ 4.39183029  3.50707353  2.14647122  0.08363033]\n",
            " [ 4.84365728  2.70449524  4.93993255  0.34592635]\n",
            " [ 5.76947362  2.68283253  3.51285812  1.34858719]\n",
            " [ 6.56827535  3.09019233  5.19941126  2.79461044]\n",
            " [ 5.20878969  3.2514279   2.77644712  1.80993097]\n",
            " [ 5.85990584  4.18700823  1.29596211  0.2729239 ]]\n",
            "current loss:  tensor(1.1172, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0834, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.1389, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0889, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.9970, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0434, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0399, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0074, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0449, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0919, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [15 12  8  1  2  6 13  7  5 14  4 11 10  9  0  3]\n",
            "best_MSE:  1.1265585786914987\n",
            "dlg results at epoch 70 - [[6.3 2.5 4.9 1.5]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.  1.7]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [5.8 2.8 5.1 2.4]] [[ 6.74683452  2.44329288  3.2778467   1.14542964]\n",
            " [ 5.67105868  4.33445147  1.16042084  0.0155772 ]\n",
            " [ 5.40401641  3.48736943  0.05012375 -0.04310045]\n",
            " [ 5.88097965  3.1055655   7.11531019  1.0061341 ]\n",
            " [ 6.62212182  2.74867885  4.03061978  1.48931483]\n",
            " [ 6.01140541  2.78151497  5.15329559  1.18454903]\n",
            " [ 4.88568497  4.34384511  2.00801167  0.47578919]\n",
            " [ 6.90512917  3.27854888  6.05793088  1.99161929]\n",
            " [ 7.28285621  2.95862638  4.14731964  2.20127844]\n",
            " [ 7.11270987  3.08491504  7.59394311  1.75203826]\n",
            " [ 6.32429155  2.57702262  3.74692402  1.42456642]\n",
            " [ 6.55452876  2.9567001   4.67764682  1.59977902]\n",
            " [ 5.01334524  4.35818689  1.79126662  0.5663368 ]\n",
            " [ 6.61840258  3.49513544  6.7749682   3.39923286]\n",
            " [ 5.77264081  3.32245821  1.9852881  -0.97377982]\n",
            " [ 6.28186289  3.08405441  5.19247703  2.31181186]]\n",
            "current loss:  tensor(1.0312, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0283, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0435, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0236, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0228, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0583, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.9581, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0498, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0828, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0161, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 7 12 10  6  4 14  8  0  5 13  9 15  3 11  1  2]\n",
            "best_MSE:  1.1526958629828563\n",
            "dlg results at epoch 80 - [[7.2 3.  5.8 1.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [6.9 3.1 4.9 1.5]] [[ 7.532836    3.27100701  7.70947229  1.39547405]\n",
            " [ 5.20818694  3.79001107  2.13694391  0.28682278]\n",
            " [ 7.18368389  3.19999909  5.72368197  2.96467163]\n",
            " [ 4.71392928  3.22158008  1.51436555 -0.2962945 ]\n",
            " [ 5.18241     3.34860562  1.33943876  0.01016664]\n",
            " [ 7.31451142  3.1182793   4.01880575  2.11038157]\n",
            " [ 6.87698311  3.05087213  4.08410565  1.72037714]\n",
            " [ 4.9348018   2.99576502  0.56965376  0.31539079]\n",
            " [ 5.0341      3.41430005  0.38663007  0.38455457]\n",
            " [ 5.90811256  2.96861414  5.9695891   1.26156063]\n",
            " [ 4.76710039  3.63458943  1.66983858  0.34076919]\n",
            " [ 5.76219248  2.46944736  5.11188443  0.67069301]\n",
            " [ 5.36975541  2.69996149  5.41391926  2.24232314]\n",
            " [ 7.31586223  3.36875737  7.46062526  1.89347303]\n",
            " [ 5.75011478  3.10181137  0.56376476  0.59007806]\n",
            " [ 7.14625621  2.62379581  3.84114001  1.58361105]]\n",
            "current loss:  tensor(1.0107, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.9906, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.9837, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.9925, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0280, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.9881, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.9994, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.8969, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0035, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.9630, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [14  4  8 12 11  0  2 15  6 10  7  9  1 13  5  3]\n",
            "best_MSE:  1.0166973205452647\n",
            "dlg results at epoch 90 - [[6.7 3.  5.  1.7]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [5.8 2.7 5.1 1.9]] [[ 6.93816107  2.94346753  4.71025982  1.57773871]\n",
            " [ 5.02544382  3.84424315  1.03432614  0.23498304]\n",
            " [ 6.37150431  2.72997016  5.30846198  1.44760982]\n",
            " [ 6.18462811  2.68247171  5.30172049  1.65231242]\n",
            " [ 6.95416808  2.8840709   5.11122575  1.37441493]\n",
            " [ 5.13801303  3.66203892  0.88386919 -0.03495391]\n",
            " [ 5.16258369  3.66916517  0.91620565  0.01811992]\n",
            " [ 4.47792124  2.9418745  -0.07144083  0.3744201 ]\n",
            " [ 6.56809477  2.4613899   4.54578193  1.31043113]\n",
            " [ 6.56981176  3.40153345  6.97319555  2.30644432]\n",
            " [ 4.26840238  3.55441048  0.96148479  0.45837082]\n",
            " [ 7.71786678  3.939597    6.23024392  2.44238693]\n",
            " [ 8.24828061  3.72562881  6.15360675  1.94639527]\n",
            " [ 6.23180474  2.94183745  5.22018942  2.45413858]\n",
            " [ 5.98121064  2.85842334  6.50146509  2.21181692]\n",
            " [ 6.26429744  2.75810019  4.58150586  2.13256266]]\n",
            "current loss:  tensor(0.9486, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.9433, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.9071, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.9149, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.8692, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.8642, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.9617, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.8484, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.8898, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(1.0559, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 3  1 10 15  5  4  0  6  2  8  9  7 11 13 14 12]\n",
            "best_MSE:  0.28866768224680917\n",
            "dlg results at epoch 100 - [[5.1 3.7 1.5 0.4]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [5.8 2.7 5.1 1.9]] [[ 5.01243933  3.56875231  1.40460834  0.44560569]\n",
            " [ 5.26809856  3.3511778   1.61716641  0.40083634]\n",
            " [ 5.88771703  2.52736282  4.45664536  1.00793695]\n",
            " [ 6.70780211  3.11099501  5.5227423   2.15197943]\n",
            " [ 4.94902344  3.45370733  1.36579771  0.26812889]\n",
            " [ 6.23409093  3.23252889  4.81403018  2.3636526 ]\n",
            " [ 6.02531188  2.81373722  5.39373655  2.25813171]\n",
            " [ 5.89279801  2.29222152  5.24099326  2.03882839]\n",
            " [ 6.34340605  3.00476732  3.97482361  1.39383005]\n",
            " [ 5.06416105  3.37520753  1.62757231  0.21754697]\n",
            " [ 4.38998383  2.89073811  0.95048931 -0.10730061]\n",
            " [ 5.74015493  2.76429158  4.01654882  1.41225353]\n",
            " [ 6.04381302  2.90171959  4.75790018  1.18839455]\n",
            " [ 5.11772855  3.59515986  1.79028652  0.17714273]\n",
            " [ 7.63132367  3.74593817  6.61523563  1.98480591]\n",
            " [ 5.82993968  2.81426606  5.59588882  2.25301059]]\n",
            "current loss:  tensor(0.8535, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.7742, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.7488, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.7315, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.9694, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.9048, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.7286, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.8044, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.7506, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.8242, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 2 11 12  7  8  0 10  9  5  1 13 15 14  4  6  3]\n",
            "best_MSE:  0.3343690919052051\n",
            "dlg results at epoch 110 - [[5.4 3.9 1.3 0.4]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [4.4 3.2 1.3 0.2]] [[ 5.60166548  3.78012624  1.15187887  0.36532654]\n",
            " [ 6.40097722  2.76073757  5.57854627  1.95164902]\n",
            " [ 4.70441047  3.54398926  1.53353554  0.27761612]\n",
            " [ 6.49699817  3.07553046  4.78238491  1.60991015]\n",
            " [ 4.76730188  2.98541026  1.07072039 -0.08548638]\n",
            " [ 5.48972599  3.64333596  1.46146099  0.28610571]\n",
            " [ 5.31444303  3.39306574  1.83596311  0.43717804]\n",
            " [ 5.85248841  2.94881621  5.26111273  2.26770144]\n",
            " [ 6.39930785  2.96245299  4.26877149  1.01713207]\n",
            " [ 5.94991521  2.64450763  4.39454597  1.37420087]\n",
            " [ 6.98975568  3.18831984  5.43378904  2.25197537]\n",
            " [ 5.38724235  4.01812927  1.19931033  0.30292496]\n",
            " [ 6.387978    2.96269812  5.0146241   2.49675318]\n",
            " [ 5.20593386  3.33334949  1.66921859  0.29202107]\n",
            " [ 5.43753584  3.51980626  1.47332122  0.40664039]\n",
            " [ 4.20027972  2.96402652  1.51714625  0.17556024]]\n",
            "current loss:  tensor(0.6682, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.7216, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.7038, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.7244, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.7597, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.7988, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.6208, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.6919, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.7776, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [11 13  4  3  8  5 15  6 12  2  0  9  1 14  7 10]\n",
            "best_MSE:  2.0089300712021845\n",
            "dlg results at epoch 120 - [[5.5 3.5 1.3 0.2]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [5.9 3.  5.1 1.8]\n",
            " [6.1 2.6 5.6 1.4]] [[ 6.17076675  3.32462718 -0.93735347  0.73980042]\n",
            " [ 6.69402762  2.9941308   5.74865329  2.01222613]\n",
            " [ 6.69201371  2.96910468  5.89222225  1.88735115]\n",
            " [ 6.5434121   2.95199322  5.54917528  2.16772932]\n",
            " [ 3.64949853  2.32821629  1.50347305 -0.16517687]\n",
            " [ 5.60414905  3.95364225  3.53505666  0.0297705 ]\n",
            " [ 6.02183914  2.51907061  4.6592774   1.61716234]\n",
            " [ 6.82285492  3.12435585  5.91442526  2.04620587]\n",
            " [ 6.68092087  3.03425182  5.99429364  1.96845369]\n",
            " [ 6.83073279  3.16131784  6.13648149  1.98645795]\n",
            " [ 6.35885533  2.61027559  5.13753981  1.27367285]\n",
            " [ 6.56469036  3.08929182  6.13645653  2.0780421 ]\n",
            " [ 6.67765276  3.23044483  6.19401411  2.19439778]\n",
            " [ 6.03318214  2.51763262  4.86598452  1.50226073]\n",
            " [ 6.55506032  3.04517641  5.53103867  2.14185835]\n",
            " [ 6.34129642  2.81099713  5.81580426  1.97379289]]\n",
            "current loss:  tensor(0.6613, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.6860, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.7469, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.6601, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.6220, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.5120, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.5814, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.6772, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.6723, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.6875, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [15  2 10 11  4  8  0  7 13  5  6  9 12  3  1 14]\n",
            "best_MSE:  1.6112709613553973\n",
            "dlg results at epoch 130 - [[5.7 4.4 1.5 0.4]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.3 2.9 6.3 1.8]] [[ 6.30190314  3.83303276  2.19493229  0.48376018]\n",
            " [ 6.30217763  3.26670677  5.3367957   2.00623343]\n",
            " [ 6.41421636  2.85757095  4.48168469  1.31199886]\n",
            " [ 6.15843939  2.94121062  5.31038715  2.00419768]\n",
            " [ 6.09690931  3.00652314  5.35342043  2.07287623]\n",
            " [ 6.48429513  2.93519273  4.43097404  1.43312248]\n",
            " [ 6.06518442  2.89383933  5.228779    2.02570462]\n",
            " [ 6.40062698  2.9350733   4.66637249  1.30152203]\n",
            " [ 6.39051369  2.83302589  4.55207436  1.25009459]\n",
            " [ 6.3382115   2.96942566  4.92602204  1.34349484]\n",
            " [ 6.11201688  2.9657334   5.35433824  2.0286479 ]\n",
            " [ 4.22391795  2.39313935 -0.43496928  1.0056925 ]\n",
            " [ 6.59991955  2.99439449  4.36891224  1.47168092]\n",
            " [ 4.28539815  2.37232839  2.79191692 -0.66918254]\n",
            " [ 5.98059052  2.98790645  5.46959445  2.11789726]\n",
            " [ 6.35949305  2.98071923  5.13871213  1.93608913]]\n",
            "current loss:  tensor(0.6850, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.7232, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.6243, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.5245, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.6228, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.5390, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.5806, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.5029, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.6093, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.5253, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 2  9  3 14 12  6  5 13 11 15  7  1 10  8  0  4]\n",
            "best_MSE:  2.872260989000832\n",
            "dlg results at epoch 140 - [[6.3 2.8 5.1 1.5]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [6.7 3.1 5.6 2.4]] [[ 6.23721566  3.17161166  4.40094212  1.57687809]\n",
            " [ 6.19124247  3.19235078  4.50587112  1.60257504]\n",
            " [ 5.67491668  2.84002775  4.37931138  1.06060432]\n",
            " [ 5.64822762  2.70186967  3.64898211  1.21762412]\n",
            " [ 6.32328435  3.85213919  2.54885173  0.20970137]\n",
            " [ 5.72944694  2.69847475  3.81866904  1.05710348]\n",
            " [ 6.63823331  2.60469355  6.94697272  2.21217038]\n",
            " [ 6.98174086  3.05446573  7.50588658  3.11045303]\n",
            " [ 6.1268373   3.29677529  4.83021435  1.62823034]\n",
            " [ 4.96200249  3.26373706  1.29575636  0.91294488]\n",
            " [ 7.42005103  2.98253818  8.3548386   2.45462517]\n",
            " [ 7.11559418  2.12209753  8.92821007  3.03250234]\n",
            " [ 7.54706049  2.30145177  9.50555647  3.41356671]\n",
            " [ 4.51162115  2.87814974  2.91887081 -0.18749562]\n",
            " [ 5.14979934  3.26223025  1.27256759  0.77848516]\n",
            " [ 6.81597919  2.73452555  5.06452008  3.0863685 ]]\n",
            "current loss:  tensor(0.5404, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.5565, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4599, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.6226, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.5402, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.5797, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4860, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4867, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4951, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.6168, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 9 12  4  2  7 13  8  1 10  5  3  0 11 15  6 14]\n",
            "best_MSE:  2.399780450766223\n",
            "dlg results at epoch 150 - [[6.2 3.4 5.4 2.3]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [5.1 3.5 1.4 0.2]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [6.3 2.3 4.4 1.3]] [[ 6.87803355  3.27499818  6.16989516  1.38535572]\n",
            " [ 6.47287088  2.96227757  4.98092802  1.05486086]\n",
            " [ 4.66510111  3.54349413  0.5685625   0.56812568]\n",
            " [ 6.89613829  3.00445552  4.14405749  2.02505511]\n",
            " [ 5.9995866   2.8931852   3.294891    1.92434676]\n",
            " [ 5.18618626  2.5187616   2.80377872  0.84345255]\n",
            " [ 5.15278483  3.62740022  1.85738232 -0.05586025]\n",
            " [ 5.22242595  2.73595192  4.8699323   2.05378296]\n",
            " [ 5.20715327  2.03345263  3.90873592  1.35714101]\n",
            " [ 6.31055607  1.97413135  3.85185516  0.78133923]\n",
            " [ 6.74841367  3.93339876  6.97525748  2.54320935]\n",
            " [ 5.35660452  3.09143392  2.28237324  0.65744808]\n",
            " [ 4.41090136  4.37976604 -0.52341047 -1.31890867]\n",
            " [ 3.63864997  3.37093916 -2.00431024 -1.18668102]\n",
            " [ 7.56862499  3.08216703  5.41841508  1.74758898]\n",
            " [ 5.61121279  2.33512778  4.59140215  1.00156806]]\n",
            "current loss:  tensor(0.5684, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3787, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3729, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3976, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.6308, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.5670, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.6279, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.5198, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.6244, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4150, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 1  4 11 12  2  6 14 15  3  8  9 13  5  0  7 10]\n",
            "best_MSE:  1.280297824834459\n",
            "dlg results at epoch 160 - [[5.  2.3 3.3 1. ]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [6.  2.2 4.  1. ]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.7 2.5 5.  2. ]] [[ 5.44786462  2.11732319  3.64529161  0.83446536]\n",
            " [ 5.70483586  3.12700854  0.95978802 -0.05753891]\n",
            " [ 4.98528133  3.40788537  2.19319954  0.40578847]\n",
            " [ 6.48730296  2.82879657  2.54082057  1.84211001]\n",
            " [ 5.19189388  2.84381174  3.81367024  0.87340365]\n",
            " [ 5.51668344  2.6830224   2.85047705  2.03613108]\n",
            " [ 7.42954475  2.31777021  5.44792491  1.81872521]\n",
            " [ 6.54255676  2.46414206  6.33976455  1.73569125]\n",
            " [ 5.66017293  2.99604873  4.83245571  1.87920683]\n",
            " [ 5.27551683  3.48350178  1.97918852  0.4145282 ]\n",
            " [ 6.55799437  2.56193332  5.13967326  0.72554798]\n",
            " [ 7.15120274  3.26915525  6.4156108   2.38908352]\n",
            " [ 4.81811306  3.37142478  3.41280351 -0.13760189]\n",
            " [ 5.81763518  2.2964807   4.3930927   0.85884889]\n",
            " [ 4.72883547  3.5034074   1.51025764  1.09689445]\n",
            " [ 6.09986697  2.74092732  6.03533777  2.22018398]]\n",
            "current loss:  tensor(0.4443, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3875, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.6409, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4044, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4444, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4594, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4548, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4597, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4668, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4204, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [13 12 10  1  5 15  4  3  7  2 14 11  6  8  0  9]\n",
            "best_MSE:  1.3878435361811994\n",
            "dlg results at epoch 170 - [[5.6 2.7 4.2 1.3]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]] [[ 5.13009822  2.9596497   2.86823949  1.76376474]\n",
            " [ 6.04248261  2.69796316  6.34352975  1.72499347]\n",
            " [ 6.07665356  2.56998643  4.41952725  1.01295999]\n",
            " [ 6.78536704  2.53509957  4.65324399  1.69799383]\n",
            " [ 5.05401593  3.37178669  1.08353639  1.10928976]\n",
            " [ 4.55868442  2.97604178  2.12027419  0.32363523]\n",
            " [ 5.54848788  3.07266899  2.3327447  -0.38572254]\n",
            " [ 6.12712631  2.33918282  5.245888    1.52064062]\n",
            " [ 6.69674645  3.09668488  6.46799857  2.04981596]\n",
            " [ 5.09285349  2.41848695  3.0128714   0.74597954]\n",
            " [ 5.61166993  3.03729703  3.66109398  1.0925499 ]\n",
            " [ 5.87233502  3.82082788  2.33551952  0.61103402]\n",
            " [ 5.55986933  2.53999571  5.80631679  1.10296815]\n",
            " [ 4.41863381  3.21960899  2.38482037  0.71673467]\n",
            " [ 5.1536054   2.65019182  3.12143636  1.49656831]\n",
            " [ 6.45637687  2.72808632  4.48062489  0.9467718 ]]\n",
            "current loss:  tensor(0.3899, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.5078, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4948, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3386, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3930, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.5375, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4388, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4381, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3140, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4269, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [13  6  7  8  4 14  1  9  2 12  3 10  5  0 11 15]\n",
            "best_MSE:  25668914332.174046\n",
            "dlg results at epoch 180 - [[6.1 2.6 5.6 1.4]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [6.  2.2 4.  1. ]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [5.6 2.8 4.9 2. ]] [[ 132378.61264728  -45027.95303761  287977.87472735   66369.50230271]\n",
            " [ 127009.67957024  -39169.89398701  282194.79603521   57181.76185557]\n",
            " [  98626.92982678  -45670.0769308   146518.66764586   53028.02371054]\n",
            " [   8267.30914176     881.62021357  -34275.68046027  -35253.84457952]\n",
            " [   8348.10243082  -27109.41525723   70565.43466987   25887.50603045]\n",
            " [ -15773.67880194   46112.15015427  -48928.36520801  -13144.63169921]\n",
            " [   1485.57349032  -54254.05801627 -114871.56153285  -32891.17083126]\n",
            " [ -30142.5514804   -17863.76687578  -11171.36839432  -19651.68987703]\n",
            " [  30887.17661851   10979.95644776  -51838.96591023  -59083.247876  ]\n",
            " [ -34426.23592558   62614.16031167  -37033.93807569  -10196.95753309]\n",
            " [ -74105.78067533    3571.85373294  -39334.59943521  -13684.70193647]\n",
            " [-209060.24072631   66861.39634322   34922.45118595  -68032.10653736]\n",
            " [  38332.66446068   -4658.44979654  -39420.88927016  -43254.80269952]\n",
            " [ -27897.07430478   52168.44993493  -20482.34776324   51566.93892883]\n",
            " [ -65772.7457705    13889.61904972   37707.39882359  -31031.59759072]\n",
            " [  38465.75074164  -12249.17226421  162515.62300825   64655.83752752]]\n",
            "current loss:  tensor(0.3243, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3839, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4840, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4105, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3938, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4387, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3756, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2689, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4982, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4400, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [11 14  5 12 10  7  2  6  3  1  4  0 13  9 15  8]\n",
            "best_MSE:  2.4253926339376157\n",
            "dlg results at epoch 190 - [[5.6 3.  4.5 1.5]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.9 3.1 5.1 2.3]] [[ 5.00052203  3.20980289  4.46302992  2.22251333]\n",
            " [ 6.49869007  3.43985504  5.8909028   2.54435043]\n",
            " [ 5.36644406  3.40463094  5.3005468   2.30994474]\n",
            " [ 5.49566954  2.09151365  3.65403525  1.12201705]\n",
            " [ 4.40429775  2.93925583  1.97673942  0.39082919]\n",
            " [ 7.08753548  2.92866524  4.1078601   0.73807376]\n",
            " [ 6.22363927  3.81792735  3.00437243 -0.59982731]\n",
            " [ 6.14590817  3.50066778  4.68499245  2.20052025]\n",
            " [ 6.51820372  2.81623346  6.20025442  1.54619645]\n",
            " [ 5.98261205  2.43198291  5.2199736   2.27692821]\n",
            " [ 6.36287612  2.76156868  5.91573192  1.96607615]\n",
            " [ 6.7405605   3.21291928  5.67861403  2.20785789]\n",
            " [ 4.31858637  5.08487755 -0.39521022  1.78328506]\n",
            " [ 5.62753062  2.78532763  5.0718807   1.21110575]\n",
            " [ 6.76101238  3.02237466  4.59359443  2.12172144]\n",
            " [ 6.76855151  3.14609801  5.09123967  2.15308782]]\n",
            "current loss:  tensor(0.4960, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3780, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3840, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4246, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3714, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3072, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4731, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3568, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3461, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3732, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [15  0  5  4 13  1  9  6 10  3 12  2  8 14  7 11]\n",
            "best_MSE:  2.731699454476112\n",
            "dlg results at epoch 200 - [[4.9 2.5 4.5 1.7]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [5.8 2.7 5.1 1.9]] [[4.20810987 3.02063222 6.06354387 1.76844854]\n",
            " [7.03562024 3.29513627 6.26700332 2.0364782 ]\n",
            " [6.27527636 3.08142355 5.42370497 2.32620323]\n",
            " [5.92043753 2.76892509 5.43122793 1.03834413]\n",
            " [6.29144418 3.49631725 5.74086302 2.32624081]\n",
            " [6.56481432 2.9942003  5.94326225 2.04942944]\n",
            " [6.7084419  2.97799545 5.68933811 1.82699139]\n",
            " [6.35735198 2.698187   5.68854027 1.52908747]\n",
            " [5.71913382 3.24336648 3.98950251 2.06111218]\n",
            " [6.92384567 2.87986178 4.17423418 1.34384091]\n",
            " [5.008229   2.73378186 3.82975741 1.06542733]\n",
            " [5.00366135 3.35998532 2.10071221 1.14320869]\n",
            " [5.74688025 3.67416551 6.78574996 2.5444889 ]\n",
            " [4.28693263 2.74645729 3.16631522 0.2483506 ]\n",
            " [5.73896929 3.35281873 2.09044168 0.56184477]\n",
            " [5.83622468 2.77827499 4.8481966  2.38102048]]\n",
            "current loss:  tensor(0.3872, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4549, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4000, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4003, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2577, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4036, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3673, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.5186, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3913, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4969, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 8 12  5  4 10  6  9  2  3 14  7  0 11  1 13 15]\n",
            "best_MSE:  2.2522359296717007\n",
            "dlg results at epoch 210 - [[5.7 4.4 1.5 0.4]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [5.  2.  3.5 1. ]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [5.9 3.  5.1 1.8]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [6.4 2.9 4.3 1.3]] [[5.85801666 3.43416758 2.67774516 0.81126309]\n",
            " [5.33390448 2.43719339 4.27348171 1.8581099 ]\n",
            " [7.19046852 3.53859462 6.37540038 3.07856003]\n",
            " [7.4266564  3.07110762 6.26768077 1.92873519]\n",
            " [7.21212727 3.07780313 5.67728283 2.1620276 ]\n",
            " [4.29960887 2.43337015 2.47194808 0.49644295]\n",
            " [6.58478122 3.04081476 4.0183873  1.67158723]\n",
            " [5.22206931 2.46235441 3.53054167 1.03044784]\n",
            " [5.27858221 2.55674625 3.21462595 1.28811232]\n",
            " [5.67768936 2.30344247 3.42339619 1.01540159]\n",
            " [7.16099083 2.81300539 4.83323362 2.32248727]\n",
            " [5.64147865 2.97227302 3.7229037  1.45438409]\n",
            " [6.69334927 3.56397543 7.09477859 2.40699333]\n",
            " [6.33212707 2.60966012 4.63820142 2.68595501]\n",
            " [6.10671393 2.90890997 4.54373757 0.64340474]\n",
            " [6.56818656 2.84543556 4.3376089  1.33340976]]\n",
            "current loss:  tensor(0.3574, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3490, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3139, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3550, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4039, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3079, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4203, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2828, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4264, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4902, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [11  9  8  3 15 12  7  0 13  6 10  1  4  5  2 14]\n",
            "best_MSE:  2229247390921.789\n",
            "dlg results at epoch 220 - [[6.3 2.7 4.9 1.8]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.6 2.9 4.6 1.3]] [[  391673.22967293  -183583.86402905   898245.12636112   367394.70294902]\n",
            " [ -262004.44048827   -80119.64046676  1358098.2028336    253733.67027176]\n",
            " [   13788.72308013   533994.64851792 -1094138.621009    -813158.21587427]\n",
            " [   30196.25758862   146860.15126408   206801.92638149   404657.27024171]\n",
            " [   91329.62870015   159166.5931444    499541.84261735   174911.29872607]\n",
            " [  383751.54943307  -180042.1114091    749424.55892309   153292.97488801]\n",
            " [ -702250.76304625   247243.95986648  2085229.22361013     3171.06059461]\n",
            " [  914752.56698352  -409019.33155726  2115444.34933372   194266.33204286]\n",
            " [ -288854.17373924   167315.42340595  1418750.46908133   777592.99272228]\n",
            " [ -152245.33921988   197778.95408006   213741.42837724  -512887.37813726]\n",
            " [ -280794.7713463     84004.67175338 -1238077.00710864  -348902.07419066]\n",
            " [  871589.51574848  -653959.86511213 -2947574.69685619  -243580.30619185]\n",
            " [  731004.49566329  -365445.00637004  2246549.20232658   863138.32352958]\n",
            " [ -661680.65372601   287535.44137052 -1544223.76101518  -622008.29774703]\n",
            " [  705685.28365794  -341248.8313302   1219617.81803426   466616.32906894]\n",
            " [ 1378634.30637696  -551023.03682769  -521029.18601444   156427.85838724]]\n",
            "current loss:  tensor(0.3203, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4200, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3305, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3154, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4127, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2955, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4267, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2624, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3098, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3341, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 1 15  7 13 12 11  2  3  9 10  8  5  4  0 14  6]\n",
            "best_MSE:  8.268621063566908\n",
            "dlg results at epoch 230 - [[5.7 2.6 3.5 1. ]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [6.  3.  4.8 1.8]\n",
            " [5.7 2.5 5.  2. ]] [[ 6.23443751  1.41105239  3.30477304 -1.14241374]\n",
            " [ 4.11664581  2.98737927 -3.98516837 -0.85171943]\n",
            " [ 6.10890471  3.03241456  1.66309196  0.1425794 ]\n",
            " [ 5.70471437  3.29068035  7.13836284  2.22772049]\n",
            " [ 5.66512427  2.76127914  3.32034682  0.62596627]\n",
            " [ 4.96170921  3.43927162 -1.57891222  0.20358904]\n",
            " [ 6.37072821  3.01930297  4.8603536   2.48760303]\n",
            " [ 2.7194565   4.80638728 -1.14799811  0.07049036]\n",
            " [ 5.34389848  2.6647772   4.90837883  0.47719721]\n",
            " [ 3.05298511  4.20881638 -4.48462254 -1.45789046]\n",
            " [ 5.75108051  1.96701411  1.89175344  0.67557446]\n",
            " [ 3.97238282  3.06011404 -0.38466211 -0.08597089]\n",
            " [ 5.90893793  3.01218137  2.53925478  1.56686262]\n",
            " [ 3.19823351  4.04749049 -3.35170885 -1.79976359]\n",
            " [ 6.25456743  3.04094781  4.21345212  0.62690201]\n",
            " [ 4.83446392  1.3237532   4.94080265  1.79998735]]\n",
            "current loss:  tensor(0.3103, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3741, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3288, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2454, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4426, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3692, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3560, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2708, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3303, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3424, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 4 14  9  5  1 12  8  2  6  0  3 15 11 13 10  7]\n",
            "best_MSE:  3136452427.295413\n",
            "dlg results at epoch 240 - [[6.1 2.8 4.7 1.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [4.4 3.  1.3 0.2]] [[-23858.27545111 -20594.0873217    4697.35622189 -14775.43211075]\n",
            " [ -8425.10019085  10495.46094989 -43773.03295206 -14778.97091332]\n",
            " [  2876.73406966  -3089.11366125    863.25947763   8498.36582774]\n",
            " [-20175.98257674  -9989.47586125   4055.49847164  22573.42706506]\n",
            " [-10468.97334721  -3262.18570586 -16257.68012221 -14466.07547976]\n",
            " [ -9872.04194959 -16408.44431709 -35052.07592201  -6428.4777701 ]\n",
            " [-31531.90429529  22098.60759417 -99700.28212772 -25226.37669911]\n",
            " [  8169.03945308 -26835.93149311  34166.78026703  -7248.88423159]\n",
            " [ 50967.87894158 -14408.74881753  29827.94551471  -7632.83466626]\n",
            " [-25819.60558295 -16202.89496188  -3470.54571362   3778.55355259]\n",
            " [ 21585.01232881   1549.44445777  86975.7056616   45752.7590058 ]\n",
            " [  -210.54050022  -5741.80711565    764.62975987  -6901.25066559]\n",
            " [-14630.88152414  -5886.72305096 -18808.02050579   9244.9953035 ]\n",
            " [ 13461.88200771 -19594.53313871   3548.67433912 -31754.09792289]\n",
            " [-16179.11773303 -18447.48794758   6418.42194526  -9264.70191178]\n",
            " [-32834.68429421  15736.50115832 -83492.73434586 -14023.33047403]]\n",
            "current loss:  tensor(0.3949, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3077, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3006, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2476, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2990, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4372, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3614, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3503, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2740, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.4110, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 0  2  6  1 15 13  5  4  3 10 12 11 14  8  7  9]\n",
            "best_MSE:  1.765626629863885\n",
            "dlg results at epoch 250 - [[5.7 2.8 4.5 1.3]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.9 3.  5.1 1.8]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.  2.2 4.  1. ]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.4 3.4 1.5 0.4]] [[ 5.67540054  2.74373887  5.23950192  1.01512445]\n",
            " [ 5.73436931  3.11400608  4.93183113  2.62332014]\n",
            " [ 5.65438309  3.50864233  0.21651591  0.61809617]\n",
            " [ 7.92965358  3.13259665  3.9990783   0.74657703]\n",
            " [ 7.37115645  3.64782864  3.49251006  0.19363858]\n",
            " [ 5.523463    3.60464288  2.01369629  0.58330395]\n",
            " [ 5.67631888  2.54726229  1.55033634  2.18388257]\n",
            " [ 5.31340651  2.53103091  5.22542509  2.27115749]\n",
            " [ 7.01071798  3.08267381  6.59603187  1.55592872]\n",
            " [ 5.80888956  2.99262609  6.03274898  1.81998032]\n",
            " [ 5.63077757  2.72113019  4.48710131  1.41421155]\n",
            " [ 5.55403946  2.58160577  5.18916392  0.67361836]\n",
            " [ 4.37460519  2.40000252  3.9197561   1.42090432]\n",
            " [ 5.69169807  4.03638232  2.1661041  -0.24503735]\n",
            " [ 5.67998647  4.08060359  2.16899607  0.67722111]\n",
            " [ 5.73673156  3.69223912  2.43156977  0.30315716]]\n",
            "current loss:  tensor(0.3353, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3362, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2442, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2158, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1943, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2885, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1995, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2421, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1647, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2965, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [12  1  3  4 14 13  5  0  2 10 11  9 15  8  6  7]\n",
            "best_MSE:  6.936860116248546\n",
            "dlg results at epoch 260 - [[5.4 3.4 1.5 0.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.  3.2 1.2 0.2]] [[ 5.56953564  2.90764648  1.68243561 -0.6522193 ]\n",
            " [ 6.42240113  2.78091268  3.95400273  0.96376787]\n",
            " [ 5.92647966  1.54966222  4.20395238 -0.14434326]\n",
            " [ 6.26657123  2.51407954  3.75340809  0.85910937]\n",
            " [ 5.82477226  2.38901197  4.18883399  0.79260021]\n",
            " [ 6.30713995  2.9109043   4.19032084  1.06250553]\n",
            " [ 7.14963854  3.50030548  4.89459636  0.82075052]\n",
            " [ 4.00251653  2.98482284 -0.22767751  0.77258293]\n",
            " [ 6.43843048  2.77169967  4.10356607  0.88229278]\n",
            " [ 7.68363835  1.39273461  2.62023876 -1.56302818]\n",
            " [ 4.61489401  3.02974422  1.55136972  0.84204911]\n",
            " [ 5.20767441  0.61273137  6.66376926  0.50703929]\n",
            " [ 5.46165898  2.21181963  2.3129047   0.33538163]\n",
            " [ 4.98736234  3.21393898  2.98031367  0.21462162]\n",
            " [ 6.58107678  2.66905421  3.99071681  0.74519274]\n",
            " [ 5.67888337  1.99067588 -1.00496691  0.15375625]]\n",
            "current loss:  tensor(0.2863, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1989, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2295, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2374, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1673, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2357, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2879, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2684, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2108, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3625, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 9  7 12 15  0 14 10 13  5  8  4  6 11  1  3  2]\n",
            "best_MSE:  20.892170538979066\n",
            "dlg results at epoch 270 - [[4.6 3.1 1.5 0.2]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [6.2 3.4 5.4 2.3]] [[ 4.3129914   1.58945217  1.45532366 -1.17418123]\n",
            " [ 5.99062864  1.45767652  3.16842124 -0.13260293]\n",
            " [ 6.41167944  1.20457621  1.27212504  0.16657065]\n",
            " [ 3.45288603  1.02413058  5.71141401 -1.52781298]\n",
            " [ 6.8568069   4.28281904  6.35919797  2.2900249 ]\n",
            " [ 4.0042343   1.15059964  6.15360465 -1.00173716]\n",
            " [ 5.84804387  2.78228267  1.73410209  0.72951534]\n",
            " [ 5.41925071  1.43594408  4.6784068  -0.48756813]\n",
            " [ 6.05793579  1.31702933  2.88080538 -0.19952657]\n",
            " [ 4.02543892  2.23532967  3.40244563 -1.01686652]\n",
            " [ 4.10438938  0.20293461  9.94990594 -1.24653191]\n",
            " [ 6.01596879  1.39989617  3.30223302 -0.26561331]\n",
            " [ 3.92325537  2.72137514  3.41836414 -0.21714059]\n",
            " [ 5.65952196  1.48853434  4.07185101 -0.30355697]\n",
            " [ 4.03155759  2.26789673  3.61867704 -1.07494366]\n",
            " [ 4.80847865  1.97574106  4.19806385  2.17763902]]\n",
            "current loss:  tensor(0.1798, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1810, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2987, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3030, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1879, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3084, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3436, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2667, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3075, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2335, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 3 10 14 13  1 15 11  0  7  5  6  2 12  4  8  9]\n",
            "best_MSE:  2989594334.080142\n",
            "dlg results at epoch 280 - [[5.4 3.9 1.3 0.4]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.1 3.5 1.4 0.2]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.  2.7 5.1 1.6]] [[  -2501.72281504   11283.91940171   -8386.88294388    3936.89790434]\n",
            " [  15977.9911125   -10112.52361632   15204.22048917    2052.1157032 ]\n",
            " [ -33803.5428771   -14332.86604544   16600.4399143     2210.17628305]\n",
            " [ -12271.88351107  -20536.56520067  -42225.26595192    -935.45577259]\n",
            " [ -52711.7983287    -7663.22888588    9174.21785543  -16584.34483294]\n",
            " [ -26791.55743377    3730.69754567  -68176.7233383   -34505.26542386]\n",
            " [ -27327.67766628    6780.10048352 -118318.50213191  -32222.73628028]\n",
            " [ -39606.47159946    2391.67982688  -94181.59513249  -33786.14809791]\n",
            " [   4267.0907056     6371.70666015   19932.66015198   38257.67605216]\n",
            " [  11550.31415873   -6993.33408373   18141.51293179  -29660.23369538]\n",
            " [  -5160.79501819    2751.45334811  -20926.67632558    3824.08948419]\n",
            " [  14359.15134524   -1091.21063722  -38836.29290595    2498.41972793]\n",
            " [   1885.97759995   -3243.4678536    26067.59044841  -14112.5364906 ]\n",
            " [ -34665.30894588   -6426.59534147  -95942.74485699  -23598.73227628]\n",
            " [ -22950.33764365   -9762.97975219   27343.28554053    5351.12916254]\n",
            " [   4250.55969506  -16192.28583153  -11624.31271026   -9414.12766497]]\n",
            "current loss:  tensor(0.3378, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2607, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2644, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3062, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2158, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1259, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2362, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2703, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2956, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2195, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 8  2 14  0 10  5  7  4  6 12 15  3 11  9  1 13]\n",
            "best_MSE:  2.660512060318048\n",
            "dlg results at epoch 290 - [[6.8 2.8 4.8 1.4]\n",
            " [6.  2.2 4.  1. ]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [6.  2.7 5.1 1.6]] [[6.57643667 2.32169387 5.22264292 0.63664915]\n",
            " [6.80030295 2.21041597 4.55131905 0.65065182]\n",
            " [5.01240981 3.15842831 2.96216594 0.98036108]\n",
            " [5.74611311 2.21428841 4.32457655 1.11401677]\n",
            " [5.79323938 2.36602605 3.97109337 1.29354513]\n",
            " [5.75967305 2.89715124 7.00412509 3.84866462]\n",
            " [6.95453977 3.22330535 4.60566167 1.53065284]\n",
            " [7.78188321 3.3818327  6.76096887 3.36333391]\n",
            " [7.03197453 3.06346539 8.73469342 4.84839964]\n",
            " [6.56576126 2.811745   5.66312787 1.09444113]\n",
            " [5.66371165 2.18303971 3.65389067 0.9601998 ]\n",
            " [5.98133149 2.26865167 4.62940021 1.56237013]\n",
            " [6.38866398 2.73189367 4.10514128 1.60227872]\n",
            " [5.73483197 2.9176036  4.76013954 0.84452676]\n",
            " [5.27811524 2.68708267 3.00376665 1.47060833]\n",
            " [6.09997623 2.6451476  4.37843185 1.35986922]]\n",
            "current loss:  tensor(0.4048, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1440, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2666, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2171, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1688, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1895, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2866, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3215, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3740, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2316, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [14  3 10  4 15  6 13  1 11  8  9  7  5 12  2  0]\n",
            "best_MSE:  3.9619932046618356\n",
            "dlg results at epoch 300 - [[5.  3.5 1.6 0.6]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [5.6 2.8 4.9 2. ]] [[ 5.96158156  3.18422291  2.74540998  1.58344378]\n",
            " [ 7.21269248  1.88086632 10.40826543  4.7884484 ]\n",
            " [ 5.84885127  3.3104005   5.63476279  1.34903732]\n",
            " [ 6.39827222  2.42160084  2.33910404  1.00916502]\n",
            " [ 6.95578993  3.12503389  5.03907643  2.30918311]\n",
            " [ 6.24865298  3.35589737  5.96063668  1.29693006]\n",
            " [ 5.92319111  2.94129206  6.50743946  1.8917346 ]\n",
            " [ 4.61130192  3.0797981   2.76081739  0.77479424]\n",
            " [ 6.7532327   3.44166195  5.93185023  2.09881159]\n",
            " [ 5.64976347  2.82718181  4.19803328  2.44423468]\n",
            " [ 6.56593614  2.1366595   4.25973569  0.27643274]\n",
            " [ 5.62902952  3.46772485  1.41698704  1.33074717]\n",
            " [ 5.87834148  2.82031755  5.61999204  1.07716314]\n",
            " [ 5.69563359  3.28494238  2.58168411  0.61879101]\n",
            " [ 6.05687662  2.36547324  2.17200475  0.83621942]\n",
            " [ 6.0705906   3.1634533   3.53593748  2.20192424]]\n",
            "current loss:  tensor(0.2274, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3024, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2755, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3080, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2181, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1487, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2157, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1323, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1607, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1168, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [14  1  5  2  0  8  9 11 13  6 12  7 15  4 10  3]\n",
            "best_MSE:  17.70119631224409\n",
            "dlg results at epoch 310 - [[5.8 2.7 5.1 1.9]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [5.1 3.5 1.4 0.2]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [6.7 3.  5.  1.7]\n",
            " [5.  2.3 3.3 1. ]] [[ 4.99024547e+00  1.74227897e+00  4.04161096e+00  6.45946377e-01]\n",
            " [ 6.10422403e+00  1.66489283e+00  3.11561416e+00  4.81586184e-01]\n",
            " [ 5.01167715e+00  1.58299282e+00 -2.31710658e+00  2.59904100e-01]\n",
            " [ 5.33145940e+00  3.69722553e+00  4.70994143e+00  1.16427238e-01]\n",
            " [ 3.00625999e+00  5.39746499e-01  5.09144846e+00 -1.17670122e+00]\n",
            " [ 5.75515207e+00  1.84251820e+00  5.51754837e+00 -1.62262123e-01]\n",
            " [ 5.59507152e+00  1.89374535e+00  5.40201362e+00 -3.92125083e-03]\n",
            " [ 6.06016430e+00  1.82576611e+00  5.45438954e+00 -2.76011781e-01]\n",
            " [ 2.79209153e+00  4.08486010e-01  6.71643912e+00 -1.05337332e+00]\n",
            " [ 7.40937188e+00  8.61665402e-01 -1.46833116e+00  8.58275333e-01]\n",
            " [ 5.79465353e+00  1.88635148e+00  5.12380464e+00  1.86829477e-02]\n",
            " [ 6.05768740e+00  1.88794514e+00  5.50609765e+00 -2.39735012e-01]\n",
            " [ 5.29871031e+00  2.33052340e+00  2.35623398e-01  3.72662654e-02]\n",
            " [ 5.93573069e+00  3.57543532e+00  4.94962304e+00  2.60434985e+00]\n",
            " [ 5.84254069e+00  1.89211027e+00  5.82742832e+00 -2.76083597e-01]\n",
            " [ 4.08206398e+00  8.26274557e-01  7.75353055e+00  1.82736769e-01]]\n",
            "current loss:  tensor(0.1979, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2973, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3137, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2347, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1658, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2233, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3514, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2384, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3158, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2138, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [14 12  9 11  5  0  3  6 15  2  1  4  8  7 10 13]\n",
            "best_MSE:  1154583505403478.0\n",
            "dlg results at epoch 320 - [[5.1 3.8 1.5 0.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [5.9 3.  5.1 1.8]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 3.  6.1 2.3]] [[ 4.08598671e+06  1.02887957e+07  5.67888064e+06 -4.71366897e+06]\n",
            " [ 8.41950679e+06  4.59571488e+06  2.61355095e+07  1.23930425e+07]\n",
            " [ 7.98736500e+06  8.01937635e+06  2.28015057e+07 -7.67689412e+06]\n",
            " [ 7.88875140e+06 -3.38034330e+06  1.24468067e+07 -1.42293756e+06]\n",
            " [ 7.36712385e+06  1.13008577e+07 -1.78444406e+07 -1.77856233e+07]\n",
            " [ 3.05533133e+07  7.24216170e+06 -1.14392570e+07 -1.43627473e+06]\n",
            " [-3.07661732e+07 -7.31969316e+06 -7.27235967e+06 -1.99799407e+07]\n",
            " [ 1.01327341e+07  5.10926944e+06  3.64200972e+07 -8.61105244e+06]\n",
            " [-1.67196674e+07  8.69169481e+05  8.28835838e+06 -1.00705570e+06]\n",
            " [ 1.63189028e+06  9.02827758e+06  2.48012848e+07  1.43806469e+07]\n",
            " [ 6.40641991e+06  2.22367743e+06  3.04176510e+07 -3.37940067e+06]\n",
            " [ 1.46001699e+04  6.51125656e+06 -3.39255644e+07 -7.66129991e+06]\n",
            " [ 2.05324753e+07  3.97391205e+06 -2.21675761e+07  1.40892835e+07]\n",
            " [ 1.33202474e+07  2.14693091e+06  1.07479762e+07 -1.50802971e+07]\n",
            " [-2.22596525e+07 -5.87605994e+06 -6.53006371e+07  1.73529382e+07]\n",
            " [ 3.39253689e+07 -7.37295147e+05  5.34422823e+07 -2.92515880e+06]]\n",
            "current loss:  tensor(0.3086, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3491, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1837, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1415, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2019, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2210, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1413, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1844, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2294, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 7  3 10  6  8  9 11 12  5  0  1  4 13 15  2 14]\n",
            "best_MSE:  4.634930793315898\n",
            "dlg results at epoch 330 - [[5.5 2.4 3.8 1.1]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [5.7 2.9 4.2 1.3]] [[ 6.14090419  2.33840795  4.2941013   0.38382111]\n",
            " [ 6.19640229  2.95659886  4.92129519  1.82389855]\n",
            " [ 6.3078857   3.28319389  1.128158    2.31153972]\n",
            " [ 4.59497684  3.20904359  0.52168244  1.33209795]\n",
            " [ 6.27061726  2.8881628   5.24960518  1.39682099]\n",
            " [ 5.47130527  3.49863109  1.44264756  0.7918711 ]\n",
            " [ 5.92538743  3.03644004  2.57653642  2.30462564]\n",
            " [ 4.29135557  3.83561154  4.09360717  0.72843298]\n",
            " [ 6.8011518   2.9967184  -0.88013001  0.59094044]\n",
            " [ 6.775826    2.31076229  8.06821076  2.53618542]\n",
            " [ 6.96505078  2.3542642   9.16620277  4.14617104]\n",
            " [ 5.60095237  3.32520715  2.62700436  1.91150093]\n",
            " [ 6.40742794  3.49771992  3.60168613 -0.44322641]\n",
            " [ 5.43087854  3.26807305  4.59872387  1.80596941]\n",
            " [ 6.33567468  2.74124815  4.49080879  1.50183687]\n",
            " [ 6.10875005  2.86989829  3.86399359  1.52371974]]\n",
            "current loss:  tensor(0.0929, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1410, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3023, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2089, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1484, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1939, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2960, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2190, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2241, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1393, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [10  1 12  8  4 14  3 13  5  2  6  9 11 15  0  7]\n",
            "best_MSE:  12054204553648.076\n",
            "dlg results at epoch 340 - [[6.5 3.  5.2 2. ]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [5.8 2.7 5.1 1.9]] [[  321495.10123125   -60745.25068932   -49777.75875679   116678.90021482]\n",
            " [ 1626579.88295595   457465.01134566 -1976096.42983449   628392.68425755]\n",
            " [-1203860.11936704 -1953314.34719867  1144113.54236528 -1512653.17978777]\n",
            " [-2977259.901118   -1351684.9140363   -289457.13763499     7525.23369822]\n",
            " [-1493218.59262918 -1843126.00523256  1665231.43260727 -1797219.79396315]\n",
            " [-1433011.83176684   333300.7454242    -10275.08518083   381251.66266472]\n",
            " [-2566133.79303668 -2005613.7352208   1819014.6741197  -1494615.89268507]\n",
            " [ 2275702.76686912  -184690.20016113   321558.35555913  -945597.52085118]\n",
            " [ -596158.4883126    336909.23442906   327432.75831855  -216765.388024  ]\n",
            " [  511998.57311272  -600564.13241018 -1045938.86692505  -188967.54629762]\n",
            " [-1530406.87516234 -1714990.62575092  1064540.42486869 -1292457.22120612]\n",
            " [ -217170.38625335   172789.53103779 -1274779.38551101  -559210.77566254]\n",
            " [  162807.5099614     72199.63515722  2602720.98207256  1090423.54379166]\n",
            " [  672639.03356425  -481850.74670912  2661875.22572104  1180213.51471498]\n",
            " [  325728.79369544  -203942.8598402    852193.65962286   177720.66580445]\n",
            " [-1757485.01806653 -1618092.65293171   710864.35979002  -985743.47777267]]\n",
            "current loss:  tensor(0.1456, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0989, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1677, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1208, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1142, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3276, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1304, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1809, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1378, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1482, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 7 12 10  6  5  3  0  8 11 15  2  9  4 13  1 14]\n",
            "best_MSE:  69459478200174.97\n",
            "dlg results at epoch 350 - [[5.7 2.6 3.5 1. ]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [6.  3.  4.8 1.8]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [4.6 3.2 1.4 0.2]] [[ -5176722.09372901  -4603519.90792551 -16814700.07179753\n",
            "    5508931.66272785]\n",
            " [  2601786.52863973   -278972.43521483  10100509.3785773\n",
            "    1508398.35592925]\n",
            " [  5499672.52526862   2505013.05105361   -154064.19082817\n",
            "   -1113033.87100239]\n",
            " [  -794023.02874082   -655779.88416283   4830031.96137556\n",
            "    2706509.69435533]\n",
            " [ -6085806.32205359   2021049.04143401  -3671461.48649819\n",
            "    1795058.58802555]\n",
            " [  6354372.69966973   1908976.22468987  -8597248.55503619\n",
            "     692738.0325906 ]\n",
            " [  -430679.49271265   -706721.46640393  -4884288.42542321\n",
            "    -831867.07126003]\n",
            " [   537650.43311999   -597484.43015579   9667322.1050326\n",
            "    5457768.26347021]\n",
            " [  1195569.06871302    125401.8241977    1298319.26077901\n",
            "     413720.16588863]\n",
            " [  6704935.9293813   -3383709.11490811  -3897652.89237485\n",
            "   -1201224.49902083]\n",
            " [  1257563.74166135    159818.46752752  -2418368.38627282\n",
            "    -951942.28375626]\n",
            " [  -190541.53715593   1523962.23669832  -6502140.95663961\n",
            "   -1255177.86945444]\n",
            " [   418724.3364391    -363526.56608446   6892195.59834252\n",
            "    1999238.51670262]\n",
            " [  -745706.95098387  -2301530.14233254   4974114.83853409\n",
            "    3637972.05411983]\n",
            " [  2085872.3281911     -79289.80691564   8447478.88261877\n",
            "    6333088.76826328]\n",
            " [  -667155.03193841    750624.7550589   -4805831.75976911\n",
            "   -2962343.66413888]]\n",
            "current loss:  tensor(0.1870, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1427, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1291, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0615, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2461, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2063, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2442, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0871, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1570, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2038, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 7  0  5  8 10  4  2 13  9  6 12 15  1 14  3 11]\n",
            "best_MSE:  2.6507404132165995\n",
            "dlg results at epoch 360 - [[6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.4 3.2 4.5 1.5]] [[6.03220957 3.09959892 7.66404109 2.25414543]\n",
            " [6.50494953 3.09359322 3.04239298 1.82055063]\n",
            " [5.72263626 2.41692313 3.2856278  1.18260119]\n",
            " [6.39354705 2.63541225 4.44934325 1.49098541]\n",
            " [7.76658496 4.03729127 4.76979721 2.82480015]\n",
            " [4.86324053 2.86091732 2.72432561 1.7358568 ]\n",
            " [5.21307744 3.34142308 1.50392294 1.13107383]\n",
            " [5.99188294 2.41889466 2.36627383 1.41631228]\n",
            " [5.58869631 2.16966861 4.70534693 1.28810105]\n",
            " [5.45537527 2.85500662 3.57574183 1.04324426]\n",
            " [4.26901757 3.17613387 3.6281553  0.25245914]\n",
            " [5.09879478 2.6552224  2.15770318 0.03420571]\n",
            " [5.87618788 2.69292302 4.98479284 1.45644819]\n",
            " [5.20204092 2.82552704 4.045454   0.71277497]\n",
            " [5.29238233 2.09219381 3.92064074 1.1572019 ]\n",
            " [5.58133783 2.89451569 4.37854626 0.77890242]]\n",
            "current loss:  tensor(0.2142, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3136, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1997, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1050, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2076, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1789, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1186, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.3935, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1278, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2008, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [10 11  8  5  3  7 15 13  2  0  9 14  4 12  1  6]\n",
            "best_MSE:  2215525199225.496\n",
            "dlg results at epoch 370 - [[6.7 3.3 5.7 2.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [5.2 3.5 1.5 0.2]] [[-3.91738715e+03  2.69498915e+05  8.57954388e+05  1.75077398e+05]\n",
            " [-2.27108639e+05 -3.17201089e+05  6.82456879e+04 -2.88838354e+05]\n",
            " [ 8.44125400e+04 -1.56079704e+05  6.29741317e+05 -5.38447711e+05]\n",
            " [-7.82131520e+05 -5.01778970e+05  9.93486254e+04 -2.87119122e+05]\n",
            " [-8.39139901e+04 -6.58416516e+04 -2.81921692e+05  1.49874287e+05]\n",
            " [ 1.18972913e+06  3.42673841e+05 -8.09064799e+05  3.73463056e+05]\n",
            " [-2.64857946e+04  1.09897656e+05 -7.77942646e+05 -5.25049534e+03]\n",
            " [-1.28549121e+05  1.85168316e+05  3.27904856e+05  2.67262443e+05]\n",
            " [-2.58643272e+05 -2.01192618e+05 -1.99358811e+05  6.80270685e+04]\n",
            " [ 9.10345252e+05 -6.53455188e+05  5.37473466e+06  2.33853510e+06]\n",
            " [-2.47556020e+05 -1.62191364e+05 -5.70697328e+05  1.56960344e+05]\n",
            " [-2.88609859e+05 -1.14083689e+05 -4.91136792e+03 -1.21875589e+05]\n",
            " [ 7.54402045e+05  2.49656760e+05  6.75526949e+05 -2.14375039e+05]\n",
            " [ 3.66528285e+05  3.57165328e+04 -3.05883209e+05  3.60252599e+04]\n",
            " [ 3.48035862e+05 -5.18839049e+05 -9.69769866e+05 -1.33864808e+05]\n",
            " [-3.53597642e+05 -6.59125827e+04  5.51024688e+04 -3.03302321e+04]]\n",
            "current loss:  tensor(0.0954, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1137, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1225, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2142, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1587, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2973, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0974, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1990, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1437, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0666, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 8  5  3  9  6 15 10  4 11  0 14  7 12 13  2  1]\n",
            "best_MSE:  19.904473490000388\n",
            "dlg results at epoch 380 - [[6.3 2.5 4.9 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [4.9 2.5 4.5 1.7]] [[ 7.04590496  2.60434741  4.85588808  1.35873313]\n",
            " [ 5.34172725  3.4384201   0.47385016  1.0341356 ]\n",
            " [ 8.01091861  2.71312617 11.77606184  5.18647422]\n",
            " [ 7.40070449  3.57461286  4.46337719  1.4599497 ]\n",
            " [ 4.13874945  1.89751485  3.80187268  0.6434431 ]\n",
            " [ 6.10215567  2.28286869 11.57122567  4.28684635]\n",
            " [ 7.90610252  1.44726042 16.57226498  9.04726096]\n",
            " [ 7.81230735  3.63945544  5.00315744  2.49092712]\n",
            " [ 3.85849851  2.32139755  2.5907327   1.49825067]\n",
            " [ 5.15832467  2.70887611  0.42595917  0.45643695]\n",
            " [ 5.61299233  3.47422397  2.09121268  1.01757427]\n",
            " [ 4.74293915  4.4954885  -1.60035492 -0.5300573 ]\n",
            " [ 5.50351568  3.67530164  0.81941755 -0.08077632]\n",
            " [ 7.06511691  1.75128245 16.65051042  7.25498071]\n",
            " [ 8.75731017  4.14103402  4.37700186  1.38038614]\n",
            " [ 3.71407771  2.49985828  4.69184236  2.33846058]]\n",
            "current loss:  tensor(0.2258, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1948, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1146, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2440, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1765, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1538, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0944, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2172, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1219, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1112, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [13  1  3  6 11 10  5  8 15  9  7  0  2 14  4 12]\n",
            "best_MSE:  582422748.4493434\n",
            "dlg results at epoch 390 - [[7.3 2.9 6.3 1.8]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [6.5 3.2 5.1 2. ]] [[  3193.17989202  -3225.09808161  20690.6798066   10272.64947494]\n",
            " [ 14782.79848608   4607.43645134  -9018.78734672   5393.02316923]\n",
            " [  2298.42715925  -8532.21966467  -5971.42991899  -7395.09687074]\n",
            " [ -5852.60785582  -8075.9837881   17887.28419879  -5601.88841959]\n",
            " [ -4651.93229514   3584.36765357 -12489.82611153   5656.84683617]\n",
            " [ -7076.40233012 -14441.24140038  20399.64104166   2625.2014105 ]\n",
            " [  6436.90814351   3902.92579789 -12965.76467026  -8645.31575798]\n",
            " [ -8244.300373    -1425.35762336  -2857.29911222   1337.65817159]\n",
            " [-17850.67039647  -2898.64736029  -1357.17562301  -2176.02261291]\n",
            " [  6638.74508473  -7407.72481476  59572.47875941  27933.69657801]\n",
            " [  1802.48596253   1138.55128653  -3765.86958963  -2938.8081691 ]\n",
            " [ -2177.13419456  -2282.12635139   2824.21029141   1441.3061379 ]\n",
            " [  2395.76999589 -12660.79532223   2046.42697945  -7829.52902891]\n",
            " [ -9102.84502648  -3045.55441657  11860.79178234  -8468.78960245]\n",
            " [ -5241.30017716   3031.52433518 -27170.30995896 -12649.11328001]\n",
            " [ -1748.33335342  -1847.38215142   4165.42729193   1698.22283378]]\n",
            "current loss:  tensor(0.1502, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0875, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0641, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2594, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1107, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1486, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0618, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0805, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1249, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0408, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 3  8 10 11  0  2 14 12 15 13  9  4  5  1  6  7]\n",
            "best_MSE:  1973093.271427083\n",
            "dlg results at epoch 400 - [[4.4 3.2 1.3 0.2]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [5.6 2.7 4.2 1.3]] [[ -335.84419605   330.88306188 -3176.06223654 -1507.40249737]\n",
            " [  -58.48724385    85.35819339  -784.0555474   -387.81744993]\n",
            " [ -208.27548037   209.79319206 -1957.93608254  -932.15863982]\n",
            " [  245.54656264  -217.57752869  2071.0747442   1022.53744697]\n",
            " [  -34.77125995    56.19321671  -400.65837802  -207.33337184]\n",
            " [  -52.72954077    87.81934735  -601.92409816  -299.28288776]\n",
            " [   73.1315067    -87.38606768   647.36570439   315.91916059]\n",
            " [   34.80634499   -19.46862463   273.67843949   127.28940303]\n",
            " [  -36.14341968    79.36907432  -501.43773876  -263.36580363]\n",
            " [ -116.79939045   138.43024018 -1271.38974822  -618.84306618]\n",
            " [   51.31702083 -1377.14415727  -451.4790501   -988.95317536]\n",
            " [   32.57746733   -39.22014512   329.89091079   166.23001421]\n",
            " [  -41.94640754    75.19634672  -499.25217533  -253.77452191]\n",
            " [ -168.00527055   109.84799901 -1159.16137478  -565.52306722]\n",
            " [  -34.73901847    60.67015993  -408.9605928   -215.85693859]\n",
            " [ -121.09887571    44.89653303  -982.93865172  -463.04079137]]\n",
            "current loss:  tensor(0.1438, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1457, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1587, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1064, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1070, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0909, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1750, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1312, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1549, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1897, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 6 15 12  0  4  3 14  8  5  7  9 10 13  1  2 11]\n",
            "best_MSE:  41512908749479.27\n",
            "dlg results at epoch 410 - [[6.9 3.1 5.4 2.1]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [6.  2.2 4.  1. ]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [4.6 3.2 1.4 0.2]] [[ 2.28666380e+06  3.04729500e+06 -6.14853935e+04  3.72484860e+06]\n",
            " [ 1.19061138e+06  2.24936589e+06 -2.59699826e+06  2.72723981e+06]\n",
            " [ 1.12370214e+05 -4.23066826e+03  3.99449405e+06  2.13461118e+06]\n",
            " [-6.80973051e+05  1.13758800e+06 -3.42795359e+06  2.03822176e+06]\n",
            " [-1.08926254e+05  8.24240581e+05 -1.64722092e+06  1.28736484e+06]\n",
            " [ 2.84639139e+06 -3.40410255e+05 -1.49419007e+05 -6.90244080e+05]\n",
            " [ 1.05624016e+06  3.70173925e+06  7.24047300e+05  3.08990529e+06]\n",
            " [ 6.17052309e+05  7.37199284e+05 -6.85591307e+05 -1.13448413e+05]\n",
            " [ 9.31227128e+05  4.13535547e+04  6.17264112e+06  3.29585436e+06]\n",
            " [-1.05915561e+06  2.73240591e+06  7.28475830e+05  2.71974753e+06]\n",
            " [-5.54846338e+06  1.26156650e+06  6.40378107e+06  3.15726192e+06]\n",
            " [ 7.67438275e+04 -3.38634655e+05  6.67009635e+06  2.40945183e+06]\n",
            " [-1.27529745e+04  8.84828476e+05 -1.49617708e+06 -1.18502007e+06]\n",
            " [ 8.79365135e+06 -1.10267164e+06 -8.08713662e+06 -2.27447504e+06]\n",
            " [-1.67879408e+05  2.71398784e+05 -1.07337391e+06 -5.26849342e+05]\n",
            " [-4.13456546e+06  1.27765600e+06  7.51080268e+05 -1.52746358e+06]]\n",
            "current loss:  tensor(0.0714, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1557, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1267, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2026, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1676, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1484, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0619, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1051, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2194, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1718, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 0  3  4  9  8 12  2 14 11 10 15  1  5  7 13  6]\n",
            "best_MSE:  449194898590.615\n",
            "dlg results at epoch 420 - [[5.6 2.5 3.9 1.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [5.1 3.5 1.4 0.2]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [7.2 3.  5.8 1.6]] [[  182171.05125258   -46596.26487086   -73918.05741991    15375.71777822]\n",
            " [   49417.98568244  -130818.08153168   334033.16267131   158683.61133323]\n",
            " [ -209866.27639106    14483.833013      90056.84141377  -261363.40488934]\n",
            " [  161007.0894027   -456344.52394401    32915.37319822   227101.41070013]\n",
            " [  169680.51595672  -167459.1940985   -286102.72382084  -155133.49557505]\n",
            " [  477838.78525109    36812.82995837  -812440.82090736   302573.3834442 ]\n",
            " [ -140296.80765207     4682.97729448  -488943.97871306  -462889.77469793]\n",
            " [   80179.25374883   237733.04759094   469529.48821234   -80340.367545  ]\n",
            " [  -90048.48679806    52879.94382953  -885613.8312078   -606021.61097019]\n",
            " [    3026.13737924   -44207.34053805   -39046.24616691   110346.73158908]\n",
            " [   27514.11220998     9429.74309175 -1377217.38835815  -306604.07423709]\n",
            " [  -96522.54988613    92196.31864594  -372145.47246486  -346517.39903168]\n",
            " [  115222.18491699    55673.42016372  -496685.13667696   225596.00853675]\n",
            " [   10338.37049516   356742.04995554   409204.27868602    16218.15755158]\n",
            " [  147039.12294589    -5379.78369348    62486.27181785   -36047.01116384]\n",
            " [  193977.41177754   163809.99840318  1065575.28434763  -264223.52893141]]\n",
            "current loss:  tensor(0.0654, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1286, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1039, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0976, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1192, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0826, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1343, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1594, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1376, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0763, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [14 11  9  4  3 12  7 15  6 10 13  1  8  0  2  5]\n",
            "best_MSE:  6.04176821000874e+21\n",
            "dlg results at epoch 430 - [[4.9 2.4 3.3 1. ]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [4.9 2.5 4.5 1.7]] [[-4.60548903e+09 -1.22306330e+10 -6.22087840e+10 -2.77807874e+10]\n",
            " [ 4.89650672e+10 -2.84336660e+10 -1.06867647e+11  2.01286743e+10]\n",
            " [-9.57016525e+09 -3.14601551e+09 -4.77545138e+10 -1.28322434e+10]\n",
            " [ 3.94723553e+10 -7.64107701e+09 -6.44469198e+10  8.78232333e+09]\n",
            " [ 4.72127584e+10 -1.96991507e+10  4.04205979e+10 -4.20093732e+10]\n",
            " [-1.14324189e+09  1.64537012e+10  4.21696165e+10  4.43228746e+09]\n",
            " [ 1.92725858e+09 -4.67971059e+09  1.47713363e+10  9.56306078e+09]\n",
            " [ 1.47989185e+10 -1.46715390e+10 -1.96047568e+10 -8.02032299e+09]\n",
            " [ 6.93532292e+10 -1.71952442e+10 -2.97654171e+10  4.74907994e+10]\n",
            " [-1.39539840e+10  1.34868371e+10 -5.50173914e+10 -2.30098912e+09]\n",
            " [ 4.42374558e+10 -1.58333175e+10  1.06657590e+10 -2.27300112e+10]\n",
            " [ 4.30573598e+10  2.06755390e+10  1.05506772e+10  9.35317714e+08]\n",
            " [ 4.80870468e+10 -2.33187328e+10  1.41016747e+11  7.57033913e+09]\n",
            " [ 3.34447960e+07 -8.11515830e+09  9.99346242e+08 -4.44128300e+09]\n",
            " [-1.18315342e+11  1.46038464e+10  2.29814407e+09  1.35664874e+10]\n",
            " [-2.84139582e+10  2.66432551e+09  5.45203037e+10 -1.03472639e+10]]\n",
            "current loss:  tensor(0.1191, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1010, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1223, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1230, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1692, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0690, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1299, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0505, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1152, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1262, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 8  9  7  4  6 14 15  5 11  3  1 12 13  2 10  0]\n",
            "best_MSE:  1975041121129507.5\n",
            "dlg results at epoch 440 - [[5.5 4.2 1.4 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.2]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.8 2.8 4.8 1.4]] [[-9.77273916e+06  7.06766620e+06 -1.33488882e+08 -6.65762335e+07]\n",
            " [ 1.37387659e+07  2.23254429e+05 -1.08002433e+07 -5.44194868e+06]\n",
            " [-2.65829952e+06 -3.88251716e+06  1.44506236e+07  5.20842081e+06]\n",
            " [ 1.39948973e+07  6.18310034e+06 -2.64336330e+07  1.76186331e+07]\n",
            " [ 7.54231551e+06 -1.63351039e+07 -7.64464970e+07  1.95523760e+07]\n",
            " [ 2.02346635e+06 -5.23342406e+06 -3.51120995e+07  1.75198062e+07]\n",
            " [ 1.86488175e+07 -1.17805256e+07 -1.39079543e+07 -8.50251972e+06]\n",
            " [ 8.67768002e+06  3.94993039e+06 -2.86140238e+07 -1.43254454e+06]\n",
            " [-2.73510020e+06  5.21403677e+06 -4.70823317e+07 -2.40828705e+07]\n",
            " [-2.52183444e+07  8.28706126e+06  6.43437962e+07 -1.40956762e+07]\n",
            " [-1.44117272e+07 -1.96699031e+07  3.16259569e+07 -5.65155624e+06]\n",
            " [ 2.20656101e+05  4.20932500e+06 -3.31743059e+07  1.19579460e+07]\n",
            " [ 9.70573803e+06 -1.51551063e+06  2.38339645e+07  3.10788855e+06]\n",
            " [ 2.32978951e+06 -4.87886869e+06 -8.17573405e+06 -3.01476701e+06]\n",
            " [ 6.88246195e+06  3.55850611e+05  2.53783482e+06 -1.67165163e+05]\n",
            " [ 3.70481759e+06 -1.09727224e+06  2.22075150e+06 -8.66300709e+05]]\n",
            "current loss:  tensor(0.0899, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0474, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1871, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0968, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1163, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0813, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0759, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0873, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0732, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0748, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [15  0  8 12  4  1  5  7 14  3 13  2  9  6 11 10]\n",
            "best_MSE:  475812111.1852195\n",
            "dlg results at epoch 450 - [[4.7 3.2 1.3 0.2]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [6.  2.2 4.  1. ]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [6.4 2.9 4.3 1.3]] [[ -2560.4943012     875.75147624  17757.74979262 -16028.37298261]\n",
            " [  1339.51238903  -2664.73317488  24907.90262554  11830.63809618]\n",
            " [ -3450.51605879   -164.18770752   8161.4265267    1499.68729224]\n",
            " [ -2296.7867627     714.64540687  -2177.92967317  -2369.63183709]\n",
            " [ 26588.45943925  -3814.40880078  51337.92479049 -15503.12713803]\n",
            " [ 11972.13983383  -1729.12140158 -28689.84402198   6879.74720619]\n",
            " [  -706.32317502    993.77290763 -14378.63142546   1686.64289989]\n",
            " [  1362.7242901    5217.99130921  -2049.69720882  16265.06857135]\n",
            " [  1963.38848354   4873.42874741   -994.80410539  -6311.19354368]\n",
            " [  3358.81641056  -4585.2087013   39484.2044952   14062.29676729]\n",
            " [-10213.70540097   3452.82173394   1820.78254893  15156.14435214]\n",
            " [    72.93734631  -2747.55655306 -22218.12530039  -8480.80520967]\n",
            " [  3243.00060686  -5630.37688436 -11499.22664112  -1468.60225358]\n",
            " [   525.37714567   7470.66077539  -4788.6288702    9894.18678086]\n",
            " [  -178.55632242    -59.61551667   7837.87572716   1729.98822368]\n",
            " [  -608.05469528    336.41822228    967.69214685  -3431.4042941 ]]\n",
            "current loss:  tensor(0.0557, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0735, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0582, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1440, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1320, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1765, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1704, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0483, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1114, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1075, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 4  3  8 13  7 12 11  9  6  2 10  1 15  5  0 14]\n",
            "best_MSE:  36.25049210926864\n",
            "dlg results at epoch 460 - [[6.3 3.3 4.7 1.6]\n",
            " [5.9 3.  5.1 1.8]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.2]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [4.3 3.  1.1 0.1]] [[ 3.65396809  3.83087702  5.13060484  0.96157834]\n",
            " [ 2.34273416  3.81387501  8.44602735  0.95164213]\n",
            " [ 3.54105385  3.84037236  5.43586271  0.86622384]\n",
            " [ 6.68341174 -0.19456963 26.47814465 12.31524785]\n",
            " [ 7.01579408  3.49008148  1.85709267  2.10383065]\n",
            " [ 4.39929082  3.50473125  6.71934189  1.63653432]\n",
            " [ 5.0385159   4.78363818 -6.93141798 -5.44600507]\n",
            " [ 5.83081432  3.93510842 -1.16017755 -2.21208197]\n",
            " [ 6.7441147   1.71183698  3.59424854  1.12068025]\n",
            " [ 6.89406142  2.78620496  5.45166642  0.11735867]\n",
            " [ 4.18195421  2.16398605  4.73917284  1.14913331]\n",
            " [ 5.95199014  2.31231162  4.46104051  1.6951547 ]\n",
            " [ 6.4266458   1.96314426  4.49193439  0.94736743]\n",
            " [ 6.61477596  2.93306122  3.60104985  0.30314086]\n",
            " [ 7.22282245  3.31423252  4.94113036  1.96613104]\n",
            " [ 3.40850519  3.7964105   5.26517303  0.74759255]]\n",
            "current loss:  tensor(0.1269, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1643, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1343, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0718, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0471, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0378, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1391, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0999, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1586, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0385, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 4  0  6 12  2  1 14 10  8 11  3 13 15  9  5  7]\n",
            "best_MSE:  82021463.86815912\n",
            "dlg results at epoch 470 - [[6.7 3.  5.  1.7]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  3.  4.8 1.8]\n",
            " [5.2 4.1 1.5 0.1]] [[-2.53966994e+01  1.51139015e+02 -3.12183463e+02 -4.77881459e+02]\n",
            " [ 1.78941225e+02 -2.50769679e+02  2.14484407e+03  1.00774115e+03]\n",
            " [-1.74646858e+02  4.44077160e+02 -4.22719900e+03 -2.12665724e+03]\n",
            " [-7.88032083e+02  1.94080918e+03 -1.36580773e+04 -6.28070939e+03]\n",
            " [-1.62498422e+02  3.15169894e+02  4.62632412e+02 -5.33904339e+02]\n",
            " [ 5.00444221e+02 -2.10850071e+02 -2.10344430e+03 -1.76290989e+03]\n",
            " [-9.52195614e+00  5.13485627e+01 -6.30029354e+02 -3.55559609e+02]\n",
            " [ 5.97564273e+01 -2.18945483e+02  5.77707063e+03  3.20212824e+03]\n",
            " [ 1.56945804e+02 -2.23568723e+02  2.00948100e+03  9.56110154e+02]\n",
            " [-2.20581783e+02 -3.98455886e+01 -8.58105090e+01 -3.09599550e+02]\n",
            " [-7.49736824e+02  2.30394027e+03 -1.46233982e+04 -8.51619694e+03]\n",
            " [-3.83535242e+02  7.61394950e+01 -5.93034852e+03 -2.65649890e+03]\n",
            " [-4.25908474e+02  9.98689833e+02 -1.09492677e+04 -5.57540230e+03]\n",
            " [ 4.77623059e+02 -7.75032791e+02  3.66089069e+03  1.84427114e+03]\n",
            " [-2.49810541e+02 -1.50330703e+02 -1.79419773e+02  3.71592704e+02]\n",
            " [-1.49855449e+03  3.11383864e+03 -3.00221459e+04 -1.51435062e+04]]\n",
            "current loss:  tensor(0.1599, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1005, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0463, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1609, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0910, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1026, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1018, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1248, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0384, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0430, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [11  0  3  7 12 14  6  4 10  2 15  9  8  1  5 13]\n",
            "best_MSE:  1056940067897.1041\n",
            "dlg results at epoch 480 - [[5.9 3.2 4.8 1.8]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [5.  3.5 1.3 0.3]] [[ -369085.81302946   125131.53912372   -14449.02133343   168387.85374087]\n",
            " [ -240371.04984269  -261327.31332186   807353.0477515     49195.56432593]\n",
            " [  159258.30175608   170706.63905024   -85761.83639496   771899.52380326]\n",
            " [ -174755.35458132   -26337.05631345   801261.38608063   362960.94684943]\n",
            " [   76145.25840658   -22483.56291662  -691869.19016804  -299320.04635919]\n",
            " [   67836.25395421   -19384.0101173    -54421.80887849    48563.97486741]\n",
            " [  729906.74178256   192874.42710364  -381059.38320135    -4724.38297055]\n",
            " [ -375151.13275745   -54797.62831499   533587.19099214    74275.50477932]\n",
            " [  369862.99243493   303473.24670823  -278860.82425129   -92002.10638589]\n",
            " [  289517.20365978  -280314.33069416   617064.26116655   144098.92543099]\n",
            " [   60140.19690265   162002.08855821   536378.76044937  -151563.37942121]\n",
            " [  180042.56053507  -216191.60651386  -268070.70151346   338132.15009565]\n",
            " [ -653987.81405996   135935.02765841 -2211731.21710869   529047.01457573]\n",
            " [  235379.32163725    30611.82381176 -1362662.49829851   153725.70293098]\n",
            " [ -195133.41038076    43938.52736351   131315.46467868  -168102.64762327]\n",
            " [ -394551.0775728    372894.23710583 -2645603.5586115  -1408098.0128717 ]]\n",
            "current loss:  tensor(0.1443, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2026, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0669, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0465, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0674, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0444, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0358, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0657, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0905, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0985, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 7  0 12 15  5 11 10  2  1  8  4  6 14  9 13  3]\n",
            "best_MSE:  923459344.6154449\n",
            "dlg results at epoch 490 - [[6.  2.2 4.  1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [7.7 2.8 6.7 2. ]] [[ -6711.91696074  -4471.50544856    636.65432272    613.70021628]\n",
            " [-19940.89743807  -2804.62665761  49432.5039326  -19961.61034239]\n",
            " [  -589.96737928   1843.54503128 -24636.01898298 -12490.10160061]\n",
            " [  4179.73691604   7667.53548658  -6720.26854273  -5852.92120704]\n",
            " [-24982.86774299 -14071.23525245  12093.14394086   3531.9999099 ]\n",
            " [-22536.64247581  -5657.10546153  -5715.02770343 -14714.52464457]\n",
            " [  -278.77000769    194.84422083  -4218.89165267  -2240.98894468]\n",
            " [-17183.1273809   -2681.57190275  -7627.31006536    365.94144717]\n",
            " [  2305.96327227   -729.30239335   1215.08804774  -1272.50112259]\n",
            " [ -3420.90474813   3424.26642472 -80232.13937898 -39166.54946551]\n",
            " [ -4210.94294673   2178.78366588   4314.65061514  -1854.53334196]\n",
            " [ 10917.24197935  -1740.15889763 -22701.12638882  -5596.98306055]\n",
            " [  -766.82550698   2011.22554368 -16446.68547851  -7932.56679289]\n",
            " [ -1896.00405416   2858.30062854 -43786.6992606  -20728.48740722]\n",
            " [  1001.7340596   -2429.62648046  18002.4066115    9113.6256042 ]\n",
            " [ 11317.01260577  -1552.9589514   29588.61158039   5753.19240548]]\n",
            "current loss:  tensor(0.0594, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1416, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1573, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0712, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1449, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0946, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0775, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0763, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1221, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0919, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 4 15  5  7 12  3  1 14  2 10 11  9  0  6 13  8]\n",
            "best_MSE:  5.375799128053895\n",
            "dlg results at epoch 500 - [[6.1 3.  4.9 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [5.8 2.7 3.9 1.2]] [[ 4.72417996  2.84396539  4.676856    1.21142098]\n",
            " [ 6.03900759  2.40439474  3.52436931  1.04133268]\n",
            " [ 6.25139763  2.84181075  5.00897503  0.97490383]\n",
            " [ 6.92473043  2.74038258 -3.02736059 -1.35669095]\n",
            " [ 7.22639771  3.2154833   5.57541321  1.89442204]\n",
            " [ 6.02036798  3.11479651  5.56713236  1.85363648]\n",
            " [ 6.79174544  3.25409736  5.98924044  1.76198641]\n",
            " [ 3.796094    2.84195234  0.60056254 -1.69497998]\n",
            " [ 6.66474228  3.58325187  4.43330306  2.59669252]\n",
            " [ 5.15532175  3.11100212  2.35784952 -0.61010687]\n",
            " [ 6.09156554  2.23850585  2.30130067  1.37420696]\n",
            " [ 4.97343604  2.56279737 -2.66388961 -0.78042779]\n",
            " [ 7.32466825  3.26039604  3.75879393  1.68417681]\n",
            " [ 6.83999039  2.25647242  8.75122827  4.19526275]\n",
            " [ 5.99014939  2.9111371   4.80726364  1.86700005]\n",
            " [ 6.49829428  2.75781234  1.67281643 -0.84185356]]\n",
            "current loss:  tensor(0.0793, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0846, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0890, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0764, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0516, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0808, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0672, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0271, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0463, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0588, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [12  6 14 10  4  2  3  5 11 13  0  7  9 15  1  8]\n",
            "best_MSE:  1232886251442.668\n",
            "dlg results at epoch 510 - [[7.7 2.6 6.9 2.3]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [5.8 2.8 5.1 2.4]] [[ 1.18406068e+05 -1.43535612e+05  2.52190100e+06  8.26541176e+05]\n",
            " [ 5.55672798e+04  1.11002479e+05 -3.88272198e+05  1.12815187e+05]\n",
            " [-6.69835595e+04  8.95820334e+04 -7.68013614e+05 -3.61927099e+05]\n",
            " [ 5.69787769e+05  4.65028541e+05  1.34919804e+06 -2.75348681e+05]\n",
            " [-7.91561281e+04  3.46778791e+03 -2.07143322e+05  9.19956321e+04]\n",
            " [-1.44914169e+04 -6.10040850e+04  1.02433903e+06  5.34197066e+05]\n",
            " [-1.80833105e+05 -1.69310458e+04 -7.04484557e+05  4.23647643e+04]\n",
            " [ 6.07177270e+05  1.23572370e+05  2.44614502e+05 -2.93923649e+04]\n",
            " [ 7.58197943e+03 -5.99907467e+04  1.44009633e+06  7.79308996e+05]\n",
            " [ 3.91822541e+04 -6.68051057e+01  3.54602618e+04  2.39704783e+05]\n",
            " [-7.32219929e+05 -5.45490433e+05  9.72678420e+05 -5.89796856e+05]\n",
            " [ 2.30091952e+05  1.33247979e+05  1.30527320e+06 -1.42579705e+05]\n",
            " [ 1.54993422e+04  5.79031702e+04  2.51979753e+05  8.10230235e+04]\n",
            " [ 3.65237427e+04  1.40074557e+05  7.84928453e+05  4.24581064e+05]\n",
            " [-6.93986232e+04  2.31133476e+05 -2.34634058e+06 -1.22449189e+06]\n",
            " [-9.52881119e+04 -4.15536020e+04  3.91922945e+05  4.69738951e+05]]\n",
            "current loss:  tensor(0.0948, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0680, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0466, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0321, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1071, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0818, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1043, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0459, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1022, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2249, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 2  7 15  9  4 11 13 12  0  6 10  3  8 14  5  1]\n",
            "best_MSE:  3.3980318907695744e+17\n",
            "dlg results at epoch 520 - [[4.4 3.2 1.3 0.2]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [5.8 2.7 5.1 1.9]] [[-8.61735446e+07  5.26209994e+07 -5.29684833e+08 -3.57868855e+08]\n",
            " [ 1.70106711e+08  1.09823627e+08 -9.74621907e+08 -2.65804780e+08]\n",
            " [-8.15480082e+07  1.41020858e+06 -3.82328549e+08 -1.84281715e+08]\n",
            " [ 6.52550868e+07 -1.42609250e+08  1.64626093e+09  8.91343350e+08]\n",
            " [ 8.57794386e+07  9.83335755e+07  1.70028250e+08 -8.56520043e+06]\n",
            " [-2.35249846e+07 -2.42486886e+07  6.98530956e+07  4.51605950e+07]\n",
            " [-3.14717629e+07  7.71190499e+07 -6.89042476e+08 -3.53958468e+08]\n",
            " [-1.94944063e+07  4.82522027e+06 -3.22593806e+07 -9.26231765e+07]\n",
            " [-2.36010995e+08 -9.36743068e+07 -7.96920063e+07  7.55787030e+07]\n",
            " [ 4.12534799e+07 -9.94771407e+07  3.37241787e+08  2.27847816e+08]\n",
            " [-9.74249960e+07 -2.86874981e+07  6.26472164e+08  1.48563851e+08]\n",
            " [ 1.56044963e+08  7.36487805e+07 -4.85054072e+08  1.99178986e+08]\n",
            " [-2.12108679e+07  6.04935433e+06 -2.46662112e+08 -1.29547332e+08]\n",
            " [ 2.57929662e+08  4.55820891e+07  3.14022979e+07  1.84171204e+05]\n",
            " [-7.60194548e+05 -8.05453508e+07  9.14164568e+08  4.45276781e+08]\n",
            " [ 1.50921173e+07 -6.64091383e+07  2.40635837e+08  1.01575962e+08]]\n",
            "current loss:  tensor(0.0424, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1128, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0427, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2025, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1816, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1089, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1462, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0796, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0801, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0838, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 0 12  2 14  4  5  7 15  3  9  6 13 11  1  8 10]\n",
            "best_MSE:  2.5299749466018904\n",
            "dlg results at epoch 530 - [[5.6 2.5 3.9 1.1]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.  2.  3.5 1. ]] [[6.10898054 2.7963912  5.15120881 1.79330172]\n",
            " [5.66830769 3.59811067 3.48327818 2.03066346]\n",
            " [6.40556879 3.24584555 2.73840067 0.9083165 ]\n",
            " [7.69291848 3.33392131 2.16051723 2.33944572]\n",
            " [6.12033558 3.00595802 4.88985924 1.83633906]\n",
            " [7.67988403 2.82835129 8.75086753 2.88738131]\n",
            " [6.22903369 3.33993269 3.72218876 1.53020426]\n",
            " [6.44850899 3.67458782 3.16977698 2.25278237]\n",
            " [5.77865719 3.59074341 1.72055788 1.69810046]\n",
            " [5.68889571 2.99667505 5.77285949 1.94264856]\n",
            " [4.86854813 3.47439709 1.50424845 0.96631634]\n",
            " [6.89055768 2.80699235 2.7204783  1.63890606]\n",
            " [6.71750942 4.30081047 3.36643796 1.04406166]\n",
            " [6.17497275 3.27848775 4.44456957 2.38894722]\n",
            " [5.58439289 2.87684382 3.9512874  0.96353037]\n",
            " [5.45708431 2.63471428 3.64661212 0.92287208]]\n",
            "current loss:  tensor(0.0524, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1114, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1209, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1248, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0583, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1380, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0423, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0601, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1129, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0533, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 6  4  0  1 15 12  3  5 14  8  2  7 10  9 13 11]\n",
            "best_MSE:  8.475390857177159\n",
            "dlg results at epoch 540 - [[6.7 3.  5.  1.7]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [5.  2.  3.5 1. ]\n",
            " [6.3 2.9 5.6 1.8]] [[ 7.35895138  2.88018025  5.03692966  1.49363572]\n",
            " [ 6.21136998  2.06117472 13.30824657  7.81341611]\n",
            " [ 7.50492162  3.41165017  2.78824379 -0.37208402]\n",
            " [ 5.049389    3.68622953 -2.53008014 -1.74065966]\n",
            " [ 5.43544165  2.82082756  3.00043513 -0.72259626]\n",
            " [ 4.22149053  3.19407033  6.29454833  1.87018817]\n",
            " [ 5.25346488  2.68763082  4.1008768   0.9212104 ]\n",
            " [ 5.42146936  2.86465402  4.34258502  2.19151445]\n",
            " [ 6.58609026  2.60199634  5.35506634  1.68324918]\n",
            " [ 6.21656948  3.45749342  5.73790698  1.10145755]\n",
            " [ 6.11712148  3.8688612   1.6958825   1.1813565 ]\n",
            " [ 4.80305437  2.6755936   0.41877147 -0.33052909]\n",
            " [ 5.94815844  3.15242937  4.70710778  1.77191327]\n",
            " [ 6.12895071  2.80748282  3.47956664  1.17134656]\n",
            " [ 6.74575791  1.69908079  0.41534059  2.10032878]\n",
            " [ 6.12265654  3.78069972  3.66196778  2.24091362]]\n",
            "current loss:  tensor(0.0770, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1022, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1004, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2105, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0717, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1555, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0895, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0483, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0516, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0651, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 4 13  1  3 10 12  7 14  5  6 11  8  2 15  9  0]\n",
            "best_MSE:  3.198297691051236\n",
            "dlg results at epoch 550 - [[6.4 3.2 4.5 1.5]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.  3.2 4.7 1.4]] [[ 5.99593817  3.19455815  6.45205853  1.0964765 ]\n",
            " [ 5.04174396  2.81518772  5.95734716  0.28913203]\n",
            " [ 5.58923757  2.85468829  3.25791154 -0.32815346]\n",
            " [ 5.21058027  3.36023092  4.05789064  0.71516586]\n",
            " [ 5.02563262  3.44311381  4.61790839  0.57377637]\n",
            " [ 5.78397236  3.30165478  4.94158276  1.80874216]\n",
            " [ 6.6257384   2.70865716  7.89433182  3.53679572]\n",
            " [ 6.69506164  1.97999444  2.54851573  1.00367665]\n",
            " [ 7.00700626  3.21449269  2.76467121 -0.32738929]\n",
            " [ 6.33795206  2.25122035  8.94763006  2.92973645]\n",
            " [ 5.30544113  3.36465418  2.27630292  1.08706048]\n",
            " [ 6.91485065  2.79901591  3.04171537  1.95269089]\n",
            " [ 6.22773249  3.49318861  6.2779558   1.74375053]\n",
            " [ 5.94120074  2.77833993  3.22624414  0.80998584]\n",
            " [ 5.22614332  2.78382208  5.79702585  1.65255631]\n",
            " [ 6.46491258  2.94922084  6.06584615  1.02307704]]\n",
            "current loss:  tensor(0.0378, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0955, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0698, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1453, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0201, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0232, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0219, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0958, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2616, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1304, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [12  5  7  1  0  4  8 11 14 15 13 10  6  2  3  9]\n",
            "best_MSE:  110985222360.92154\n",
            "dlg results at epoch 560 - [[6.2 2.9 4.3 1.3]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [5.2 3.5 1.5 0.2]] [[-2.37004527e+04  1.97992335e+03 -3.91993418e+04  2.41046380e+04]\n",
            " [-3.98466988e+04  3.14079226e+04  2.01230899e+04  4.09990269e+04]\n",
            " [ 2.96887521e+04 -1.50360281e+04 -5.19140533e+04  1.22139483e+04]\n",
            " [ 1.17363640e+04 -1.23897585e+04 -6.28770340e+04  6.67374661e+03]\n",
            " [-1.61665599e+05  8.45940860e+04 -5.21138316e+04  6.99527350e+04]\n",
            " [ 1.59688241e+04 -3.34797993e+04 -1.28454903e+04 -4.91669482e+02]\n",
            " [ 2.89394495e+04 -4.77609852e+04  1.85453744e+05 -1.09320944e+05]\n",
            " [ 1.07586710e+05  3.40669039e+03 -2.73037389e+05 -2.78521870e+05]\n",
            " [-6.02235777e+02 -2.06873041e+04  8.90021886e+04  6.11146194e+04]\n",
            " [ 7.72464313e+02 -3.18020718e+03  6.68323847e+04  3.32537499e+04]\n",
            " [ 6.35994086e+04 -1.57757711e+05  1.07155979e+06  5.38207483e+05]\n",
            " [ 4.76069180e+03  7.67805129e+03 -2.69625267e+04 -1.16766845e+04]\n",
            " [ 1.43205907e+03 -5.42559708e+03  1.01510452e+05  4.95028333e+04]\n",
            " [ 4.33329006e+04 -6.63171619e+04  5.31885352e+05  2.49488650e+05]\n",
            " [ 1.10235261e+04  4.11110380e+04 -8.14663545e+04  7.13159678e+04]\n",
            " [ 1.63859753e+04  4.71238186e+04 -4.30001881e+05 -2.31568450e+05]]\n",
            "current loss:  tensor(0.0486, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0238, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1298, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0704, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1450, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0651, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0912, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1631, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0581, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0876, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [14 12 15  9  2 10  7  8  6  4  3 11  1  0  5 13]\n",
            "best_MSE:  3.065394309689411\n",
            "dlg results at epoch 570 - [[5.5 2.3 4.  1.3]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [5.7 2.8 4.1 1.3]] [[ 5.08824594  2.65275206  3.01459979  0.85112563]\n",
            " [ 4.03114418  2.73657751  3.43559501  1.6541834 ]\n",
            " [ 5.92930913  3.83270247  3.82467693  2.03785656]\n",
            " [ 6.96824106  3.18317608  2.0653851   2.4327097 ]\n",
            " [ 6.16259858  3.19452248  1.73848853  2.10053463]\n",
            " [ 5.76059134  2.66847364  4.30619586  1.32232107]\n",
            " [ 5.63358775  2.52718571  5.01402939  1.12202094]\n",
            " [ 6.00069681  3.22843205  3.98357971  1.905343  ]\n",
            " [ 5.5879302   3.44816762  4.35376638  2.49560286]\n",
            " [ 6.12914241  2.52612772  5.10782087  1.21332684]\n",
            " [ 5.19883824  2.9615507   1.09465435  0.49511992]\n",
            " [ 4.79517867  3.06383999  4.55297901  1.38198708]\n",
            " [ 5.13431096  2.95629541  2.92442937 -0.2073891 ]\n",
            " [ 6.29865417  2.37237499  5.02514578  1.73030541]\n",
            " [ 5.74122761  3.64667267  2.66957872  0.40319006]\n",
            " [ 4.69290904  3.17503545  4.66928323  1.37521587]]\n",
            "current loss:  tensor(0.0188, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0570, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1222, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0327, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0915, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0891, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0521, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0992, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0935, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0953, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 2  8 12  0 15 13  7  5  3 14  6 11  9  4  1 10]\n",
            "best_MSE:  78345502640148.4\n",
            "dlg results at epoch 580 - [[4.9 3.  1.4 0.2]\n",
            " [5.1 3.5 1.4 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [5.7 4.4 1.5 0.4]] [[  -144769.29588691   -856633.54188993    422999.49105888\n",
            "    -789946.47235977]\n",
            " [   110253.44559447    444169.1577603   -4049576.1139015\n",
            "   -1951009.69047778]\n",
            " [  -374245.0808924     347905.91366632  -5322164.07095219\n",
            "   -2616174.71430586]\n",
            " [   994600.87961438    615566.33088856 -23340771.36217864\n",
            "  -11423582.69169839]\n",
            " [ -1123516.00698514  -1920573.22697142  -1174953.65785052\n",
            "     445903.16712682]\n",
            " [   354536.21898252    701553.85504761  -4758308.49654846\n",
            "   -2252506.81455858]\n",
            " [    71586.38433808  -2224136.35314272  22844086.79458182\n",
            "   11400055.89029367]\n",
            " [ -2021091.82144643   -631860.29315601    538885.9112431\n",
            "    -653050.14569653]\n",
            " [   447469.96729195    360726.19584476    295081.96347531\n",
            "      61182.25575331]\n",
            " [  2302804.01068876   1322766.20882727  -4550211.02200973\n",
            "   -2168788.30711745]\n",
            " [  -344905.80050409   -509590.0047525    -132345.80464267\n",
            "    -157308.61427071]\n",
            " [    96280.28231858    266491.94962765    258148.11347554\n",
            "     145754.78234528]\n",
            " [   503128.28640994    296811.33731252     37071.21274602\n",
            "     123158.50856135]\n",
            " [   -66287.92720657   -952306.25857464  12587504.43932959\n",
            "    6346708.91754262]\n",
            " [  -184782.00445188  -1020478.15453589  13375742.09245384\n",
            "    6745629.59399507]\n",
            " [   589380.36967042   1478886.01704221  -5314120.51541448\n",
            "   -2740524.62225771]]\n",
            "current loss:  tensor(0.0923, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0496, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0187, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0222, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1388, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1450, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0182, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1361, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1098, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1112, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 6 10 11  8  9 12 15 13 14  5  4  3  2  7  0  1]\n",
            "best_MSE:  5248743.412261869\n",
            "dlg results at epoch 590 - [[5.2 3.5 1.5 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.9 3.  5.1 1.8]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.6 3.1 1.5 0.2]] [[ 3.68403098e+01  8.71841764e+01 -1.52292987e+03 -7.77076459e+02]\n",
            " [-2.34222930e+02 -2.96910360e+02 -3.08597890e+03 -2.44340122e+03]\n",
            " [-8.85346096e+00  1.05288129e+02 -8.35518546e+02 -4.06854279e+02]\n",
            " [ 7.03865576e+01 -4.29796023e+02  2.46526781e+03  1.20137551e+03]\n",
            " [ 1.40823064e+00 -2.08052059e+01 -4.04202344e+03 -1.91711618e+03]\n",
            " [ 8.26675193e+00 -1.44716676e+02  1.21121143e+03  5.92223691e+02]\n",
            " [ 9.95150857e+00 -1.19364073e+02  1.03194530e+03  4.95920780e+02]\n",
            " [ 6.25375187e+01  1.44537487e+02 -1.84708117e+03 -9.15201692e+02]\n",
            " [-2.16048421e+00 -1.66436654e+02  2.61371430e+03  1.31869590e+03]\n",
            " [ 6.30122281e+01  7.97718007e+01 -1.94388211e+03 -8.29582515e+02]\n",
            " [-1.26391147e+01  1.01290913e+02 -6.68500854e+02 -4.21445348e+02]\n",
            " [-9.61763848e+01 -1.67264856e+02  2.76089730e+03  1.40937818e+03]\n",
            " [-1.78862589e-01 -1.24989833e+02  1.58881322e+03  7.97301102e+02]\n",
            " [ 2.26035268e+03 -1.80295811e+03 -1.58277431e+03 -5.92919529e+02]\n",
            " [-2.74102004e+01  1.32171252e+02 -9.40634241e+02 -5.04360021e+02]\n",
            " [ 1.53079613e+01  1.43388757e+01 -1.18040770e+03 -1.07615378e+03]]\n",
            "current loss:  tensor(0.1011, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1368, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0673, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1300, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0837, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0421, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0945, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0417, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1215, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0939, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 9  4 14  6 11  1  3  8 10 13  7  2 12  5 15  0]\n",
            "best_MSE:  8186026921994.942\n",
            "dlg results at epoch 600 - [[4.5 2.3 1.3 0.3]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [5.8 2.7 3.9 1.2]] [[-5.63564297e+05 -2.33765865e+05  4.56966546e+05 -1.77523893e+05]\n",
            " [-4.13764814e+05  2.15116852e+05 -1.95608387e+06 -2.60712924e+06]\n",
            " [ 9.38546831e+04  4.52511559e+05  1.68627903e+05 -1.46040461e+05]\n",
            " [-8.98201943e+04 -4.24176488e+04 -2.42770950e+06 -1.13198336e+06]\n",
            " [-1.53488145e+06 -8.93099410e+05  1.87671103e+06  1.55000937e+04]\n",
            " [-7.05072128e+03 -6.37418040e+04  8.80671209e+05  4.29512799e+05]\n",
            " [-3.93397564e+05 -2.20376084e+05  4.81431197e+05  1.08002035e+05]\n",
            " [ 1.19440571e+05  1.58645191e+05 -1.59509143e+06 -8.34523526e+05]\n",
            " [ 1.50407907e+06  1.47825634e+06 -7.47083673e+06  4.18647317e+06]\n",
            " [ 3.57669446e+04 -1.71290197e+05  1.62178768e+06  8.21223897e+05]\n",
            " [-1.65646628e+06  1.02982943e+06  9.10190435e+05  3.06823476e+04]\n",
            " [ 2.85828774e+04 -2.13177270e+05  1.38675175e+06  5.28699977e+05]\n",
            " [ 1.29043668e+04 -4.00977856e+04 -5.20375952e+05  2.96365009e+05]\n",
            " [-4.19912896e+05  3.21031568e+05 -2.30708894e+06 -8.50939819e+05]\n",
            " [ 2.83375389e+05 -4.98980983e+05  5.64921181e+06 -1.82002197e+06]\n",
            " [ 3.41773270e+05 -3.23949908e+05 -5.67570702e+05 -1.40655808e+05]]\n",
            "current loss:  tensor(0.0227, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0282, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1427, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1102, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0412, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0890, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0351, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1068, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1619, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0294, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [12  1 11 10  8  2  3 13 14  7 15  4  0  9  5  6]\n",
            "best_MSE:  18737111.627709895\n",
            "dlg results at epoch 610 - [[6.3 2.3 4.4 1.3]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [5.7 2.8 4.1 1.3]] [[ 3.37453865e+02 -6.91664862e+02 -3.20913160e+03 -2.12827882e+03]\n",
            " [-1.14871107e+01  1.43361192e+02 -2.08084609e+03 -8.79626525e+02]\n",
            " [ 1.86478737e+01  2.36911835e+02 -5.71420599e+03 -2.71119769e+03]\n",
            " [ 2.74538520e+02 -8.29541558e+02  4.59052784e+03  2.05902638e+03]\n",
            " [ 1.78918645e+02 -5.35163909e+02  3.25744335e+03  1.46087008e+03]\n",
            " [ 3.16328543e+01  5.05629089e+02 -9.82454630e+03 -4.85305331e+03]\n",
            " [ 2.51934538e+01  6.06818156e+02 -9.21868761e+03 -4.51860346e+03]\n",
            " [-1.45697327e+02  3.27549122e+02 -5.00523445e+03 -2.74377897e+03]\n",
            " [-7.17646008e+01  1.00386761e+02 -8.17196432e+02 -4.88121637e+02]\n",
            " [ 5.83496397e+01  7.40149340e+01 -9.18569205e+02 -4.61472534e+02]\n",
            " [-7.96035842e+00  2.32594982e+02 -3.28939389e+03 -1.80942733e+03]\n",
            " [ 4.49462354e+01 -5.79736161e+02  7.73898657e+03  3.73459636e+03]\n",
            " [-1.47547668e+03 -6.42242289e+02  2.92425505e+02 -5.72548601e+02]\n",
            " [-5.29452623e+00  2.38369965e+02 -2.14631603e+03 -1.02076354e+03]\n",
            " [ 1.07407786e+02 -2.63467132e+02  1.02868947e+03  4.66015348e+02]\n",
            " [ 1.42739900e+01  1.68019940e+02 -2.83846370e+03 -1.40774255e+03]]\n",
            "current loss:  tensor(0.0810, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0610, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0963, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0813, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1373, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1098, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0595, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0864, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0283, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0538, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 1  3 11  9 15  2  6  8  7 10  0  5 12 14  4 13]\n",
            "best_MSE:  362235874476079.3\n",
            "dlg results at epoch 620 - [[5.2 3.4 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.5 3.  5.2 2. ]] [[ 1.06026825e+06  1.08503198e+06 -1.22856386e+07 -4.70123850e+06]\n",
            " [ 5.13728508e+05  2.22268682e+05 -9.57256540e+06 -5.09416064e+06]\n",
            " [ 1.55268282e+06 -5.04884302e+05 -4.31767630e+06 -1.90111403e+06]\n",
            " [-4.28727302e+06  1.04565331e+07  7.10032884e+07 -1.40741130e+07]\n",
            " [ 7.27664689e+06  1.04397613e+06 -1.08623546e+07  4.61177949e+06]\n",
            " [ 8.37070515e+05 -2.98706926e+04 -5.93226514e+06 -2.51358962e+06]\n",
            " [ 6.51311775e+06 -5.47281361e+06  6.77214970e+06 -2.46893470e+06]\n",
            " [ 1.35434678e+05 -3.58277881e+06  2.69675968e+07  1.27419329e+07]\n",
            " [-9.47912225e+04 -1.52962683e+05 -3.54446660e+06 -1.51960085e+06]\n",
            " [-1.68523148e+07  1.24374732e+07  2.46590915e+07 -2.93723905e+06]\n",
            " [ 1.97593328e+05 -2.24447591e+06  2.13818091e+07  1.04547521e+07]\n",
            " [ 1.26098018e+06 -5.96632207e+03  8.25805898e+05  9.43552453e+05]\n",
            " [-9.34208033e+04 -1.18365649e+06  9.96555517e+06  4.32077657e+06]\n",
            " [-9.22530342e+04 -1.20539626e+06 -6.36851598e+06 -3.69434303e+06]\n",
            " [-7.44083068e+05  1.23442671e+05 -4.84271771e+05 -1.13725259e+06]\n",
            " [ 5.42801757e+05 -6.99570790e+05  8.80719608e+06  5.14594597e+06]]\n",
            "current loss:  tensor(0.1749, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0459, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1497, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0854, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0462, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0760, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0814, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0710, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1089, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0346, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [13  1 14  0 10 15  7  5  6 12  8 11  2  3  4  9]\n",
            "best_MSE:  284201.386702439\n",
            "dlg results at epoch 630 - [[6.9 3.1 5.1 2.3]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [6.  2.2 4.  1. ]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.7 3.8 1.7 0.3]] [[ 8.27601061e+00 -8.32343262e+01  8.26102913e+02  3.97069857e+02]\n",
            " [ 1.87509223e+01 -5.70480999e+01  8.54227444e+02  3.99891347e+02]\n",
            " [-1.38804087e+00 -2.44241418e+01  2.40518468e+02  1.19704625e+02]\n",
            " [ 7.79588103e+00  5.57990259e+00 -6.26401137e+01 -2.46416341e+01]\n",
            " [ 4.37925746e+00 -7.59837939e+01  1.16425744e+03  5.62736266e+02]\n",
            " [-6.94877294e+00  6.28975436e+01 -8.24331071e+02 -3.92224817e+02]\n",
            " [ 8.01822831e+00 -1.49239820e+01  2.83956279e+02  1.29488276e+02]\n",
            " [ 3.60461009e+01 -1.83912323e+02  1.30082603e+03  6.44205511e+02]\n",
            " [ 1.65474590e+01 -6.84287893e+00  9.27180896e+01  3.45752215e+01]\n",
            " [ 7.54013547e+00  2.10703217e+01 -9.94344673e+01 -4.98458188e+01]\n",
            " [-3.20475114e+00  2.48976354e+01 -2.28698242e+02 -1.03105041e+02]\n",
            " [ 6.00800783e+00  2.59447900e+00  5.20008924e+00  1.42048558e+00]\n",
            " [ 4.87123675e+00  3.23067615e+01 -4.63952091e+02 -2.24833914e+02]\n",
            " [-2.46420927e+00  3.52096775e+01 -4.65828116e+02 -2.24861921e+02]\n",
            " [ 1.94330981e+00 -1.00622686e+00  1.65029936e+02  7.60477898e+01]\n",
            " [ 5.18374059e+00  2.36122549e+01 -2.09611086e+02 -9.84132296e+01]]\n",
            "current loss:  tensor(0.0502, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1859, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1053, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0445, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0856, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0579, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0589, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0643, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0134, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 4  8 12  5  6 11  7  2  1 10 13 15  0  9  3 14]\n",
            "best_MSE:  438533902.59055156\n",
            "dlg results at epoch 640 - [[4.6 3.4 1.4 0.3]\n",
            " [5.9 3.  5.1 1.8]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.1 3.5 1.4 0.2]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [4.4 3.  1.3 0.2]] [[-2.41638300e+02  5.01438763e+02 -3.56289381e+03 -1.91469762e+03]\n",
            " [-7.82818087e+02 -1.82988311e+03  2.79441856e+04  1.40599450e+04]\n",
            " [-4.01343444e+02 -2.29448013e+03  2.82652803e+04  1.39240861e+04]\n",
            " [-4.35669773e+00 -3.93149486e+03  3.63634237e+04  1.77552813e+04]\n",
            " [-9.57869105e+02 -3.56038784e+03  4.98928905e+04  2.38553787e+04]\n",
            " [-4.96637409e+02 -2.65056561e+03  3.14817785e+04  1.49768495e+04]\n",
            " [-2.18245537e+02  2.29674067e+03 -2.35437486e+04 -1.19261723e+04]\n",
            " [-1.52169386e+02  2.75882743e+01  7.22769656e+02  2.98406632e+02]\n",
            " [ 1.77439309e+02  4.07280610e+02 -7.49815280e+03 -3.91743286e+03]\n",
            " [-8.35752332e+01  2.88535310e+02 -2.48766490e+03 -1.28779290e+03]\n",
            " [-3.50781550e+02  4.48164520e+03 -3.78090621e+04 -1.87103506e+04]\n",
            " [ 1.42999301e+02  3.82389291e+02 -1.42012028e+03 -4.68874417e+01]\n",
            " [-2.75868227e+03  4.66838804e+03  2.77094773e+03  2.39692082e+03]\n",
            " [-1.59178995e+02 -1.48476767e+03  1.60313998e+04  7.98141428e+03]\n",
            " [-2.00811507e+03  3.24495693e+03  3.07235306e+03  1.90627920e+03]\n",
            " [ 1.47160363e+02  2.81348996e+02 -4.12323222e+03 -2.02820434e+03]]\n",
            "current loss:  tensor(0.1161, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0155, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0641, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2292, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0878, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0931, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0962, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1164, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0573, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [15 14  1  4 12  7 10 13  2  6  8  0  5  9  3 11]\n",
            "best_MSE:  9111581051899.508\n",
            "dlg results at epoch 650 - [[6.  2.7 5.1 1.6]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.  3.3 1.4 0.2]] [[-1.89498653e+04 -6.49566139e+04  8.08023601e+05  4.07837201e+05]\n",
            " [ 4.70693942e+04 -1.28724967e+05 -7.61654358e+05 -6.21399309e+05]\n",
            " [-2.75480299e+04 -5.07224631e+04  8.62460552e+05  4.20100634e+05]\n",
            " [ 1.65004649e+04 -3.03212989e+04 -4.35672926e+04 -6.13170410e+04]\n",
            " [ 2.30237857e+03 -1.83667452e+04  3.66728251e+05  1.82533319e+05]\n",
            " [-2.42948014e+03  1.22852426e+04 -1.05805394e+05 -4.79788326e+04]\n",
            " [-5.75328962e+03 -3.76725778e+04  6.41226707e+05  3.24419651e+05]\n",
            " [ 8.69885870e+03 -7.92769036e+04  6.63907240e+05  3.21956608e+05]\n",
            " [ 6.30431511e+03 -1.16794270e+04  9.47863395e+04  4.32541092e+04]\n",
            " [-1.70730244e+05  4.18435024e+04  1.15340496e+06 -2.54426628e+05]\n",
            " [-2.45084893e+01 -2.54356301e+02 -7.89174384e+04 -2.92609944e+04]\n",
            " [ 7.56706759e+03 -3.66876022e+03  1.84811088e+04 -1.66643875e+03]\n",
            " [-4.85918765e+05 -2.19618702e+05  2.68951392e+06  1.27930877e+06]\n",
            " [-1.26130835e+04  6.98408825e+03 -8.95049685e+04 -4.07486153e+04]\n",
            " [-3.99619923e+05  4.82180754e+06  5.80731714e+06 -1.09345688e+06]\n",
            " [ 2.96071210e+03  4.66311864e+04 -4.64795553e+05 -2.19223041e+05]]\n",
            "current loss:  tensor(0.0794, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0838, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0817, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1057, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2893, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1847, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0520, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1086, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0539, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 6 11  1  8 10 14  2  5  9 15  7  3  4 12 13  0]\n",
            "best_MSE:  584464707.6167237\n",
            "dlg results at epoch 660 - [[5.2 3.5 1.5 0.2]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [5.  3.3 1.4 0.2]] [[ 3.68287286e+02  5.42557681e+02 -8.73519856e+03 -4.38224382e+03]\n",
            " [-2.09006359e+02 -5.67737149e+02  7.29421987e+03  3.97179851e+03]\n",
            " [-3.69404526e+02  3.33897292e+02  3.14320215e+03  1.90551190e+03]\n",
            " [-1.85993202e+02  1.22892995e+02  6.77402235e+02 -1.39462181e+03]\n",
            " [-1.97757120e+02 -4.52189797e+03  1.17031318e+04  8.20942455e+02]\n",
            " [ 2.44991106e+02  1.04042213e+03 -1.22263562e+04 -6.36675942e+03]\n",
            " [-4.83413749e+02  6.18798768e+02 -1.89058475e+03 -1.23937159e+03]\n",
            " [ 1.39405382e+02 -2.76326773e+02  5.30773499e+03  4.00669058e+03]\n",
            " [-4.79937361e+01  3.42798872e+02 -7.66323624e+02 -3.45516472e+02]\n",
            " [-1.15027466e+02 -1.41110076e+03  1.36251914e+04  6.60045778e+03]\n",
            " [ 8.09087410e+02 -2.07441101e+04  6.68643554e+03 -1.88962809e+04]\n",
            " [-1.55019305e+02 -7.32251849e+02  9.56786132e+03  4.74559182e+03]\n",
            " [ 2.45663653e+02  2.83155720e+03 -3.11494600e+04 -1.54937304e+04]\n",
            " [ 4.24633204e+03 -2.93487580e+04  5.04532305e+03 -1.25643957e+04]\n",
            " [-2.85199609e+01 -1.03838028e+03  1.05095652e+04  5.79601488e+03]\n",
            " [ 3.10303347e+02  4.08075908e+02 -6.51292174e+03 -3.13976319e+03]]\n",
            "current loss:  tensor(0.0165, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1248, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0271, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1207, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0898, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0509, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1552, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0177, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0470, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1092, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [15 10  6  3  0 13  4  2  1 14  8  5  7 11  9 12]\n",
            "best_MSE:  832273715946.6614\n",
            "dlg results at epoch 670 - [[4.9 2.4 3.3 1. ]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [6.  3.  4.8 1.8]] [[-7.05179293e+05 -6.53095796e+04  2.94853846e+05  1.05135810e+05]\n",
            " [ 2.42283741e+02  2.56554560e+04 -3.99776913e+05 -1.95678172e+05]\n",
            " [ 5.27029923e+03  8.78640670e+04 -1.05298033e+06 -5.16956767e+05]\n",
            " [ 8.72591847e+04  2.04696650e+05 -1.34693585e+06  8.41146741e+05]\n",
            " [-5.63351463e+02  9.52146400e+04 -1.12900869e+06 -5.61502483e+05]\n",
            " [ 2.28020190e+04  3.30935645e+03 -4.01743900e+05 -2.07986974e+05]\n",
            " [ 1.48649563e+04  1.28337845e+05 -1.25276242e+06 -6.21049803e+05]\n",
            " [-3.51423202e+04 -1.39957572e+05  1.47747927e+06  7.41582043e+05]\n",
            " [-2.39258905e+04 -2.12031293e+03  2.63078431e+05  1.19736900e+05]\n",
            " [-6.74944802e+03 -8.82712944e+04  7.47907568e+05  3.69472676e+05]\n",
            " [ 1.05988347e+05  3.15196138e+03  2.90083057e+05  3.14710185e+05]\n",
            " [-3.10304966e+05 -2.03342531e+05  1.58968724e+06  2.34720843e+05]\n",
            " [ 2.09100255e+04  8.85478163e+04 -1.32842504e+06 -6.26167140e+05]\n",
            " [-1.21574197e+04 -3.13285656e+04  2.64602267e+05  1.38254361e+05]\n",
            " [-4.39918740e+03  1.40475423e+05 -1.36501416e+06 -6.71654021e+05]\n",
            " [ 3.55250281e+02 -1.03141297e+05  7.70993093e+05  3.74680701e+05]]\n",
            "current loss:  tensor(0.0310, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0591, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0328, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0980, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0918, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1515, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0196, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0770, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1282, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1444, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 6  8  0 11  3  4 13 10  2  9 14  7  1  5 12 15]\n",
            "best_MSE:  20521.139916786302\n",
            "dlg results at epoch 680 - [[5.  3.3 1.4 0.2]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [5.4 3.7 1.5 0.2]] [[  12.85396784   10.03243707 -147.28166843  -76.59536642]\n",
            " [   6.83187483  -13.98150987  163.65705289   83.04994272]\n",
            " [   7.81969871   18.96227747 -144.20880545  -70.81116649]\n",
            " [   2.9781457   -17.33814593  209.43017684  101.33854351]\n",
            " [   7.227025     21.63136187 -173.2314287   -84.63386056]\n",
            " [   2.75246439   -7.92965787  102.84990497   52.99009385]\n",
            " [   8.66924132   22.91698593 -173.63283571  -85.28315108]\n",
            " [   7.34544479   -9.01550549  133.94224954   64.70115633]\n",
            " [   5.86966345   -7.21239854  141.55312988   68.98621062]\n",
            " [   4.75487849   -3.04943111   57.31629767   27.59340098]\n",
            " [   5.34818215  -17.4168057   181.86925819   90.77788746]\n",
            " [  -0.99687326   -9.37123183  217.82303841  107.45945017]\n",
            " [   4.18814962  -10.57027249  188.71113753   92.55048814]\n",
            " [   3.38680591   -6.47375373   83.81504618   37.87969782]\n",
            " [  -3.05893094    7.25004115  101.33803791   53.75224977]\n",
            " [  10.31429055   23.43878817 -259.05843214 -130.69140272]]\n",
            "current loss:  tensor(0.0364, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0677, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0536, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0364, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1457, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0196, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0395, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0702, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0838, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0149, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 2  8  3 13  6  4  9 15 11  5  0 14 12  1 10  7]\n",
            "best_MSE:  41836008.586731344\n",
            "dlg results at epoch 690 - [[6.7 3.  5.2 2.3]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [7.9 3.8 6.4 2. ]] [[-5.81871062e+01 -1.69036876e+02  1.51737287e+03  8.12432172e+02]\n",
            " [-4.56790302e+01 -2.09965367e+02  1.32992535e+03  6.59861420e+02]\n",
            " [ 2.00282197e+01  3.45836275e+01 -1.19092249e+02 -9.91584554e+01]\n",
            " [ 7.75586493e+03 -9.00661824e+02  5.81210149e+03 -1.49070706e+03]\n",
            " [ 2.99402286e+01  1.57220755e+02 -1.45200110e+03 -7.22651187e+02]\n",
            " [-1.71136141e+02  4.15281684e+02 -8.64707083e+01  1.59702565e+02]\n",
            " [ 4.10552198e+01  4.38923918e+01 -6.26372277e+01 -6.33952491e+01]\n",
            " [-1.51376681e+04  2.59888919e+03 -9.44660174e+03  3.66576553e+03]\n",
            " [ 3.60978050e+01  5.88903052e+01 -8.43986967e+02 -4.46274694e+02]\n",
            " [-1.97595281e+00 -3.51664669e+01  4.61352054e+02  2.36484936e+02]\n",
            " [-1.27545409e+02 -7.96407977e+01  4.14057332e+02  2.30668771e+02]\n",
            " [ 5.63427878e+01 -4.18653318e+01  2.21914762e+02  2.84137922e+01]\n",
            " [-2.04345921e+01  1.47157583e+00 -4.29169981e+02 -1.99565301e+02]\n",
            " [ 1.14569336e+02  3.72494324e+02 -8.26875355e+02 -4.28158594e+02]\n",
            " [ 4.88396635e+03 -1.38026961e+02  2.88474844e+03 -1.83307555e+03]\n",
            " [ 7.32954443e+03 -9.36342716e+01  4.42041760e+03 -4.34112935e+02]]\n",
            "current loss:  tensor(0.0698, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0533, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1427, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1201, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0156, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1123, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1703, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1421, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0182, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0864, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 1  9 11  3  5  4  0 12  6  7 13 10 14  8  2 15]\n",
            "best_MSE:  48842131.59296507\n",
            "dlg results at epoch 700 - [[6.3 2.5 4.9 1.5]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.7 4.9 1.8]] [[ 1.43712378e+01 -3.07937483e+01  3.49458402e+02  1.74043861e+02]\n",
            " [ 2.58049069e+01  2.79761741e+02 -2.53168093e+03 -1.24504295e+03]\n",
            " [ 3.20028805e+01  1.90165049e+02 -2.18836690e+03 -1.08188282e+03]\n",
            " [-1.42661818e+03  7.03760480e+03  3.63635353e+03  1.01284236e+04]\n",
            " [ 1.96551067e+01  5.41477712e+01 -2.38325325e+02 -1.09657251e+02]\n",
            " [ 1.04814498e+01 -5.41977386e+00  1.01243492e+02  5.03287875e+01]\n",
            " [-9.53372806e+03 -3.71771630e+03  3.63292793e+03  2.22651116e+03]\n",
            " [-4.09347600e+00 -1.14636865e+01 -1.59298348e+02 -7.63979838e+01]\n",
            " [-1.56355408e+02 -1.21454602e+03  9.86970564e+03  4.79085362e+03]\n",
            " [-1.41933911e+01 -1.82252992e+01 -1.92498884e+02 -1.04673808e+02]\n",
            " [ 4.27654035e+01  4.10657079e+02 -4.81522740e+03 -2.37810438e+03]\n",
            " [ 4.12192907e-01 -5.06533761e+00  2.62036643e+02  1.32035535e+02]\n",
            " [-2.70539072e+00 -7.84085554e+00 -2.38160677e+02 -1.24600566e+02]\n",
            " [ 2.59045593e+01  2.58424723e+02 -3.12314674e+03 -1.54152950e+03]\n",
            " [ 1.31063689e+01 -1.62130596e+01  2.15860072e+02  1.06068180e+02]\n",
            " [ 1.88552836e+01 -5.54557413e+01  7.58420999e+02  3.76395984e+02]]\n",
            "current loss:  tensor(0.0887, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0311, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0781, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0435, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0521, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0839, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0881, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0088, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0512, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0623, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 9 10 12  4  3 13 11  5  2  0  1  8  6  7 15 14]\n",
            "best_MSE:  1933.5923002655593\n",
            "dlg results at epoch 710 - [[6.9 3.1 5.1 2.3]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.2 2. ]] [[  5.17182693   3.45171192  13.36874991   5.43830729]\n",
            " [  9.05688975   8.29655019 -84.90122894 -44.03045962]\n",
            " [  5.65459821   2.4036398   26.15519282  12.76688408]\n",
            " [ -0.92532794  -5.55187991  93.47444592  47.88330081]\n",
            " [  1.27014535  -2.00498315  40.17382312  20.88243308]\n",
            " [  7.52754572   7.25113031 -53.10779798 -25.58175897]\n",
            " [  5.16088412   0.76589726  26.72354569  12.93184172]\n",
            " [  9.49255074   8.92377634 -46.31878587 -24.43767307]\n",
            " [  7.77881482   5.18922868 -23.10601526 -13.71157035]\n",
            " [  9.42117503   4.60916377 -23.37951775 -13.70532517]\n",
            " [  7.12931436   7.54413657 -38.48071136 -22.50410313]\n",
            " [  5.43454675   1.21217547  20.01907449   9.02172453]\n",
            " [  2.03891898  -2.34616555  98.11259354  46.86953785]\n",
            " [  7.61396684   7.84227873 -45.70866507 -21.9645134 ]\n",
            " [  7.09005174   4.71179581 -18.30963678 -12.60842446]\n",
            " [  6.69400529   3.47122862 -18.66265655  -9.92953741]]\n",
            "current loss:  tensor(0.0173, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0829, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0108, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0188, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0627, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0540, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1417, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0316, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0713, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0357, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 1  9  6  4  2 13 15  0 11  8  5 14 12  7 10  3]\n",
            "best_MSE:  3442188.480463592\n",
            "dlg results at epoch 720 - [[6.5 3.2 5.1 2. ]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [6.  2.9 4.5 1.5]] [[ 3.23581208e+02 -2.46010355e+02  5.28624883e+02  6.93770910e+02]\n",
            " [ 1.96728819e+01  5.66860196e+02 -4.82464468e+03 -2.39999117e+03]\n",
            " [-5.17263494e+01 -6.73312298e+01  7.26100701e+02  2.41821494e+02]\n",
            " [-1.99172345e+01  1.08552183e+02 -3.99321321e+02 -1.89447222e+02]\n",
            " [-9.55926017e-01 -2.38290360e+02  2.32809078e+03  1.15002791e+03]\n",
            " [ 1.02582432e+02 -2.03050096e+02  1.40415300e+03  7.17788168e+02]\n",
            " [-9.36130294e+02 -1.76901268e+02  3.35636087e+03 -1.77911475e+03]\n",
            " [ 1.57733326e+02  6.37962008e+01 -1.43407223e+03 -5.73979609e+02]\n",
            " [-2.59884963e+01 -1.55114739e+02  1.90520108e+03  1.02820751e+03]\n",
            " [ 1.14567460e+02 -1.36189465e+02  1.24657498e+03  7.26523196e+02]\n",
            " [-2.18026669e+01  2.56887130e+02 -1.30526203e+03 -6.32813083e+02]\n",
            " [-2.46735634e+02  3.39044388e+02 -1.18376780e+03 -7.63034248e+02]\n",
            " [-2.25198092e+01 -3.15983491e+01  8.29608942e+02  3.70511125e+02]\n",
            " [-1.94872835e+02  4.11303472e+02 -2.15848688e+03 -1.38547007e+03]\n",
            " [ 7.89506389e+01 -1.54274711e+02  7.22420868e+02  4.61829944e+02]\n",
            " [ 1.27778843e+01 -1.24361695e+02  9.38799326e+02  4.66605798e+02]]\n",
            "current loss:  tensor(0.0388, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1208, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0267, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0388, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0421, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0350, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0395, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0543, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0160, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1094, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [11  3  5  8 12 14  7 13 10  9  4  1  0 15  2  6]\n",
            "best_MSE:  698642593.8027453\n",
            "dlg results at epoch 730 - [[5.  3.6 1.4 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [5.8 4.  1.2 0.2]] [[ 9.17429714e+02  1.59876166e+03 -2.91164136e+04 -1.40148566e+04]\n",
            " [ 4.16885487e+03 -2.93768411e+02 -2.79243226e+03  6.93300229e+02]\n",
            " [ 2.18594399e+03 -1.04994828e+03 -1.03864173e+04 -6.18758510e+03]\n",
            " [-4.82625874e+02 -1.15700735e+03  1.62463272e+04  9.33379031e+03]\n",
            " [-6.62437587e+02 -1.68191856e+03  3.02829405e+04  1.49033418e+04]\n",
            " [ 1.04041744e+03 -2.95984691e+03  1.17652024e+04  7.58571310e+03]\n",
            " [-1.73029560e+03 -3.43902151e+03  4.32407796e+04  2.23485714e+04]\n",
            " [-1.46999324e+03 -5.38191375e+03  6.61252280e+04  3.16181524e+04]\n",
            " [ 5.23525960e+02  1.82135571e+03 -2.53172108e+04 -1.22326934e+04]\n",
            " [ 1.78713315e+02  2.16195199e+02 -1.38130904e+04 -5.42194476e+03]\n",
            " [-2.97744306e+02 -3.26151797e+03  2.84113813e+04  1.46444483e+04]\n",
            " [-1.33147147e+03 -1.98873435e+03  3.69872046e+04  1.89598126e+04]\n",
            " [-8.31366244e+02 -3.63351184e+03 -7.48672526e+03 -3.00456739e+03]\n",
            " [-7.05258711e-03 -1.34434804e+03  4.07294088e+03  2.75770712e+03]\n",
            " [-4.89401641e+01 -2.57578689e+03  1.43042561e+04  6.99147025e+03]\n",
            " [ 8.59716854e+02  4.61549724e+03 -4.61270366e+04 -2.33111901e+04]]\n",
            "current loss:  tensor(0.0913, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0559, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0146, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0124, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1054, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0713, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0547, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0770, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1356, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0579, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [10 11  1  7 15  0 12 13  3  5  2  8 14  6  4  9]\n",
            "best_MSE:  26235446.965113517\n",
            "dlg results at epoch 740 - [[5.8 4.  1.2 0.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [6.7 3.  5.  1.7]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [7.7 3.8 6.7 2.2]] [[    88.73978945   1260.71314443 -11908.47278948  -5735.0583085 ]\n",
            " [    42.17156337    -50.61362271    132.40361664    101.12101983]\n",
            " [  2882.50110422   -376.2581324    1423.53458272   -517.72669765]\n",
            " [   -44.85056806   -203.13295304   1928.52134929    894.99106403]\n",
            " [   -50.49036196   -161.33936464   3119.26011963   1344.01290027]\n",
            " [   100.83637968   1043.46163167  -9654.3334067   -4592.72467707]\n",
            " [  -189.98573031  -1195.75541225  12696.15906638   5959.14737676]\n",
            " [    36.77566      -251.57757116   2082.7739651    1093.92731747]\n",
            " [  -509.70063285    -59.0361982      15.11309903    -67.99748344]\n",
            " [    41.69452421     14.03279328     67.21940881     24.9050085 ]\n",
            " [   351.32380319   -128.47918696  -1524.68734153   -836.64296423]\n",
            " [    66.80448224    579.6680012   -6687.91672729  -3356.9903981 ]\n",
            " [   582.87345469     14.02672481  -2100.8868038    -973.13734301]\n",
            " [  2480.8310356    -338.78549339    168.05729465   -364.01568731]\n",
            " [   -34.55278229   -163.50654084   3060.60551409   1350.02923559]\n",
            " [  -159.38232278   -450.79707813   6260.75167846   3041.52335702]]\n",
            "current loss:  tensor(0.1465, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0885, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0171, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0342, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0883, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1012, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1277, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0697, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1303, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0147, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [11  5  0  8 14  7  1 12 10 13  3  6  2  4  9 15]\n",
            "best_MSE:  116432.3463267983\n",
            "dlg results at epoch 750 - [[4.7 3.2 1.3 0.2]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.4 3.4 1.7 0.2]] [[ 3.03740025e+01  4.76281300e+01 -6.67844997e+02 -3.15034176e+02]\n",
            " [ 3.45665252e+01  4.82196517e+01 -6.66427724e+02 -3.16809559e+02]\n",
            " [-1.32847062e+01 -1.40730755e+01  2.87506981e+02  1.37007872e+02]\n",
            " [ 7.71816587e+00  7.79150419e+00 -4.52370816e+01 -2.16886414e+01]\n",
            " [ 9.53798939e+00  9.45719932e+00 -7.93541838e+01 -3.99799142e+01]\n",
            " [ 3.69561406e+00 -2.67633041e+00 -1.72159222e+01 -2.21794136e+00]\n",
            " [ 4.27894847e+01  7.04731018e+01 -1.00255970e+03 -4.70245908e+02]\n",
            " [ 2.31236852e+01  5.89236271e+01 -6.01330471e+02 -3.03662434e+02]\n",
            " [-1.50642623e+00 -6.60338235e+00  7.04460009e+01  2.88859803e+01]\n",
            " [ 6.01589324e+00  1.82357981e+00  2.36578423e+01  1.04938927e+01]\n",
            " [ 4.22862803e-01 -6.24127102e+00  7.99677995e+01  2.86840594e+01]\n",
            " [-3.74896031e+00 -7.42545950e+00  1.41256209e+02  6.54871975e+01]\n",
            " [ 4.15955600e+00  1.00309233e+01 -3.60423792e+01 -1.88614320e+01]\n",
            " [ 5.60309135e+00 -7.52422881e-01  8.53067439e+00  5.15619847e+00]\n",
            " [-1.72231599e+01 -2.13040883e+00  2.16302554e+02  8.77461649e+01]\n",
            " [ 1.60975958e+01  3.14198203e+01 -2.78980215e+02 -1.30397708e+02]]\n",
            "current loss:  tensor(0.0405, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0400, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0990, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1220, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0104, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0370, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0422, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0617, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0540, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1335, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [11  4  7 10 15  2 12  0  1  3  5  9  6  8 14 13]\n",
            "best_MSE:  12.705788052393748\n",
            "dlg results at epoch 760 - [[5.5 2.4 3.8 1.1]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [6.  3.  4.8 1.8]] [[ 4.90351769e+00  2.70643879e+00  1.31332521e+00  1.89512679e+00]\n",
            " [ 6.56329734e+00  2.98199973e+00  4.11720859e+00  1.05640956e+00]\n",
            " [ 5.17218298e+00  2.83344414e+00  6.79196595e+00  1.58843418e+00]\n",
            " [ 6.48203196e+00  2.64910766e+00  7.08367069e+00  1.41889848e+00]\n",
            " [ 5.88774884e+00  2.34191416e+00  4.04879514e+00  1.36046507e+00]\n",
            " [ 6.44215666e+00  3.44522567e+00  5.90347907e+00  1.27013691e+00]\n",
            " [ 6.03248342e+00  2.98882403e+00  4.94823060e+00  1.74197913e+00]\n",
            " [ 7.39198209e+00  3.72225367e+00 -7.34701092e-01 -9.24337086e-01]\n",
            " [ 6.38652896e+00  3.37687138e+00 -1.08392217e+01 -4.66978770e+00]\n",
            " [ 7.01991989e+00  2.65002937e+00  3.04331881e+00  5.93093697e-01]\n",
            " [ 5.19648992e+00  3.28478003e+00  2.09185636e+00  1.30502369e-02]\n",
            " [ 5.86642655e+00  3.07987281e+00  5.10984871e+00  1.35777204e+00]\n",
            " [ 5.64427013e+00  2.66976691e+00  1.48936878e+01  7.67514686e+00]\n",
            " [ 5.64286793e+00  3.18060036e+00  2.14881714e+00  4.32194301e-01]\n",
            " [ 6.10378190e+00  3.53780380e+00  1.63045138e+00 -7.70967094e-01]\n",
            " [ 6.05770941e+00  3.11726044e+00  4.28522197e+00  2.30290396e+00]]\n",
            "current loss:  tensor(0.0580, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1051, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0205, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0338, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0070, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0268, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0101, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0218, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0234, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1191, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [13  9  1  0  3 10  6 11 14  8  4 12  7  5  2 15]\n",
            "best_MSE:  2582286086582190.0\n",
            "dlg results at epoch 770 - [[5.5 2.3 4.  1.3]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.  2.2 4.  1. ]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.9 3.2 4.8 1.8]] [[-6.11719459e+06 -2.22304381e+06  4.76768264e+06 -3.10666019e+06]\n",
            " [ 7.01582597e+03 -1.79207392e+06  1.35714907e+07  6.65323806e+06]\n",
            " [ 4.94627747e+06  3.69837951e+06 -3.54466466e+07 -1.73046376e+07]\n",
            " [ 3.91448129e+05 -1.47480783e+05 -1.69969559e+06  4.74467373e+05]\n",
            " [ 2.34035770e+06  4.00657194e+06 -7.62692546e+07 -3.70011382e+07]\n",
            " [ 1.29983629e+06 -4.70248394e+06  3.09390222e+07  1.58487042e+07]\n",
            " [-3.11013754e+06 -2.12309497e+06  1.10413841e+07  5.27979013e+06]\n",
            " [-3.57790043e+05 -1.76189561e+06  2.01229608e+07  8.72115633e+06]\n",
            " [-1.25355564e+06 -1.21671962e+06  2.74251316e+07  1.37956729e+07]\n",
            " [-7.43564469e+05  1.10945022e+06 -2.79263730e+07 -1.43401042e+07]\n",
            " [ 6.49982811e+05  1.63185993e+06 -1.87188873e+07 -8.79279295e+06]\n",
            " [-4.12370986e+06 -5.31843959e+06  1.89108269e+08  9.59417290e+07]\n",
            " [ 1.20109944e+07 -6.21831974e+06  9.55406399e+06  1.05349726e+07]\n",
            " [ 5.36437016e+06 -2.27922249e+06 -2.43947934e+07 -1.10342509e+07]\n",
            " [ 3.26914726e+05  3.01327975e+06 -3.37735624e+07 -1.62066569e+07]\n",
            " [-3.98519416e+07  8.21532698e+06  4.16252906e+07  4.80347995e+06]]\n",
            "current loss:  tensor(0.1370, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0151, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0187, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0208, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0095, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0256, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0892, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0132, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0461, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1113, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 6 13  1  0 11  7  3 12  5  2 15  9  4 10 14  8]\n",
            "best_MSE:  1747398235.248992\n",
            "dlg results at epoch 780 - [[6.5 2.8 4.6 1.5]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [6.7 3.  5.  1.7]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.7 3.8 1.7 0.3]] [[ 1.16844821e+02 -1.94032064e+03  2.04395180e+04  8.66946879e+03]\n",
            " [-2.14922688e+03  8.43646586e+02 -3.66116314e+03 -2.21876052e+03]\n",
            " [-3.37319158e+04  1.70854660e+04 -1.31219762e+04 -1.89758068e+04]\n",
            " [ 3.02628527e+03  4.74672923e+03 -7.98403352e+04 -3.94302073e+04]\n",
            " [-6.07422925e+02 -1.23672474e+03  1.74034584e+04  8.04407409e+03]\n",
            " [-4.22613162e+02  1.25232655e+03 -6.01938058e+02  3.93046834e+02]\n",
            " [-1.02099075e+03 -2.58253744e+03  3.11413750e+04  1.50639589e+04]\n",
            " [-2.20211143e+02 -6.73750129e+02  1.09050299e+04  4.77880204e+03]\n",
            " [-4.92011653e+03  2.59125370e+03 -7.68018840e+03 -1.00102146e+03]\n",
            " [-8.78552835e+02  2.84720427e+03 -2.15449196e+04 -9.97824099e+03]\n",
            " [-2.17703132e+04  3.92776417e+02  1.65292567e+05  5.98660942e+04]\n",
            " [-5.70411154e+02 -2.42884378e+03  2.95027994e+04  1.38665350e+04]\n",
            " [-1.77629910e+03 -2.47766432e+03  3.24506740e+04  1.61532305e+04]\n",
            " [-2.11915774e+01  1.02630590e+03  9.73937229e+03  3.28072304e+03]\n",
            " [ 4.09743136e+02 -8.19334119e+02  6.31540403e+03  3.00284877e+03]\n",
            " [-1.28169398e+03  2.31514523e+03 -8.83020552e+03 -2.02597071e+03]]\n",
            "current loss:  tensor(0.0548, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0362, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0597, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1472, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0636, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0991, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0223, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1168, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0555, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0411, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 0  4 10 15 14  7  5  6 11  2 13  3  8 12  9  1]\n",
            "best_MSE:  10874006.123166705\n",
            "dlg results at epoch 790 - [[6.7 3.3 5.7 2.5]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.3 2.3 4.4 1.3]] [[-7.72616330e+01 -9.36913811e-01  5.91144855e+03  2.83372554e+03]\n",
            " [-2.77079107e+01 -1.18806795e+02  1.27353916e+03  6.24642637e+02]\n",
            " [-1.54044436e+02  4.43886734e+02 -3.45801361e+03 -1.70955261e+03]\n",
            " [ 3.41650087e+02 -5.37229323e+02 -3.91278713e+03 -2.46625728e+03]\n",
            " [ 9.45587642e+01  1.24293907e+02 -2.29041255e+03 -1.14971274e+03]\n",
            " [-1.66891650e+02 -9.93220552e+01  2.54355291e+03  1.22568057e+03]\n",
            " [-1.88906415e+03  2.06793548e+03  4.96449785e+03 -9.67990221e+02]\n",
            " [-3.52583799e+01  5.91599428e+01 -2.01579537e+02 -9.55907366e+01]\n",
            " [-2.76504295e+01 -1.29038123e+02  1.30645915e+03  6.39987046e+02]\n",
            " [-1.04284067e+02  1.41609615e+02  4.73694192e+02  2.78727931e+02]\n",
            " [-4.59821902e+01 -2.37283319e+02  2.34051034e+03  1.15534177e+03]\n",
            " [-8.50468312e+01 -9.18860949e+01  5.94546857e+02  1.68777145e+02]\n",
            " [-2.39848683e+01  3.06553290e+01  1.96426007e+02  1.11091649e+02]\n",
            " [-1.00183796e+03 -3.33370507e+03 -1.70273991e+03 -1.10409576e+03]\n",
            " [-5.48179426e+00 -1.42407197e+02  1.31287318e+03  6.41087544e+02]\n",
            " [ 4.29469519e+02 -5.60581988e+02  1.66197528e+03  5.32352558e+00]]\n",
            "current loss:  tensor(0.0623, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0999, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0196, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0503, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1014, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1098, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0765, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0215, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0574, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0188, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 9  1  2 15  3  6  8  7 10  0  5 11 13 12 14  4]\n",
            "best_MSE:  7944014.408300172\n",
            "dlg results at epoch 800 - [[6.3 2.9 5.6 1.8]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.3 2.3 4.4 1.3]] [[-1.18347841e+01 -1.46416921e+02  1.47041576e+03  7.13942642e+02]\n",
            " [ 1.47448102e+02 -1.55437567e+03  9.32716574e+03  4.39718372e+03]\n",
            " [ 2.18306132e+01  1.22447104e+02 -1.04932276e+03 -5.30823652e+02]\n",
            " [-1.26625735e+02  9.56588758e+01  2.74261167e+02  2.53928423e+02]\n",
            " [-1.26062370e+02  2.06551257e+02 -1.16836270e+03 -5.22317496e+02]\n",
            " [ 3.41655168e+01  1.68124274e+02 -1.56202109e+03 -7.69192423e+02]\n",
            " [ 4.24865042e+01  2.41035372e+02 -1.73682235e+03 -8.73741968e+02]\n",
            " [-3.00710561e+00 -1.75382464e+01  1.98596765e+02  9.31646202e+01]\n",
            " [-3.81300722e+02 -2.17582381e+02  5.78707337e+03  2.84257050e+03]\n",
            " [ 4.87983823e+01  1.89161690e+01 -3.56234070e+02 -1.85864578e+02]\n",
            " [-2.58116042e+02  1.34732935e+02  1.62669321e+02  2.17813255e+02]\n",
            " [ 3.57936376e+01  2.61506883e+02 -2.30724566e+03 -1.13094410e+03]\n",
            " [-2.47681117e+01 -4.81818910e+02  3.87086671e+03  1.93015017e+03]\n",
            " [ 4.31195512e+00 -4.33556731e+01  3.66644404e+02  1.63383091e+02]\n",
            " [-1.04719322e+02 -8.80712579e+01  1.16400938e+03  5.96734922e+02]\n",
            " [-3.18947665e+01 -3.25632358e+01  7.91168315e+02  3.82213030e+02]]\n",
            "current loss:  tensor(0.0324, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2312, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0873, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0860, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0897, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0194, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0268, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0270, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0342, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0120, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [12 11  6  2  7 15  9  8 13 14  3  4  1  0  5 10]\n",
            "best_MSE:  396658387.92187023\n",
            "dlg results at epoch 810 - [[5.6 2.8 4.9 2. ]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  2.  3.5 1. ]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.8 5.1 1.5]] [[-1.71071237e+02 -2.18669127e+03  2.11509736e+04  1.02391622e+04]\n",
            " [ 8.17419911e+02 -1.32909582e+03  1.07215888e+04  4.16497113e+03]\n",
            " [ 1.51393093e+03  5.24135543e+01 -2.01926664e+04 -1.26729635e+04]\n",
            " [ 8.90859989e+02  4.10890776e+02 -8.47212985e+03 -5.64674849e+03]\n",
            " [ 2.09224449e+03  2.05308299e+03 -2.60528650e+04 -1.36806305e+04]\n",
            " [-1.59566501e+03  2.37819400e+03 -2.54516385e+04 -8.67630142e+03]\n",
            " [-3.61619691e+03  1.10149240e+03 -3.79573479e+03  8.68499751e+02]\n",
            " [ 1.75727472e+03  5.87731002e+00  4.62908661e+02  7.72308123e+02]\n",
            " [-3.75415149e+01 -2.24234312e+02 -6.54863164e+02 -1.97476773e+02]\n",
            " [ 2.10910675e+03  3.87642164e+03 -5.21087733e+04 -2.57751597e+04]\n",
            " [-4.98755912e+03  4.91498112e+02 -4.66833048e+03  1.46446925e+03]\n",
            " [ 4.65058500e+03 -8.46919375e+02 -8.39081328e+02  4.30844232e+02]\n",
            " [ 7.53377168e+01 -5.01041808e+02  5.65542991e+03  3.04401053e+03]\n",
            " [ 2.73998289e+03  1.29087660e+03 -4.37487381e+04 -2.39951405e+04]\n",
            " [-8.61959867e+02 -3.06599591e+03  2.74359171e+04  1.27108140e+04]\n",
            " [-2.93933805e+01 -2.11529170e+02  2.46551136e+03  9.74250504e+02]]\n",
            "current loss:  tensor(0.0995, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0413, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0912, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0555, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1788, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0261, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0825, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0253, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1713, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0758, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [13  8 10  1 15  9  7 14 11  6 12  0  5  3  4  2]\n",
            "best_MSE:  28898.98556456888\n",
            "dlg results at epoch 820 - [[5.1 3.4 1.5 0.2]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [5.9 3.  5.1 1.8]\n",
            " [5.5 2.3 4.  1.3]] [[ 7.12502218e+00  2.42044146e+01 -1.95943905e+02 -9.77332898e+01]\n",
            " [ 1.18984059e+01  1.00822095e+01  5.06742091e+01  3.36779465e+01]\n",
            " [-4.09248902e+00 -6.67375969e+00  2.25395636e+02  1.09570247e+02]\n",
            " [ 2.12984193e+00  1.24916406e+01 -7.36248989e+01 -3.38375855e+01]\n",
            " [ 1.21808825e+01  1.66643864e+01 -1.46644121e+02 -8.55309357e+01]\n",
            " [-9.14724535e+00  4.25644608e+01 -2.47691543e+02 -1.20292693e+02]\n",
            " [-3.91734184e+00 -2.70948187e+01  2.59818864e+02  1.25804145e+02]\n",
            " [ 1.68136864e+00 -3.57480192e+01  4.53841217e+02  2.25417160e+02]\n",
            " [-1.31762027e+00  3.20210794e+01 -2.55922722e+02 -1.33433963e+02]\n",
            " [ 3.29295735e+01  4.98755534e-01  3.64557209e+01  4.61210923e+01]\n",
            " [ 3.83605662e+00  4.01672160e-02  6.70096648e+01  3.28865613e+01]\n",
            " [ 1.22502559e+01  1.57695456e+01 -1.07326644e+02 -5.14433225e+01]\n",
            " [ 7.11743130e+00  4.95083368e+00 -2.42701949e+01 -1.19800024e+01]\n",
            " [ 2.31496953e+00 -1.28139725e+00  2.37042312e+01  1.03133721e+01]\n",
            " [-1.61818604e+00 -1.65766358e+01  1.73861078e+02  8.27095671e+01]\n",
            " [ 6.42932045e+00 -1.58495580e+00  8.08120106e+01  3.97174860e+01]]\n",
            "current loss:  tensor(0.0092, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0215, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0461, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0559, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0647, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0235, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0604, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1630, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0853, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1443, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [10 12  8  9  3 13  7  1  4  0 14  5 11  6 15  2]\n",
            "best_MSE:  147269715676.4575\n",
            "dlg results at epoch 830 - [[6.3 2.8 5.1 1.5]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [5.8 2.8 5.1 2.4]] [[ 1.90173388e+04 -1.25000997e+04 -6.13120922e+04  4.22120397e+03]\n",
            " [-4.87130929e+02 -1.79644942e+04  1.74328234e+05  8.41670292e+04]\n",
            " [-1.52052429e+04  2.75656289e+04  5.21014409e+04 -1.25700147e+04]\n",
            " [-3.30532795e+04  3.36139396e+04  3.26987217e+05 -1.09168079e+05]\n",
            " [-2.38733985e+04  6.43310882e+04 -3.93011922e+05 -2.44926007e+05]\n",
            " [-4.29119483e+04 -1.29081228e+04  4.58109581e+05  2.36955099e+05]\n",
            " [-3.98363007e+03 -5.04233885e+03  8.53330202e+04  4.27401237e+04]\n",
            " [-9.28992245e+03  1.04487575e+04  4.17306637e+05 -1.39096883e+05]\n",
            " [ 9.93499067e+04 -9.72541869e+04 -4.69259271e+05  1.18000670e+05]\n",
            " [ 5.13348620e+03 -5.46318479e+01  6.52249221e+02  1.20620201e+04]\n",
            " [-1.44546410e+04  2.91790889e+04 -1.89525241e+05 -1.18233741e+05]\n",
            " [ 5.57205194e+02  4.59322010e+03 -4.37723732e+04 -2.20924591e+04]\n",
            " [-1.79429558e+04 -7.07487396e+03 -1.97733424e+05 -6.00971348e+04]\n",
            " [ 1.30327429e+03  5.03061467e+03 -4.92383433e+04 -2.46402338e+04]\n",
            " [ 5.40377238e+02  7.91204523e+03 -4.69540974e+04 -2.33527922e+04]\n",
            " [-3.39121861e+04 -1.71103210e+05  1.37235399e+06  6.91680730e+05]]\n",
            "current loss:  tensor(0.2211, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0453, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0360, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0722, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0160, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1435, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0145, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0589, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 9 11 15  8 14  1  7  5  4 10  3 12  6 13  2  0]\n",
            "best_MSE:  177750828.89660007\n",
            "dlg results at epoch 840 - [[6.  2.2 4.  1. ]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.8 2.8 4.8 1.4]] [[ 1.95872944e+03 -1.65198461e+03 -9.88823914e+02 -3.01634485e+03]\n",
            " [ 1.75324638e+02  2.58339559e+02 -4.28800840e+03 -2.11621555e+03]\n",
            " [-4.73165385e+02 -3.07526729e+02  7.10219956e+03  3.52859984e+03]\n",
            " [ 4.17329873e+02  2.61635981e+02 -3.61128859e+03 -1.69140808e+03]\n",
            " [-2.38217310e+01 -6.75692463e+02  4.21555098e+03  2.11883270e+03]\n",
            " [ 3.33368261e+02  6.66070192e+01 -4.73570844e+03 -2.48611909e+03]\n",
            " [ 1.15006051e+04  1.47045630e+04  2.22618087e+04 -8.77394270e+03]\n",
            " [ 7.91044464e-01  2.02892702e+02 -2.19173258e+03 -1.39249667e+03]\n",
            " [-4.55197351e+02 -7.98461977e+02  9.48844845e+03  4.21589836e+03]\n",
            " [ 1.08241562e+03 -1.83282493e+03  7.95917925e+03  2.31889208e+03]\n",
            " [ 3.23104357e+02  2.21777886e+02 -6.50191645e+03 -3.35136355e+03]\n",
            " [-1.14849225e+04  1.03791389e+04  1.23559652e+04  7.28992855e+03]\n",
            " [ 1.15030332e+02  9.98070676e+00  9.71234687e+02  7.96313279e+02]\n",
            " [-4.69821162e+02 -4.84131969e+02  3.72806934e+03  1.75976424e+03]\n",
            " [-3.68513438e+02  8.81587906e+01  3.24888752e+03  1.60818275e+03]\n",
            " [ 3.09052707e+01  7.45332960e+01 -8.18685224e+02 -3.63160593e+02]]\n",
            "current loss:  tensor(0.0652, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0489, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0191, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1866, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1021, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1017, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0140, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1252, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0078, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1456, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 7  1 13 15 11  0  4  3 12  2  6  9  5 14  8 10]\n",
            "best_MSE:  30560877078.273376\n",
            "dlg results at epoch 850 - [[5.8 4.  1.2 0.2]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [5.9 3.  5.1 1.8]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [5.7 4.4 1.5 0.4]] [[   6025.03806823    9482.882074   -118899.72401411  -59995.59124132]\n",
            " [ -14268.49849697  -18742.13736795  239562.23626639  123839.13380496]\n",
            " [   2741.7384735     6912.11772208  -64315.78671535  -30556.2674096 ]\n",
            " [    679.88509284   -6810.10937966   56984.87302937   31289.22627241]\n",
            " [  -2020.44401456     404.50021002    2491.49886423     435.44203203]\n",
            " [  -7258.56099366   -8960.11277097  148549.94087584   73396.35048568]\n",
            " [  -7687.53471286   -5581.21759869  119271.03804074   59652.10422855]\n",
            " [    509.73349521   17550.60305651 -100247.33995675  -48276.69740038]\n",
            " [   1999.69327782    4163.79891706  -51455.08593563  -24591.94284456]\n",
            " [   1513.30963826    5911.41472571  -45691.18543508  -21310.50840554]\n",
            " [  -2378.66265524   -1953.21128114    6432.0934083      410.08919166]\n",
            " [   9530.65843716    4079.24107673 -141920.09669898  -71943.9063208 ]\n",
            " [  13454.82826073  -19068.81102186   67021.8711733    27890.42377372]\n",
            " [   3975.19638773    5171.65187676  -91373.4419174   -45615.53270298]\n",
            " [   3357.28146299    5027.28913667 -106648.40245431  -53342.19727106]\n",
            " [  35381.53533758  251496.62603513   11903.59564346   78261.57638733]]\n",
            "current loss:  tensor(0.0227, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1405, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0204, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1341, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0568, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0315, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0384, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0124, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1375, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0287, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 9  7 12 11  3  2  0 10 13 14  4  8 15  5  6  1]\n",
            "best_MSE:  1189849319188.5479\n",
            "dlg results at epoch 860 - [[6.  2.2 4.  1. ]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [7.1 3.  5.9 2.1]] [[ 9.52201312e+04 -2.73892336e+04  5.37936933e+05 -1.32785867e+05]\n",
            " [ 4.12449109e+04  2.85266783e+04  2.28990115e+05 -6.48102560e+04]\n",
            " [-1.48057680e+04 -4.59174299e+04 -2.34217705e+05  1.08794822e+05]\n",
            " [-2.30041483e+04 -5.09064090e+04 -3.65416522e+05 -7.53819547e+04]\n",
            " [ 3.54686981e+04  1.25424902e+05  2.45365053e+05  1.48185470e+04]\n",
            " [ 2.35492987e+04  6.69741464e+04 -2.98748001e+05 -3.15054112e+05]\n",
            " [ 6.70564345e+04  1.92482811e+04  1.89702759e+05 -3.32510163e+05]\n",
            " [ 7.75924090e+02  1.09756635e+05 -3.90845354e+05  2.79263877e+05]\n",
            " [ 1.59603961e+05  1.41449359e+05 -3.59749206e+05 -4.56842859e+05]\n",
            " [ 1.34815444e+05 -1.57629370e+05  6.15632161e+05 -9.66543310e+03]\n",
            " [-6.11672551e+04 -1.00291040e+04 -1.00399185e+05  1.13486470e+05]\n",
            " [-1.10765023e+04 -1.25337675e+05  1.06492936e+06  3.50221091e+05]\n",
            " [ 6.52866399e+02  8.67437890e+04  7.88889691e+04 -9.79141150e+03]\n",
            " [-9.69093829e+03 -1.97654603e+04 -5.09077224e+05  1.38302661e+05]\n",
            " [ 9.34202394e+04  4.24657426e+05 -4.83024745e+06 -2.01213779e+06]\n",
            " [ 4.24329031e+04 -9.71215151e+04  1.14541781e+06  4.00181304e+05]]\n",
            "current loss:  tensor(0.0419, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0818, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0378, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0108, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0077, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0343, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0306, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0620, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0196, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0533, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 3 13  1  2 10  7 11  8  4  0 15 14  9  5  6 12]\n",
            "best_MSE:  703584055.9369712\n",
            "dlg results at epoch 870 - [[5.5 3.5 1.3 0.2]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.7 2.5 5.8 1.8]] [[-2.89318390e+02  2.22718188e+03 -1.82847112e+04 -1.00007550e+04]\n",
            " [-1.60749829e+03 -1.28617993e+01  1.86876756e+04  8.68480434e+03]\n",
            " [ 2.30757732e+02  1.15105736e+03 -1.41639446e+04 -6.93931394e+03]\n",
            " [ 3.74743843e+02  1.26424199e+03 -1.26351376e+04 -6.46510030e+03]\n",
            " [-1.44455224e+04 -1.21636009e+04 -2.50769817e+04  1.85196081e+03]\n",
            " [ 1.76495330e+02  3.97345904e+03 -3.13870483e+04 -1.53624059e+04]\n",
            " [-1.57940450e+03 -8.18065514e+02  1.88795073e+04  1.09797979e+04]\n",
            " [-2.46371467e+02  1.39212872e+03 -8.34665462e+03 -3.22223918e+03]\n",
            " [ 3.16427623e+02  8.52932810e+02 -8.87680224e+03 -4.37328034e+03]\n",
            " [-9.22223282e+02 -2.33009864e+03  3.27273231e+04  1.71661620e+04]\n",
            " [-1.11279343e+03 -2.86823923e+03  3.20754846e+04  1.47825700e+04]\n",
            " [ 9.04324228e+02  3.46371489e+03 -3.72635197e+04 -1.85510154e+04]\n",
            " [ 3.09022376e+03  4.20972048e+03 -3.35424591e+04 -4.09204940e+03]\n",
            " [-1.25220719e+03 -1.35122618e+03  5.33291696e+02 -7.00059680e+03]\n",
            " [-3.31927703e+03 -2.26471916e+03  6.93311715e+04  3.26224690e+04]\n",
            " [-1.13120021e+03 -3.33356910e+03  3.95115096e+04  1.70690726e+04]]\n",
            "current loss:  tensor(0.0197, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0228, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0873, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1042, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0097, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0697, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0237, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0100, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0350, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0660, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [15 14  5  1  8 12 10  7 11  2  6 13  4  0  3  9]\n",
            "best_MSE:  8629184360.140415\n",
            "dlg results at epoch 880 - [[4.9 2.4 3.3 1. ]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.3 3.7 1.5 0.2]] [[ 1.62047668e+04 -2.21045478e+04 -2.91902914e+04 -2.34318269e+04]\n",
            " [ 8.50320185e+03  1.42799531e+03 -9.86957861e+04 -4.50160551e+04]\n",
            " [ 8.16424158e+03 -1.39529160e+04  8.05875226e+04  3.99135092e+04]\n",
            " [ 4.27577450e+03  6.78063671e+03 -8.03719020e+04 -4.21682998e+04]\n",
            " [-9.69478028e+02 -3.61771142e+03  3.79195445e+04  1.83644317e+04]\n",
            " [-4.51164034e+03 -3.68563326e+02  4.73191538e+04  2.27906072e+04]\n",
            " [ 1.31639873e+02 -1.17453450e+03  8.26050297e+03  3.69711287e+03]\n",
            " [-2.82378947e+04  2.42104388e+04 -3.24014650e+04  2.64336805e+04]\n",
            " [ 1.27805092e+03 -1.07664436e+04  7.71543479e+04  4.11483362e+04]\n",
            " [-7.80288669e+03 -1.94932696e+04  2.16984257e+05  1.04494344e+05]\n",
            " [-1.28763683e+04 -5.69634711e+03  1.49180247e+05  7.13473467e+04]\n",
            " [ 9.78099534e+02 -3.78737409e+02  3.27989020e+04  1.08617251e+04]\n",
            " [ 1.00457849e+03 -7.19451557e+03  5.93206847e+04  2.87052268e+04]\n",
            " [ 4.69791893e+03  4.94876384e+03 -1.05582643e+05 -5.62277948e+04]\n",
            " [-7.45757102e+02 -8.86877193e+03  9.18502377e+04  4.32887791e+04]\n",
            " [ 4.91528145e+03  1.84962020e+04 -1.98073264e+05 -9.40771831e+04]]\n",
            "current loss:  tensor(0.0277, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1025, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0291, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0256, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1748, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1709, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0624, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0081, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1873, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0058, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [13  7  4  2 12 14 11  3 10  1  0  5  8  6 15  9]\n",
            "best_MSE:  10545533.713964246\n",
            "dlg results at epoch 890 - [[5.7 3.8 1.7 0.3]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [5.7 3.  4.2 1.2]] [[ 1.12624093e+02  1.86992887e+02 -2.30095824e+03 -1.05051174e+03]\n",
            " [ 7.26128310e+02  2.21041583e+02 -1.20562791e+04 -4.16144814e+03]\n",
            " [ 1.83025182e+01 -3.70578707e+02  9.58313527e+02 -1.50421496e+01]\n",
            " [-3.63360091e+01  3.30023122e+01  4.01558196e+02  4.50438198e+01]\n",
            " [-2.24860918e+02 -6.28048340e+01  1.99847892e+03  7.74583089e+01]\n",
            " [ 4.44063850e+01  1.91756613e+02 -1.78693938e+03 -9.81596713e+02]\n",
            " [ 8.62312254e+01  1.69951815e+02 -2.35041420e+03 -1.19443167e+03]\n",
            " [ 1.43785159e+01 -7.58797252e+00  3.77524596e+02  5.73635950e+01]\n",
            " [-9.90824470e+00 -3.74241962e+01  3.28478308e+02  1.77137439e+02]\n",
            " [-7.86742464e-01 -4.72053036e+01  1.05746363e+03  2.10672613e+02]\n",
            " [ 1.85412100e+02  5.59331143e+01 -2.52927270e+03 -8.27063530e+02]\n",
            " [-3.95047537e+01 -4.17475684e+01  8.75476404e+02  3.61783331e+02]\n",
            " [ 2.09823595e+02  4.74978662e+00 -4.06335965e+03  4.20448025e+02]\n",
            " [-3.32041779e+01 -1.50049293e+02  2.09037407e+03  7.15002149e+02]\n",
            " [ 2.69727515e+01 -1.64735931e+02  1.47046946e+03  6.18647446e+02]\n",
            " [-9.61033700e+02  5.07596878e+02  9.37906816e+03 -4.29553351e+03]]\n",
            "current loss:  tensor(0.0279, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0549, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1509, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1157, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0839, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0437, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0154, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0727, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0385, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0107, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 9  3 12 13  2  4  6 11  8 10  7 14 15  0  1  5]\n",
            "best_MSE:  8533907.135304956\n",
            "dlg results at epoch 900 - [[5.  3.3 1.4 0.2]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.9 3.  5.1 1.8]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [6.2 3.4 5.4 2.3]] [[  -32.57256165   253.84209033 -1190.24636345  -536.04004733]\n",
            " [ -285.76454192  -449.89670413   988.12631927  1234.25206055]\n",
            " [  225.33937484  -116.29385856  -422.64037821   113.88375397]\n",
            " [  -46.63617496   -60.6458706    202.91442727   130.90778461]\n",
            " [   16.70150411    51.63240201  -551.60523853  -267.02806089]\n",
            " [ -549.75696149   419.97013502 -7354.08268933 -1051.9380188 ]\n",
            " [  -83.36859307   -97.75934634  1618.29816441   802.1819789 ]\n",
            " [  106.74438769   379.52778373 -3248.89366129 -1673.39190533]\n",
            " [ -268.744491    -454.26759329  5157.07871072  2427.58822039]\n",
            " [   61.68317768   327.30808021   673.8965813    -91.78432716]\n",
            " [ -331.94053706  -810.83823512  9573.51666995  4555.7324649 ]\n",
            " [  103.15441648   421.92509043 -1829.64992544 -1360.80778624]\n",
            " [ -155.54591093    84.91716047   276.80861949   114.04039652]\n",
            " [  205.07299947   119.88294142  1424.78175794   676.89042341]\n",
            " [  -34.55343398   239.9323222   -205.32695521  -275.38966435]\n",
            " [ -297.70159019    45.02542256  1014.12789304   774.04539179]]\n",
            "current loss:  tensor(0.0399, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1786, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0987, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0570, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1267, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0092, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0556, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0635, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1090, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0693, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [10 15  2  1 14  9  4  3  7  0 11  8  6 13 12  5]\n",
            "best_MSE:  293190691059.1083\n",
            "dlg results at epoch 910 - [[4.9 3.1 1.5 0.1]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.  2.  3.5 1. ]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.5 3.2 5.1 2. ]] [[  21814.96996081    5111.45329206 -153852.05893015  -84681.09690827]\n",
            " [   8489.34742758    8233.7163671  -141403.24426397  -66960.6016314 ]\n",
            " [ 267478.77061459  -28434.52312835   39357.58925652  284945.09586004]\n",
            " [ 178039.65746257   80748.04205704   70955.69935688 -226861.41816408]\n",
            " [-266239.00983509  147757.76650151 -954718.05466202  319985.72839887]\n",
            " [ -45119.91944606  -79194.88811919  880113.42281714  431067.79452757]\n",
            " [ -36072.5475872   -31885.29040741  386817.97873205  202977.11015675]\n",
            " [ -54603.20190715 -120070.59128579 1243544.72366402 -389250.29927433]\n",
            " [-423812.70226768  -39290.96228741 -322939.20180184  -87717.9919287 ]\n",
            " [  10219.88173079   18837.33173677 -171007.4719071   -77935.32312743]\n",
            " [-216040.16192492  290279.2624948  -878821.43188637  123443.97493648]\n",
            " [  50150.54374156  -38545.53003596  178427.96203136   32952.04505743]\n",
            " [ -34246.58782213  -50476.169097    559659.03010358  281297.57414954]\n",
            " [  -9962.71145157  -28064.35916706  362270.80069704  140528.80927715]\n",
            " [  -4899.79429062  -28560.5600042   307806.88087172  146816.86824968]\n",
            " [ 232425.20724463  211170.58170847  429563.63519347 -121456.45195232]]\n",
            "current loss:  tensor(0.1348, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0626, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1085, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0779, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0356, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0249, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0138, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0529, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2276, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2442, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [12  0  1 13 11  2 14  9 10  5  6  4  7  3  8 15]\n",
            "best_MSE:  6.502604325711783\n",
            "dlg results at epoch 920 - [[4.7 3.2 1.3 0.2]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.  2.  3.5 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.2 3.4 5.4 2.3]] [[ 5.7901096   3.31047717  1.40725187  0.36307996]\n",
            " [ 5.75669517  4.07611054 -3.86490752 -2.42562453]\n",
            " [ 5.88840111  2.51656941  1.79042327  1.91863453]\n",
            " [ 6.3730387   2.9098901   6.42272488 -0.57101832]\n",
            " [ 5.66377821  3.53074177  4.60913398  1.23865463]\n",
            " [ 5.49872858  3.0401395   4.6255326   2.01837957]\n",
            " [ 6.34129499  3.0673419   5.01132115  4.20830138]\n",
            " [ 5.16677188  2.37460639 12.02849243  3.91042547]\n",
            " [ 5.23540825  3.76490944  1.15428875  0.9890351 ]\n",
            " [ 4.95556309  3.09772432  3.88016766  1.88421796]\n",
            " [ 5.87982478  3.33872289  1.90014063  0.11685071]\n",
            " [ 6.27977888  2.99263335  5.91838111  0.94730845]\n",
            " [ 5.34196569  2.98440711  4.02314427  1.65281178]\n",
            " [ 6.90476978  3.14211159  3.91362382 -0.01831823]\n",
            " [ 7.44857991  3.85209434  7.24474475  0.77173097]\n",
            " [ 5.90493776  3.35387255  3.9682412   1.68032646]]\n",
            "current loss:  tensor(0.0060, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0384, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0417, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0214, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0044, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0203, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0861, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0080, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1736, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.2036, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 3 15  7  4  6  2  8  0 13  5  1 12 11 14  9 10]\n",
            "best_MSE:  5021677098360.793\n",
            "dlg results at epoch 930 - [[6.7 3.1 5.6 2.4]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [5.6 3.  4.5 1.5]] [[  206270.33899535  -519677.78764251  4561304.10317717  2150332.07415766]\n",
            " [  332705.94239753  -162410.5105575   -572567.07942493   138718.30743229]\n",
            " [  -43255.76692941  -142833.047228      43300.73678351   -38360.03781186]\n",
            " [ -127191.24235918  -142145.65974827  2429130.69947589  1138381.04015955]\n",
            " [  119303.81561818   583469.33352371 -5092682.35954702 -2311833.6808725 ]\n",
            " [ -230126.24962911   -44534.32981867   156080.10780529   312076.25982465]\n",
            " [  -73636.1262113   -247052.02590837  2266927.93976944  1122533.66201835]\n",
            " [-1158676.00843108  1479387.87031269  1727632.54649638  -420188.59162249]\n",
            " [   25919.17394186    76198.08267002 -1586796.72097127 -1164532.67455525]\n",
            " [ -269196.42543287   -18657.23038678  -616872.88744168   -73185.17285361]\n",
            " [  103436.70838331   -17327.05382206   379363.16377985  -596553.08694076]\n",
            " [   26369.34839395   321519.00411619  -546107.29171698   158847.5268879 ]\n",
            " [  205045.66925033   295225.27571863 -3687602.47932312 -1780236.48542008]\n",
            " [  -60945.97761317   -59772.05473118  1082875.83441466   500757.2006516 ]\n",
            " [  267417.18250569   139749.88902364 -2240401.14621151 -1032721.35049688]\n",
            " [ -198548.13316152   155222.37233819   706875.62582877  -517951.15682934]]\n",
            "current loss:  tensor(0.1798, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0078, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0092, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0253, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1425, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1086, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0054, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0098, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1178, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1789, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 9 12  3  5  0  7 11 15 13 14  4  2  8  6  1 10]\n",
            "best_MSE:  141602033439029.97\n",
            "dlg results at epoch 940 - [[4.4 3.  1.3 0.2]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [6.9 3.1 5.4 2.1]] [[ 1.65177195e+05 -6.05082984e+05 -2.90110532e+06 -9.43980325e+05]\n",
            " [ 5.84096275e+05  1.94600237e+06 -2.09589834e+07 -9.73183154e+06]\n",
            " [-1.07091739e+06  9.34750007e+05 -3.45038115e+06  1.27283951e+06]\n",
            " [-4.65850356e+04  1.06425905e+04  2.56596888e+04  8.12577982e+04]\n",
            " [-4.30951662e+05 -6.95193816e+04  3.15089125e+06  1.94446183e+06]\n",
            " [ 4.52154120e+05  1.79042058e+06 -1.97279794e+07 -9.23876063e+06]\n",
            " [-1.76519191e+05  5.08227330e+04 -6.19508727e+04  2.24376061e+05]\n",
            " [ 8.59410689e+04  2.38037461e+05 -8.73274856e+05  3.04659879e+05]\n",
            " [-9.03637483e+05 -2.96241996e+06  3.15906351e+07  1.45638650e+07]\n",
            " [-5.31706171e+05 -2.21786302e+06  2.41782288e+07  1.12106037e+07]\n",
            " [-1.54292525e+05 -9.20290930e+05  7.78727130e+06  3.22511710e+06]\n",
            " [-9.12232480e+05  7.18358500e+05 -2.50390731e+06  1.31707148e+06]\n",
            " [-1.01598153e+05 -9.92932776e+03  6.68886133e+05  4.38578876e+05]\n",
            " [-6.20277348e+04  7.72289064e+03  3.08515014e+05  2.33176839e+05]\n",
            " [ 4.59661421e+05 -1.05487123e+06  2.96937991e+06  1.93160089e+05]\n",
            " [ 2.08911316e+05 -9.41168722e+05  2.65368806e+07  9.43278929e+06]]\n",
            "current loss:  tensor(0.1612, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1169, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0071, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0551, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0065, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0360, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1046, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0505, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0101, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [12 14  3  7  2  5 13  0 11  6 15  8  4 10  9  1]\n",
            "best_MSE:  38297239587.29013\n",
            "dlg results at epoch 950 - [[7.3 2.9 6.3 1.8]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.  2.  3.5 1. ]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [5.7 2.5 5.  2. ]] [[ 3.52710188e+05 -8.09130378e+04  3.80482337e+05 -1.43488891e+05]\n",
            " [ 2.85233388e+03  5.60892809e+03 -4.81476537e+04 -2.06525122e+04]\n",
            " [ 5.28516356e+04 -8.67337307e+04 -1.26187451e+05 -5.91429253e+04]\n",
            " [ 2.63986051e+03 -9.54741604e+03  4.77817706e+04  1.86663323e+04]\n",
            " [-1.50554863e+01  1.36242482e+05  4.17835255e+05 -7.32204333e+04]\n",
            " [ 1.99197916e+01 -5.68722109e+03  5.08263609e+04  2.37289789e+04]\n",
            " [-1.96851298e+04  1.26985900e+03 -1.23654582e+05 -7.88117710e+04]\n",
            " [ 1.31922503e+04  3.41418228e+03 -1.54774811e+05 -7.31744125e+04]\n",
            " [ 3.12405144e+03 -3.76682176e+02 -6.01563218e+04 -3.38282250e+04]\n",
            " [-3.88644765e+02 -4.97799952e+02 -3.89700533e+03 -1.98405574e+03]\n",
            " [ 1.70047514e+04 -1.54893885e+04 -6.72870132e+01 -1.11046611e+04]\n",
            " [ 6.96889824e+03  6.67708352e+04 -1.20898283e+05  1.35918170e+04]\n",
            " [-4.03640140e+03 -8.77570701e+03  1.10832228e+05  5.06723059e+04]\n",
            " [ 7.98163400e+03  4.40550492e+03 -9.64062654e+04 -5.53222530e+04]\n",
            " [-2.84876074e+02 -4.61570703e+02  1.25956390e+03 -2.31803992e+02]\n",
            " [ 8.67618268e+02 -7.98842622e+03  7.24771509e+04  2.89804670e+04]]\n",
            "current loss:  tensor(0.0438, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0363, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1674, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0489, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0040, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0211, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0210, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1080, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0428, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0660, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 4 13  7  5  0 15  6 11  3 14  9  2 10 12  8  1]\n",
            "best_MSE:  110500401.76124568\n",
            "dlg results at epoch 960 - [[5.7 2.5 5.  2. ]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [6.  2.2 4.  1. ]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [5.  2.  3.5 1. ]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.8 2.8 5.1 2.4]] [[-7.60872762e+01 -5.38665234e+02  5.34046050e+03  2.56058024e+03]\n",
            " [ 1.89566437e+02  5.06715594e+02 -5.70066940e+03 -2.66296537e+03]\n",
            " [-6.09910738e+03  8.38308247e+03 -1.03591895e+04  3.65197496e+03]\n",
            " [ 6.01025449e+02 -4.19459540e+02  1.41069439e+03 -1.25434528e+03]\n",
            " [ 5.46596101e+01  3.48780826e+02 -3.54159733e+03 -1.60905970e+03]\n",
            " [ 1.90645821e+03  6.52373947e+03 -2.91861403e+04  6.22813643e+03]\n",
            " [-6.86870566e+02 -5.55519234e+02  8.01945001e+03  3.79149541e+03]\n",
            " [ 6.07698380e+01  2.16927605e+02 -2.25653844e+03 -1.04639427e+03]\n",
            " [-2.22600640e+01  4.62585880e+01 -1.78123026e+02 -4.55551424e+01]\n",
            " [ 7.01168323e+01 -5.32315261e+02  3.77716900e+03  1.74043251e+03]\n",
            " [-2.85367835e+03 -6.02401574e+02 -1.09811990e+04 -2.65726434e+03]\n",
            " [ 5.26486304e+03  2.12415670e+03  1.05268035e+04 -2.68444857e+03]\n",
            " [ 3.06840849e+02  9.56473487e+02 -9.17843265e+03 -4.39797220e+03]\n",
            " [-1.04289432e+02 -4.97302968e+02  4.93139777e+03  2.28743754e+03]\n",
            " [-5.21695353e+00  3.01635861e+02 -2.55132517e+03 -1.17962035e+03]\n",
            " [-3.91771275e+03 -1.17013004e+03  1.93733655e+04  9.88187145e+03]]\n",
            "current loss:  tensor(0.0102, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0053, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0367, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0172, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1442, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0660, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0075, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0319, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0283, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0161, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [ 7  6  2 13 14  5  8  0  3 10 11  1 15 12  4  9]\n",
            "best_MSE:  25858657501634.656\n",
            "dlg results at epoch 970 - [[6.  3.  4.8 1.8]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [5.5 2.3 4.  1.3]] [[-8.42953234e+05  2.61508170e+05 -1.18094223e+06  8.71906031e+05]\n",
            " [ 2.66787787e+05 -8.17276723e+05  3.23329162e+06  1.43277627e+06]\n",
            " [ 9.38811057e+04 -6.21214103e+04 -1.09071647e+06 -5.60882099e+05]\n",
            " [ 1.45232113e+05 -4.17624174e+03 -3.21239162e+06 -1.78430654e+06]\n",
            " [ 5.16600092e+05  1.76750334e+06 -1.79851401e+07 -8.15356250e+06]\n",
            " [ 1.80068976e+04  1.74834276e+05 -1.08654602e+06 -5.26384647e+05]\n",
            " [-3.33172698e+05 -1.59558897e+06  1.04650341e+07  3.61866105e+06]\n",
            " [-1.16871404e+05  2.29921927e+04  1.16617141e+06  5.97907644e+05]\n",
            " [-1.55319045e+05  1.52063024e+05  5.42347319e+05  1.78400033e+05]\n",
            " [-2.05805085e+05 -1.72202460e+05  3.62459892e+06  1.70597437e+06]\n",
            " [ 2.72100277e+05 -1.98620708e+06 -2.77199497e+06 -7.20612318e+05]\n",
            " [ 8.78113626e+05  1.40310791e+06 -2.07311239e+06  1.22219024e+06]\n",
            " [ 6.21521912e+04  1.26555851e+05 -1.28729886e+06 -5.80949095e+05]\n",
            " [-1.63649698e+06  9.82186272e+05 -4.94315457e+06  2.27279661e+06]\n",
            " [-3.38227344e+04 -6.85302550e+04  1.15303251e+06  5.34277783e+05]\n",
            " [ 3.84915044e+05 -4.01398786e+05  1.24500503e+06  4.22935427e+05]]\n",
            "current loss:  tensor(0.0757, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0853, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1334, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0429, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0623, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0556, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0216, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0079, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0829, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0391, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [14 15  0  9  7  8  6  2 12  4 11  5  3 10 13  1]\n",
            "best_MSE:  34650.342334067514\n",
            "dlg results at epoch 980 - [[5.5 2.3 4.  1.3]\n",
            " [6.  2.2 4.  1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.  3.5 1.3 0.3]] [[ 5.24982450e+00  3.25772087e+00  1.31155441e+01  2.09751003e+00]\n",
            " [ 7.69906411e+00  5.00400778e+00 -4.14840758e+01 -1.37955804e+01]\n",
            " [ 9.78432535e+00  7.78389540e+00 -6.41137851e+01 -2.82981534e+01]\n",
            " [ 1.12129317e+01  1.35984130e+01 -1.21861936e+02 -6.08765590e+01]\n",
            " [ 9.07996444e+00  4.83041984e+00 -3.29677813e+01 -1.56440506e+01]\n",
            " [ 1.78648892e+01  5.10310965e+01 -4.65644916e+02 -2.31135181e+02]\n",
            " [ 1.76403715e+01  1.66559722e+01 -2.34646942e+02 -1.27039358e+02]\n",
            " [-4.27135037e+00 -2.92343413e+00  9.02811232e+01  4.02344105e+01]\n",
            " [-3.68978928e+00 -2.22921816e+01  2.58687477e+02  1.35891088e+02]\n",
            " [ 7.56276494e-01 -1.74754388e+01  2.12857680e+02  1.09906299e+02]\n",
            " [ 5.53503212e-01 -2.57930450e+00  8.00006662e+01  3.58206968e+01]\n",
            " [ 1.46008722e+01  1.16213388e+01 -1.24191947e+02 -4.38200911e+01]\n",
            " [-1.33114792e+01 -4.00600730e+01  4.67965015e+02  2.26126404e+02]\n",
            " [ 1.67831633e+01  1.08487490e+01 -1.21986839e+02 -4.60565800e+01]\n",
            " [ 5.12760046e+00  4.32529546e-01  2.43217850e+01  8.65381290e+00]\n",
            " [ 9.40714592e+00  2.05429250e+01 -1.96552177e+02 -9.28054481e+01]]\n",
            "current loss:  tensor(0.0104, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0697, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1790, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0446, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0622, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.1055, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0416, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0448, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0479, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0730, grad_fn=<MeanBackward0>)\n",
            "best guessed-actual assignment:  [14 11 13  4  1 10  3  8 15  0  9  2 12  5  7  6]\n",
            "best_MSE:  607056835.2984785\n",
            "dlg results at epoch 990 - [[5.2 4.1 1.5 0.1]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.1 3.8 1.9 0.4]] [[ 2.79312819e+03  3.03629989e+03 -5.80751805e+04 -2.68107839e+04]\n",
            " [-7.70693427e+01 -1.09269030e+02  1.16223682e+02  8.17289312e+01]\n",
            " [-2.65430906e+03 -4.89394805e+03  4.80231285e+04  2.29986398e+04]\n",
            " [-1.06107076e+04 -1.63412141e+04  2.60723101e+03 -6.32178844e+03]\n",
            " [ 1.00681613e+03  2.90227222e+03  4.24916721e+04  2.74328930e+04]\n",
            " [-1.34340254e+02  1.04179324e+03 -1.83403598e+03 -9.94253589e+02]\n",
            " [-3.37177497e+01  2.72962208e+03 -1.84524611e+04 -7.81098852e+03]\n",
            " [ 4.41606041e+03 -2.80134800e+03 -2.76123654e+04 -7.35719756e+03]\n",
            " [-1.80655840e+03 -1.55366508e+03  1.78589808e+04  8.74278061e+03]\n",
            " [-6.03522590e+02 -3.82705757e+02  9.07248513e+03  4.35586728e+03]\n",
            " [-2.82645357e+02 -1.11670948e+03  1.14918539e+04  5.35304880e+03]\n",
            " [ 8.43996386e+02  2.31203393e+03 -6.04837464e+03 -1.45809101e+03]\n",
            " [-6.33562822e+02  5.46096338e+02  1.44029617e+03  8.05916825e+02]\n",
            " [-6.91565222e+02  6.56509585e+02 -2.27095236e+03 -1.24987272e+03]\n",
            " [ 4.88444186e+03 -4.03542174e+03 -1.84000484e+04 -8.04159975e+03]\n",
            " [ 6.25873370e+01  4.17724742e+03 -2.33884606e+04 -1.01621771e+04]]\n",
            "current loss:  tensor(0.0757, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0223, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0325, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0058, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0115, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0072, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0327, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0059, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0790, grad_fn=<MeanBackward0>)\n",
            "current loss:  tensor(0.0455, grad_fn=<MeanBackward0>)\n",
            "score: 30/30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create summary plots of MSE and normalized errors over time\n",
        "fig, axs = plt.subplots(1, 3, figsize=(24, 6))\n",
        "\n",
        "axs[0].plot(dlg_timestamps, torch.log(torch.tensor(dlg_MSE)), 'ro')\n",
        "axs[0].set(title='log MSE of guessed data over evolution of model', xlabel='time (epochs)', ylabel='log MSE (cm^2)')\n",
        "\n",
        "axs[1].plot(torch.tensor(dlg_timestamps).repeat_interleave(batch_size), torch.log(torch.tensor(dlg_n_errors).view(-1)), 'ro')\n",
        "axs[1].set(title='log normalized error of guessed data over evolution of model', xlabel='time (epochs)', ylabel='log normalized error (SE / true norm squared)')\n",
        "\n",
        "axs[2].plot(list(range(epochs)), losses)\n",
        "axs[2].set(title='loss over time', xlabel='time (epochs)', ylabel='loss (NLL)')\n",
        "\n",
        "plt.savefig('train_DLG_16.png', dpi=300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "6euRuR8Fnxon",
        "outputId": "be401132-2dca-4f87-878c-ead6b3c9d35c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1728x432 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evolution of SEs, normalized errors, cosine distances\n",
        "fig, axs = plt.subplots(len(dlg_timestamps), 3, sharex='col', figsize=(24, len(dlg_timestamps)*4))\n",
        "\n",
        "for i in range(len(dlg_timestamps)):\n",
        "    axs[i, 0].hist(torch.log(torch.tensor(dlg_SEs[i])), 50)\n",
        "    axs[i, 0].set(title=f'log SE of batch DLG at epoch {dlg_timestamps[i]}', xlabel='log SE', ylabel='frequency')\n",
        "\n",
        "    axs[i, 1].hist(torch.log(torch.tensor(dlg_n_errors[i])), 50)\n",
        "    axs[i, 1].set(title=f'log NE of batch DLG at epoch {dlg_timestamps[i]}', xlabel='log NE', ylabel='frequency')\n",
        "\n",
        "    axs[i, 2].hist(dlg_cos_angles[i], 50)\n",
        "    axs[i, 2].set(title=f'cosine distances of batch DLG at epoch {dlg_timestamps[i]}', xlabel='cosine distance', ylabel='frequency')"
      ],
      "metadata": {
        "id": "Amka4BDAvQBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notes"
      ],
      "metadata": {
        "id": "kNHDbhF0-VWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Todo\n",
        "# look at BRAZPD medical dataset --> see notebook that has the baseline features --> try 1 data point before batch\n",
        "# see if larger dataset + batch size + trained network make dlg harder\n",
        "\n",
        "# future tasks -----------------------------------------------------------\n",
        "# added assign_best(), so DLG training can be modified to work with both forced assignment (assign_guess) and closest assignment (assign_best)\n",
        "# maybe rerun training of model with DLG using Adam (only did LBFGS above)\n",
        "# look at dp\n",
        "# look at papers more related to FL\n",
        "# estimate how quickly the model can be trained + attacked\n",
        "# icml workshop for results\n",
        "# consider other medical dataset\n",
        "# possible idea - PCA with image tasks to capture similarity between reconstructed and true input data\n",
        "# consider dropout with a probability like ~ 0.20-0.25 (or even, aggressively, 0.5 - good for generalization)"
      ],
      "metadata": {
        "id": "gLZEAjIwTnUb"
      },
      "execution_count": 128,
      "outputs": []
    }
  ]
}