{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgozon/DLG-UROP/blob/main/Batch_DLG_Iris_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch-DLG - Iris Dataset\n",
        "This notebook modifies the code in [Deep Leakage from Gradients](https://gist.github.com/Lyken17/91b81526a8245a028d4f85ccc9191884) to work with the Iris Dataset. In addition, it explores whether it is possible to repeat the same procedure on the batch input gradient."
      ],
      "metadata": {
        "id": "EFXvpWu88EO4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWa7Xo6PkIl3",
        "outputId": "38ed7337-a413-44fb-ed71-368f51e9b8da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# setting up libraries and device\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad\n",
        "torch.manual_seed(100) # for generating the same random weights\n",
        "\n",
        "# for testing\n",
        "from random import randint\n",
        "from random import shuffle\n",
        "from itertools import permutations\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import math\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "dst = load_iris()\n",
        "\n",
        "print(torch.__version__)\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "print(\"Running on %s\" % device)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n",
            "Running on cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjKWqs2akepH"
      },
      "source": [
        "# auxiliary functions for NN - conver to onehot and loss function\n",
        "def label_to_onehot(target, num_classes = 3):\n",
        "    target = torch.unsqueeze(target, 1)\n",
        "    onehot_target = torch.zeros(target.size(0), num_classes, device=target.device)\n",
        "    onehot_target.scatter_(1, target, 1)\n",
        "    return onehot_target\n",
        "\n",
        "def cross_entropy_for_onehot(pred, target):\n",
        "    return torch.mean(torch.sum(- target * F.log_softmax(pred, dim=-1), 1))"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AorI020iVjjS"
      },
      "source": [
        "# a random fully connected neural network with random weights and biases\n",
        "def weights_init(m):\n",
        "    if hasattr(m, \"weight\"):\n",
        "        m.weight.data.uniform_(-0.5, 0.5)\n",
        "    if hasattr(m, \"bias\"):\n",
        "        m.bias.data.uniform_(-0.5, 0.5)\n",
        "    \n",
        "class FcNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FcNet, self).__init__()\n",
        "        act = nn.Sigmoid\n",
        "        self.body = nn.Sequential(\n",
        "            nn.Linear(4, 100),\n",
        "            act(),\n",
        "            nn.Linear(100, 100),\n",
        "            act(),\n",
        "            nn.Linear(100, 100),\n",
        "            act(),\n",
        "            nn.Linear(100, 3),\n",
        "            act(),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.body(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        return out\n",
        "    \n",
        "net = FcNet().to(device)\n",
        "    \n",
        "net.apply(weights_init)\n",
        "criterion = cross_entropy_for_onehot"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optionally train NN to see if it makes a difference\n",
        "# TODO - consider partitioning dataset into a train and test portion\n",
        "def train_net_LBFGS():\n",
        "    epochs = 150\n",
        "    batch_size = 32\n",
        "    optimizer = torch.optim.LBFGS(net.parameters(), lr=0.001)\n",
        "    scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lambda epoch: 0.99)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        #TODO - concatenate dst.data and dst.target and use dataloader to sample random mini batches\n",
        "        gt_data = torch.tensor(dst.data).to(device)\n",
        "        gt_label = torch.tensor(dst.target).to(device)\n",
        "        gt_onehot_label = label_to_onehot(gt_label, num_classes=3)\n",
        "        #print('lbfgs: ', gt_data, gt_onehot_label)\n",
        "        \n",
        "        def closure():\n",
        "            optimizer.zero_grad()\n",
        "            output = net(gt_data.float())\n",
        "            loss = criterion(output, gt_onehot_label)\n",
        "            loss.backward()\n",
        "            #print('closure loss: ', criterion(output, gt_onehot_label))\n",
        "            #print(f'output: {output}, onehot_label: {gt_onehot_label}')\n",
        "            print('loss: ', loss)\n",
        "            return loss\n",
        "      \n",
        "        optimizer.step(closure)\n",
        "        scheduler.step()\n",
        "\n",
        "def train_net_Adam():\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "    epochs = 100\n",
        "    for i in range(epochs): # TODO - add random minibatches using dataloader\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for input, target in zip(dst.data, dst.target):\n",
        "            gt_data = torch.tensor(input).to(device)\n",
        "            gt_data = gt_data.view(1, *gt_data.size())\n",
        "            gt_label = torch.tensor(target).to(device)\n",
        "            gt_label = gt_label.view(1)\n",
        "            gt_onehot_label = label_to_onehot(gt_label, num_classes=3)\n",
        "\n",
        "            \n",
        "            output = net(gt_data.float())\n",
        "            print('adam: ', output.tolist(), gt_onehot_label.tolist())\n",
        "            loss = criterion(output, gt_onehot_label)\n",
        "            loss.backward()\n",
        "            \n",
        "            print('current loss: ', loss)\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "def test_net():\n",
        "    for input, target in zip(dst.data, dst.target):\n",
        "        gt_data = torch.tensor(input).to(device)\n",
        "        pred = net(gt_data.float())\n",
        "        #print('input, target, pred: ', input, target, pred)\n",
        "        pred = pred.view(-1)\n",
        "        print(f'data: {gt_data.tolist()}, pred: {torch.argmax(pred).item()}, label: {target}')\n",
        "\n",
        "# randomize dataset\n",
        "# dst_length = dst.data.shape[0]\n",
        "# perm = list(range(dst_length))\n",
        "# shuffle(perm)\n",
        "\n",
        "train_net_LBFGS()\n",
        "test_net()"
      ],
      "metadata": {
        "id": "F96GffQPLCFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a5e940b-e323-44a7-ea72-876d4d5c4a47"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  tensor(1.1379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1338, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1328, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1323, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1318, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1312, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1306, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1299, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1291, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1283, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1275, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1266, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1258, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1249, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1242, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1234, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1227, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1221, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1215, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1209, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1204, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1199, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1194, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1189, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1185, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1180, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1176, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1172, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1168, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1165, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1161, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1157, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1154, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1151, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1147, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1144, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1141, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1138, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1135, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1132, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1129, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1126, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1123, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1120, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1117, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1115, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1112, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1109, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1106, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1104, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1101, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1098, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1096, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1093, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1090, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1088, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1085, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1082, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1080, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1077, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1074, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1072, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1069, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1066, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1063, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1061, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1058, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1055, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1052, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1049, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1046, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1043, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1040, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1037, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1034, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1031, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1027, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1024, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1021, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1018, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1014, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1011, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1007, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1004, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.1000, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0997, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0993, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0989, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0986, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0982, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0978, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0974, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0970, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0966, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0963, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0959, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0955, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0951, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0947, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0943, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0939, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0935, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0931, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0926, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0922, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0918, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0914, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0910, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0906, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0902, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0897, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0893, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0889, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0885, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0881, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0876, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0872, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0868, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0864, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0860, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0856, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0852, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0847, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0843, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0839, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0835, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0831, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0827, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0822, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0818, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0814, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0810, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0806, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0802, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0797, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0793, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0789, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0785, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0780, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0776, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0772, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0768, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0763, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0759, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0755, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0751, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0746, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0742, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0737, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0733, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0729, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0724, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0720, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0715, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0711, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0706, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0701, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0697, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0692, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0687, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0683, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0678, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0673, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0668, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0663, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0659, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0654, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0648, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0643, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0638, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0633, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0627, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0622, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0617, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0611, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0605, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0599, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0594, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0588, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0582, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0575, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0569, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0562, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0556, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0549, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0542, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0534, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0527, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0519, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0511, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0502, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0493, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0483, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0473, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0461, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0449, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0434, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0418, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0398, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0370, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0325, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(1.0142, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9809, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9802, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9799, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9793, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9786, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9778, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9767, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9754, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9740, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9727, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9714, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9702, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9690, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9680, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9670, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9660, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9651, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9642, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9634, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9626, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9618, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9611, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9604, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9597, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9590, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9583, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9577, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9570, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9564, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9558, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9552, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9546, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9540, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9534, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9529, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9523, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9518, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9512, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9507, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9502, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9497, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9491, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9486, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9481, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9476, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9471, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9466, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9461, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9455, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9450, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9445, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9440, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9434, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9429, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9423, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9417, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9411, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9405, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9399, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9392, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9386, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9364, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9357, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9349, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9341, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9332, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9324, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9316, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9307, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9299, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9290, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9282, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9274, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9266, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9258, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9250, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9243, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9236, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9228, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9221, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9215, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9208, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9202, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9195, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9189, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9183, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9177, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9171, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9165, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9160, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9155, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9150, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9145, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9140, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9135, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9130, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9125, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9120, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9115, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9109, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9103, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9098, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9092, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9087, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9081, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9076, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9070, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9064, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9058, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9051, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9045, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9038, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9031, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9024, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9017, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9009, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.9002, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8995, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8988, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8980, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8973, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8966, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8959, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8952, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8945, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8938, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8931, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8924, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8917, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8910, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8903, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8897, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8890, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8883, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8876, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8870, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8863, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8856, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8849, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8842, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8835, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8828, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8821, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8813, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8806, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8799, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8791, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8783, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8775, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8767, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8759, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8751, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8743, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8735, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8727, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8719, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8711, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8703, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8695, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8687, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8679, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8671, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8664, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8656, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8649, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8642, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8635, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8628, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8621, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8614, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8607, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8601, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8594, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8588, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8581, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8575, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8569, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8563, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8557, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8552, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8546, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8541, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8536, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8530, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8525, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8520, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8515, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8509, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8504, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8499, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8493, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8488, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8483, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8478, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8473, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8468, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8462, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8457, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8452, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8447, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8441, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8436, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8430, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8424, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8417, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8411, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8405, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8399, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8393, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8387, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8381, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8368, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8362, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8355, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8349, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8342, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8336, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8330, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8324, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8317, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8311, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8305, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8300, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8294, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8288, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8282, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8277, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8271, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8266, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8260, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8255, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8250, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8244, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8239, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8234, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8229, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8223, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8218, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8213, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8208, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8203, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8198, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8194, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8189, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8184, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8180, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8176, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8171, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8167, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8163, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8159, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8156, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8152, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8148, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8145, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8141, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8138, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8135, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8131, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8128, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8125, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8122, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8119, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8115, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8112, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8109, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8106, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8103, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8100, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8096, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8093, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8090, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8086, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8083, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8080, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8076, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8073, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8069, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8066, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8063, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8059, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8056, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8053, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8050, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8047, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8044, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8041, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8038, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8035, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8033, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8030, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8028, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8025, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8023, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8020, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8018, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8016, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8014, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8011, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8009, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8007, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8005, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8003, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.8001, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7999, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7996, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7994, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7992, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7990, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7988, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7985, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7983, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7981, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7979, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7977, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7975, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7972, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7970, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7967, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7965, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7962, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7960, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7957, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7955, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7952, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7949, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7947, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7944, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7941, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7939, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7936, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7933, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7931, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7928, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7925, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7923, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7921, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7918, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7916, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7914, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7911, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7909, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7907, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7905, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7903, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7901, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7899, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7897, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7895, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7893, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7891, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7890, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7888, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7886, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7884, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7883, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7881, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7879, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7878, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7876, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7875, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7873, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7872, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7870, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7869, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7867, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7866, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7864, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7863, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7861, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7859, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7858, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7856, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7855, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7853, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7851, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7850, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7848, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7846, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7844, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7842, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7840, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7838, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7836, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7833, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7831, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7828, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7826, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7824, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7821, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7819, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7817, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7814, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7812, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7810, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7808, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7807, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7805, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7803, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7802, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7800, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7799, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7798, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7796, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7795, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7794, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7793, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7792, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7790, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7789, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7788, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7787, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7786, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7785, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7784, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7783, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7782, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7781, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7780, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7779, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7778, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7777, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7775, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7774, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7773, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7772, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7770, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7769, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7768, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7766, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7765, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7763, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7761, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7760, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7758, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7757, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7755, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7753, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7752, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7750, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7749, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7748, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7746, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7745, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7744, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7742, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7741, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7740, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7739, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7738, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7737, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7736, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7735, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7734, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7733, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7732, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7731, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7730, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7729, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7728, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7727, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7727, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7726, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7725, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7724, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7723, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7723, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7722, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7721, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7720, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7719, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7719, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7718, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7717, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7716, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7715, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7714, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7714, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7713, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7712, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7711, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7710, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7709, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7708, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7707, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7706, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7705, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7704, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7703, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7702, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7701, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7700, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7699, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7698, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7697, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7696, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7695, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7694, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7693, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7692, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7691, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7690, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7689, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7688, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7686, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7685, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7684, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7683, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7682, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7681, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7680, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7679, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7678, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7678, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7677, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7676, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7675, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7674, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7673, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7672, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7671, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7670, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7669, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7668, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7668, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7667, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7666, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7665, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7664, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7663, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7663, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7662, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7661, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7660, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7659, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7659, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7658, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7657, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7656, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7655, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7655, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7654, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7653, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7652, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7652, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7651, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7650, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7649, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7648, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7648, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7647, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7646, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7645, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7644, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7644, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7643, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7642, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7641, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7641, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7640, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7639, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7638, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7637, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7637, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7636, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7635, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7634, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7634, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7633, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7632, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7631, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7631, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7630, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7629, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7629, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7628, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7627, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7626, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7626, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7625, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7624, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7624, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7623, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7622, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7622, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7621, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7620, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7620, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7619, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7618, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7618, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7617, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7616, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7616, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7615, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7615, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7614, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7613, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7613, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7612, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7611, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7611, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7610, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7610, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7609, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7608, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7608, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7607, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7607, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7606, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7606, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7605, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7605, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7604, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7604, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7603, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7603, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7602, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7602, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7601, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7600, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7600, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7599, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7599, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7599, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7598, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7598, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7597, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7597, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7596, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7596, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7595, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7595, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7595, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7594, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7594, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7593, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7593, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7592, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7592, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7592, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7591, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7591, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7590, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7590, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7589, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7589, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7588, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7588, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7587, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7587, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7586, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7586, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7585, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7585, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7584, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7584, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7583, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7582, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7582, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7581, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7581, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7580, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7579, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7579, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7578, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7577, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7577, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7576, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7575, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7574, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7574, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7573, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7573, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7572, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7571, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7571, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7570, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7569, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7569, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7568, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7568, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7567, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7567, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7566, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7566, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7565, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7565, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7564, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7564, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7563, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7563, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7562, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7562, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7561, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7561, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7560, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7560, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7559, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7559, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7559, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7558, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7558, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7557, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7557, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7557, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7556, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7556, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7555, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7555, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7555, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7554, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7554, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7553, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7553, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7553, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7552, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7552, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7552, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7551, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7551, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7551, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7550, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7550, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7550, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7549, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7549, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7549, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7548, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7548, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7547, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7547, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7547, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7546, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7546, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7546, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7545, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7545, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7545, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7544, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7544, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7544, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7543, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7543, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7543, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7542, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7542, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7541, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7541, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7541, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7540, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7540, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7539, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7539, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7538, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7538, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7537, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7537, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7536, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7536, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7535, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7535, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7534, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7534, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7533, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7533, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7532, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7532, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7531, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7531, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7530, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7530, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7529, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7529, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7528, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7528, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7527, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7527, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7526, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7526, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7526, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7525, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7525, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7524, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7524, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7523, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7523, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7523, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7522, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7522, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7521, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7521, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7521, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7520, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7520, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7519, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7519, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7519, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7518, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7518, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7518, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7517, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7517, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7517, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7516, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7516, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7516, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7515, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7515, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7515, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7514, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7514, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7514, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7513, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7513, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7513, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7512, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7512, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7512, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7511, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7511, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7511, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7510, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7510, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7510, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7509, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7509, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7509, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7508, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7508, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7508, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7508, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7507, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7507, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7507, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7506, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7506, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7506, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7505, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7505, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7505, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7505, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7504, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7504, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7504, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7503, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7503, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7503, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7502, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7502, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7502, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7501, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7501, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7501, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7500, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7500, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7500, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7499, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7499, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7499, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7498, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7498, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7498, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7497, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7497, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7497, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7496, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7496, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7496, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7495, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7495, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7495, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7495, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7494, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7494, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7494, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7494, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7493, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7493, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7493, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7493, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7493, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7492, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7492, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7492, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7492, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7492, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7491, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7491, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7491, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7491, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7491, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7490, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7490, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7490, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7490, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7490, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7490, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7490, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7489, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7489, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7489, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7489, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7489, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7489, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7489, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7488, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7488, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7488, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7488, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7488, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7488, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7488, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7488, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7487, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7487, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7487, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7487, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7487, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7487, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7487, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7487, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7487, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7486, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7486, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7486, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7486, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7486, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7486, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7486, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7486, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7486, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7485, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7485, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7485, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7485, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7485, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7485, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7485, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7485, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7485, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7484, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7484, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7484, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7484, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7484, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7484, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7484, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7484, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7484, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7483, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7483, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7483, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7483, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7483, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7483, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7483, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7482, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7482, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7482, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7482, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7482, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7482, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7481, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7481, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7481, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7481, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7481, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7481, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7481, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7480, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7480, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7480, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7480, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7480, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7479, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7479, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7479, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7479, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7479, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7479, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7478, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7478, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7478, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7478, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7478, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7477, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7477, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7477, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7477, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7477, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7476, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7476, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7476, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7476, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7476, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7475, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7475, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7475, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7475, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7474, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7474, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7474, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7474, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7473, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7473, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7473, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7473, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7472, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7472, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7472, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7472, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7471, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7471, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7471, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7471, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7470, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7470, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7470, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7470, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7469, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7469, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7469, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7469, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7469, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7468, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7468, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7468, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7468, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7467, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7467, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7467, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7467, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7467, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7466, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7466, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7466, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7466, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7466, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7465, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7465, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7465, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7465, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7465, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7464, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7464, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7464, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7464, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7464, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7464, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7463, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7463, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7463, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7463, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7463, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7463, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7463, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7462, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7462, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7462, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7462, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7462, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7462, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7462, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7462, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7461, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7461, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7461, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7461, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7461, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7461, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7461, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7461, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7461, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7461, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7461, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7461, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7460, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7460, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7460, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7460, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7460, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7460, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7460, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7460, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7460, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7460, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7459, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7459, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7459, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7459, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7459, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7459, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7459, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7458, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7458, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7458, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7458, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7458, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7458, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7457, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7457, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7457, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7457, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7457, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7456, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7456, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7456, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7456, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7456, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7456, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7455, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7455, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7455, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7455, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7455, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7455, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7455, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7455, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7454, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7454, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7454, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7454, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7454, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7454, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7454, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7454, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7454, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7453, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7453, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7453, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7453, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7453, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7453, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7453, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7453, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7453, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7452, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7452, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7452, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7452, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7452, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7452, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7452, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7452, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7452, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7452, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7452, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7451, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7451, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7451, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7451, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7451, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7451, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7451, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7451, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7451, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7451, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7450, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7450, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7450, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7450, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7450, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7450, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7450, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7450, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7450, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7450, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7449, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7449, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7449, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7449, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7449, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7449, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7449, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7449, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7449, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7449, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7448, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7448, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7448, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7448, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7448, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7448, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7448, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7448, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7448, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7447, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7447, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7447, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7447, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7447, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7447, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7447, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7447, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7447, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7446, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7446, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7446, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7446, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7446, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7446, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7446, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7446, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7446, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7445, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7445, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7445, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7445, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7445, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7445, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7445, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7445, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7445, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7445, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7444, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7444, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7444, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7444, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7444, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7444, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7444, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7444, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7444, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7444, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7443, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7443, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7443, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7443, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7443, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7443, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7443, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7443, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7443, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7443, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7443, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7442, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7442, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7442, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7442, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7442, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7442, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7442, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7442, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7442, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7442, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7442, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7442, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7441, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7441, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7441, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7441, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7441, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7441, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7441, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7441, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7441, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7441, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7441, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7441, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7441, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7441, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7440, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7440, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7440, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7440, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7440, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7440, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7440, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7440, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7440, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7440, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7440, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7440, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7440, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7440, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7440, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7439, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7439, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7439, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7439, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7439, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7439, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7439, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7439, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7439, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7439, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7439, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7439, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7439, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7439, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7438, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7438, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7438, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7438, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7438, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7438, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7438, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7438, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7438, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7437, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7437, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7437, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7437, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7437, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7437, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7437, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7437, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7437, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7436, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7436, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7436, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7436, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7436, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7436, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7436, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7436, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7436, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7435, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7435, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7435, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7435, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7435, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7435, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7435, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7435, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7435, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7435, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7434, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7434, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7434, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7434, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7434, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7434, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7434, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7434, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7434, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7434, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7433, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7433, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7433, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7433, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7433, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7433, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7433, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7433, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7433, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7433, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7433, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7433, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7432, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7432, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7432, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7432, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7432, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7432, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7432, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7432, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7432, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7432, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7432, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7431, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7431, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7431, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7431, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7431, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7431, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7431, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7431, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7431, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7431, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7431, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7431, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7430, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7430, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7430, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7430, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7430, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7430, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7430, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7430, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7430, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7430, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7430, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7430, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7429, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7429, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7429, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7429, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7429, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7429, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7429, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7429, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7429, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7429, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7428, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7428, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7428, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7428, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7428, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7428, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7428, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7428, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7428, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7427, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7427, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7427, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7427, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7427, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7427, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7427, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7426, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7426, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7426, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7426, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7426, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7425, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7425, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7425, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7425, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7424, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7424, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7424, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7424, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7423, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7423, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7423, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7422, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7422, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7421, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7421, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7421, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7420, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7420, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7419, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7419, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7418, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7417, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7417, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7416, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7414, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7412, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7411, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7410, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7410, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7409, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7409, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7408, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7408, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7407, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7407, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7407, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7406, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7406, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7406, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7405, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7405, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7405, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7405, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7404, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7404, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7404, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7404, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7404, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7403, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7403, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7403, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7403, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7403, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7402, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7402, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7402, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7402, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7402, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7402, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7401, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7401, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7401, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7401, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7401, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7401, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7400, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7400, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7400, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7400, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7400, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7400, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7400, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7399, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7399, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7399, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7399, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7399, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7399, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7399, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7398, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7398, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7398, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7398, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7398, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7398, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7398, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7397, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7397, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7397, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7397, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7397, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7397, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7397, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7397, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7396, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7396, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7396, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7396, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7396, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7396, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7396, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7396, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7396, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7395, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7395, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7395, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7395, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7395, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7395, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7395, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7395, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7395, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7394, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7394, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7394, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7394, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7394, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7394, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7394, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7394, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7394, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7393, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7393, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7393, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7393, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7393, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7393, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7393, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7393, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7393, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7393, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7393, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7393, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7392, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7392, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7392, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7392, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7392, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7392, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7392, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7392, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7392, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7392, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7392, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7392, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7392, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7391, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7391, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7391, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7391, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7391, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7391, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7391, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7391, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7391, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7391, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7391, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7391, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7391, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7391, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7391, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7390, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7390, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7390, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7390, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7390, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7390, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7390, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7390, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7390, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7390, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7390, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7390, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7390, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7390, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7390, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7390, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7389, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7389, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7389, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7389, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7389, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7389, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7389, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7389, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7389, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7389, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7388, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7388, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7388, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7388, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7388, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7388, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7388, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7388, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7388, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7388, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7388, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7387, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7387, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7387, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7387, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7387, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7387, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7387, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7387, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7387, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7387, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7387, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7387, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7387, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7386, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7386, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7386, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7386, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7386, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7386, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7386, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7386, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7386, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7386, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7386, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7386, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7386, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7386, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7386, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7386, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7385, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7385, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7385, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7385, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7385, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7385, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7385, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7385, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7385, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7385, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7385, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7385, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7385, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7385, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7385, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7385, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7385, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7385, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7385, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7385, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7383, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7382, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7382, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7382, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7382, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7382, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7382, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7382, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7382, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7382, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7382, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7382, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7382, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7382, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7382, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7382, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7382, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7382, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7382, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7381, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7379, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7378, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7377, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7376, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7375, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7374, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7372, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "loss:  tensor(0.7371, grad_fn=<MeanBackward0>)\n",
            "data: [5.1, 3.5, 1.4, 0.2], pred: 0, label: 0\n",
            "data: [4.9, 3.0, 1.4, 0.2], pred: 0, label: 0\n",
            "data: [4.7, 3.2, 1.3, 0.2], pred: 0, label: 0\n",
            "data: [4.6, 3.1, 1.5, 0.2], pred: 0, label: 0\n",
            "data: [5.0, 3.6, 1.4, 0.2], pred: 0, label: 0\n",
            "data: [5.4, 3.9, 1.7, 0.4], pred: 0, label: 0\n",
            "data: [4.6, 3.4, 1.4, 0.3], pred: 0, label: 0\n",
            "data: [5.0, 3.4, 1.5, 0.2], pred: 0, label: 0\n",
            "data: [4.4, 2.9, 1.4, 0.2], pred: 0, label: 0\n",
            "data: [4.9, 3.1, 1.5, 0.1], pred: 0, label: 0\n",
            "data: [5.4, 3.7, 1.5, 0.2], pred: 0, label: 0\n",
            "data: [4.8, 3.4, 1.6, 0.2], pred: 0, label: 0\n",
            "data: [4.8, 3.0, 1.4, 0.1], pred: 0, label: 0\n",
            "data: [4.3, 3.0, 1.1, 0.1], pred: 0, label: 0\n",
            "data: [5.8, 4.0, 1.2, 0.2], pred: 0, label: 0\n",
            "data: [5.7, 4.4, 1.5, 0.4], pred: 0, label: 0\n",
            "data: [5.4, 3.9, 1.3, 0.4], pred: 0, label: 0\n",
            "data: [5.1, 3.5, 1.4, 0.3], pred: 0, label: 0\n",
            "data: [5.7, 3.8, 1.7, 0.3], pred: 0, label: 0\n",
            "data: [5.1, 3.8, 1.5, 0.3], pred: 0, label: 0\n",
            "data: [5.4, 3.4, 1.7, 0.2], pred: 0, label: 0\n",
            "data: [5.1, 3.7, 1.5, 0.4], pred: 0, label: 0\n",
            "data: [4.6, 3.6, 1.0, 0.2], pred: 0, label: 0\n",
            "data: [5.1, 3.3, 1.7, 0.5], pred: 0, label: 0\n",
            "data: [4.8, 3.4, 1.9, 0.2], pred: 0, label: 0\n",
            "data: [5.0, 3.0, 1.6, 0.2], pred: 0, label: 0\n",
            "data: [5.0, 3.4, 1.6, 0.4], pred: 0, label: 0\n",
            "data: [5.2, 3.5, 1.5, 0.2], pred: 0, label: 0\n",
            "data: [5.2, 3.4, 1.4, 0.2], pred: 0, label: 0\n",
            "data: [4.7, 3.2, 1.6, 0.2], pred: 0, label: 0\n",
            "data: [4.8, 3.1, 1.6, 0.2], pred: 0, label: 0\n",
            "data: [5.4, 3.4, 1.5, 0.4], pred: 0, label: 0\n",
            "data: [5.2, 4.1, 1.5, 0.1], pred: 0, label: 0\n",
            "data: [5.5, 4.2, 1.4, 0.2], pred: 0, label: 0\n",
            "data: [4.9, 3.1, 1.5, 0.2], pred: 0, label: 0\n",
            "data: [5.0, 3.2, 1.2, 0.2], pred: 0, label: 0\n",
            "data: [5.5, 3.5, 1.3, 0.2], pred: 0, label: 0\n",
            "data: [4.9, 3.6, 1.4, 0.1], pred: 0, label: 0\n",
            "data: [4.4, 3.0, 1.3, 0.2], pred: 0, label: 0\n",
            "data: [5.1, 3.4, 1.5, 0.2], pred: 0, label: 0\n",
            "data: [5.0, 3.5, 1.3, 0.3], pred: 0, label: 0\n",
            "data: [4.5, 2.3, 1.3, 0.3], pred: 0, label: 0\n",
            "data: [4.4, 3.2, 1.3, 0.2], pred: 0, label: 0\n",
            "data: [5.0, 3.5, 1.6, 0.6], pred: 0, label: 0\n",
            "data: [5.1, 3.8, 1.9, 0.4], pred: 0, label: 0\n",
            "data: [4.8, 3.0, 1.4, 0.3], pred: 0, label: 0\n",
            "data: [5.1, 3.8, 1.6, 0.2], pred: 0, label: 0\n",
            "data: [4.6, 3.2, 1.4, 0.2], pred: 0, label: 0\n",
            "data: [5.3, 3.7, 1.5, 0.2], pred: 0, label: 0\n",
            "data: [5.0, 3.3, 1.4, 0.2], pred: 0, label: 0\n",
            "data: [7.0, 3.2, 4.7, 1.4], pred: 1, label: 1\n",
            "data: [6.4, 3.2, 4.5, 1.5], pred: 1, label: 1\n",
            "data: [6.9, 3.1, 4.9, 1.5], pred: 1, label: 1\n",
            "data: [5.5, 2.3, 4.0, 1.3], pred: 1, label: 1\n",
            "data: [6.5, 2.8, 4.6, 1.5], pred: 1, label: 1\n",
            "data: [5.7, 2.8, 4.5, 1.3], pred: 1, label: 1\n",
            "data: [6.3, 3.3, 4.7, 1.6], pred: 1, label: 1\n",
            "data: [4.9, 2.4, 3.3, 1.0], pred: 0, label: 1\n",
            "data: [6.6, 2.9, 4.6, 1.3], pred: 1, label: 1\n",
            "data: [5.2, 2.7, 3.9, 1.4], pred: 1, label: 1\n",
            "data: [5.0, 2.0, 3.5, 1.0], pred: 1, label: 1\n",
            "data: [5.9, 3.0, 4.2, 1.5], pred: 1, label: 1\n",
            "data: [6.0, 2.2, 4.0, 1.0], pred: 1, label: 1\n",
            "data: [6.1, 2.9, 4.7, 1.4], pred: 2, label: 1\n",
            "data: [5.6, 2.9, 3.6, 1.3], pred: 0, label: 1\n",
            "data: [6.7, 3.1, 4.4, 1.4], pred: 0, label: 1\n",
            "data: [5.6, 3.0, 4.5, 1.5], pred: 2, label: 1\n",
            "data: [5.8, 2.7, 4.1, 1.0], pred: 0, label: 1\n",
            "data: [6.2, 2.2, 4.5, 1.5], pred: 1, label: 1\n",
            "data: [5.6, 2.5, 3.9, 1.1], pred: 1, label: 1\n",
            "data: [5.9, 3.2, 4.8, 1.8], pred: 2, label: 1\n",
            "data: [6.1, 2.8, 4.0, 1.3], pred: 0, label: 1\n",
            "data: [6.3, 2.5, 4.9, 1.5], pred: 2, label: 1\n",
            "data: [6.1, 2.8, 4.7, 1.2], pred: 1, label: 1\n",
            "data: [6.4, 2.9, 4.3, 1.3], pred: 0, label: 1\n",
            "data: [6.6, 3.0, 4.4, 1.4], pred: 1, label: 1\n",
            "data: [6.8, 2.8, 4.8, 1.4], pred: 1, label: 1\n",
            "data: [6.7, 3.0, 5.0, 1.7], pred: 2, label: 1\n",
            "data: [6.0, 2.9, 4.5, 1.5], pred: 1, label: 1\n",
            "data: [5.7, 2.6, 3.5, 1.0], pred: 0, label: 1\n",
            "data: [5.5, 2.4, 3.8, 1.1], pred: 1, label: 1\n",
            "data: [5.5, 2.4, 3.7, 1.0], pred: 0, label: 1\n",
            "data: [5.8, 2.7, 3.9, 1.2], pred: 0, label: 1\n",
            "data: [6.0, 2.7, 5.1, 1.6], pred: 2, label: 1\n",
            "data: [5.4, 3.0, 4.5, 1.5], pred: 2, label: 1\n",
            "data: [6.0, 3.4, 4.5, 1.6], pred: 1, label: 1\n",
            "data: [6.7, 3.1, 4.7, 1.5], pred: 1, label: 1\n",
            "data: [6.3, 2.3, 4.4, 1.3], pred: 1, label: 1\n",
            "data: [5.6, 3.0, 4.1, 1.3], pred: 0, label: 1\n",
            "data: [5.5, 2.5, 4.0, 1.3], pred: 1, label: 1\n",
            "data: [5.5, 2.6, 4.4, 1.2], pred: 1, label: 1\n",
            "data: [6.1, 3.0, 4.6, 1.4], pred: 1, label: 1\n",
            "data: [5.8, 2.6, 4.0, 1.2], pred: 1, label: 1\n",
            "data: [5.0, 2.3, 3.3, 1.0], pred: 0, label: 1\n",
            "data: [5.6, 2.7, 4.2, 1.3], pred: 1, label: 1\n",
            "data: [5.7, 3.0, 4.2, 1.2], pred: 0, label: 1\n",
            "data: [5.7, 2.9, 4.2, 1.3], pred: 1, label: 1\n",
            "data: [6.2, 2.9, 4.3, 1.3], pred: 1, label: 1\n",
            "data: [5.1, 2.5, 3.0, 1.1], pred: 0, label: 1\n",
            "data: [5.7, 2.8, 4.1, 1.3], pred: 1, label: 1\n",
            "data: [6.3, 3.3, 6.0, 2.5], pred: 2, label: 2\n",
            "data: [5.8, 2.7, 5.1, 1.9], pred: 2, label: 2\n",
            "data: [7.1, 3.0, 5.9, 2.1], pred: 2, label: 2\n",
            "data: [6.3, 2.9, 5.6, 1.8], pred: 2, label: 2\n",
            "data: [6.5, 3.0, 5.8, 2.2], pred: 2, label: 2\n",
            "data: [7.6, 3.0, 6.6, 2.1], pred: 2, label: 2\n",
            "data: [4.9, 2.5, 4.5, 1.7], pred: 2, label: 2\n",
            "data: [7.3, 2.9, 6.3, 1.8], pred: 2, label: 2\n",
            "data: [6.7, 2.5, 5.8, 1.8], pred: 2, label: 2\n",
            "data: [7.2, 3.6, 6.1, 2.5], pred: 2, label: 2\n",
            "data: [6.5, 3.2, 5.1, 2.0], pred: 2, label: 2\n",
            "data: [6.4, 2.7, 5.3, 1.9], pred: 2, label: 2\n",
            "data: [6.8, 3.0, 5.5, 2.1], pred: 2, label: 2\n",
            "data: [5.7, 2.5, 5.0, 2.0], pred: 2, label: 2\n",
            "data: [5.8, 2.8, 5.1, 2.4], pred: 2, label: 2\n",
            "data: [6.4, 3.2, 5.3, 2.3], pred: 2, label: 2\n",
            "data: [6.5, 3.0, 5.5, 1.8], pred: 2, label: 2\n",
            "data: [7.7, 3.8, 6.7, 2.2], pred: 2, label: 2\n",
            "data: [7.7, 2.6, 6.9, 2.3], pred: 2, label: 2\n",
            "data: [6.0, 2.2, 5.0, 1.5], pred: 2, label: 2\n",
            "data: [6.9, 3.2, 5.7, 2.3], pred: 2, label: 2\n",
            "data: [5.6, 2.8, 4.9, 2.0], pred: 2, label: 2\n",
            "data: [7.7, 2.8, 6.7, 2.0], pred: 2, label: 2\n",
            "data: [6.3, 2.7, 4.9, 1.8], pred: 2, label: 2\n",
            "data: [6.7, 3.3, 5.7, 2.1], pred: 2, label: 2\n",
            "data: [7.2, 3.2, 6.0, 1.8], pred: 2, label: 2\n",
            "data: [6.2, 2.8, 4.8, 1.8], pred: 2, label: 2\n",
            "data: [6.1, 3.0, 4.9, 1.8], pred: 2, label: 2\n",
            "data: [6.4, 2.8, 5.6, 2.1], pred: 2, label: 2\n",
            "data: [7.2, 3.0, 5.8, 1.6], pred: 2, label: 2\n",
            "data: [7.4, 2.8, 6.1, 1.9], pred: 2, label: 2\n",
            "data: [7.9, 3.8, 6.4, 2.0], pred: 2, label: 2\n",
            "data: [6.4, 2.8, 5.6, 2.2], pred: 2, label: 2\n",
            "data: [6.3, 2.8, 5.1, 1.5], pred: 2, label: 2\n",
            "data: [6.1, 2.6, 5.6, 1.4], pred: 2, label: 2\n",
            "data: [7.7, 3.0, 6.1, 2.3], pred: 2, label: 2\n",
            "data: [6.3, 3.4, 5.6, 2.4], pred: 2, label: 2\n",
            "data: [6.4, 3.1, 5.5, 1.8], pred: 2, label: 2\n",
            "data: [6.0, 3.0, 4.8, 1.8], pred: 2, label: 2\n",
            "data: [6.9, 3.1, 5.4, 2.1], pred: 2, label: 2\n",
            "data: [6.7, 3.1, 5.6, 2.4], pred: 2, label: 2\n",
            "data: [6.9, 3.1, 5.1, 2.3], pred: 2, label: 2\n",
            "data: [5.8, 2.7, 5.1, 1.9], pred: 2, label: 2\n",
            "data: [6.8, 3.2, 5.9, 2.3], pred: 2, label: 2\n",
            "data: [6.7, 3.3, 5.7, 2.5], pred: 2, label: 2\n",
            "data: [6.7, 3.0, 5.2, 2.3], pred: 2, label: 2\n",
            "data: [6.3, 2.5, 5.0, 1.9], pred: 2, label: 2\n",
            "data: [6.5, 3.0, 5.2, 2.0], pred: 2, label: 2\n",
            "data: [6.2, 3.4, 5.4, 2.3], pred: 2, label: 2\n",
            "data: [5.9, 3.0, 5.1, 1.8], pred: 2, label: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# process input flowers and compute gradient of batch\n",
        "def batch_grad(flower_indices, verbose = 0):\n",
        "    n = len(flower_indices)\n",
        "\n",
        "    gt_dataset = []\n",
        "    gt_labels = []\n",
        "    for flower_index in flower_indices:\n",
        "        gt_data = torch.tensor(dst.data[flower_index, :]).to(device)\n",
        "        gt_data = gt_data.view(1, *gt_data.size())\n",
        "        gt_dataset.append(gt_data)\n",
        "        gt_label = torch.tensor(dst.target[flower_index]).to(device)\n",
        "        gt_label = gt_label.view(1)\n",
        "        gt_labels.append(gt_label)\n",
        "        gt_onehot_label = label_to_onehot(gt_label, num_classes=3)\n",
        "\n",
        "        # print out (data, label) and verify onehot\n",
        "        if (verbose):\n",
        "            print(f\"gt_data: {gt_data}\")\n",
        "            print(f\"gt_label: {gt_label}\")\n",
        "            print(f\"gt_onehot_label: {gt_onehot_label}\")\n",
        "            print(f\"flower {flower_index} has label (gt, onehot) = ({gt_label.item()}, {torch.argmax(gt_onehot_label, dim=-1).item()})\")\n",
        "\n",
        "        # compute original gradient \n",
        "        out = net(gt_data.float())\n",
        "        y = criterion(out, gt_onehot_label)\n",
        "\n",
        "        if (flower_index == flower_indices[0]):\n",
        "          batch_dy_dx = torch.autograd.grad(y, net.parameters())\n",
        "        else:\n",
        "          batch_dy_dx = tuple(map(sum, zip(batch_dy_dx, torch.autograd.grad(y, net.parameters())))) # sum of gradients\n",
        "\n",
        "    batch_dy_dx = tuple(part/n for part in batch_dy_dx)\n",
        "    original_dy_dx = list((_.detach().clone() for _ in batch_dy_dx)) # share the gradients with other clients\n",
        "\n",
        "    # verifying dy_dx is average of list of flowers\n",
        "    if (verbose >= 2):\n",
        "      print(original_dy_dx)\n",
        "    \n",
        "    return original_dy_dx, gt_dataset, gt_labels"
      ],
      "metadata": {
        "id": "GWL_MjKJIZ9C"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mSgR4GClV-8"
      },
      "source": [
        "# DLG algorithm on a given set of flowers and returns the hypothesized input\n",
        "def batch_DLG(original_dy_dx, n, gt_data_len, gt_onehot_label_len, verbose = 0):\n",
        "\n",
        "    # identify (data, label) using Adam on the squared difference between the original and guessed gradient\n",
        "    dummy_data = [torch.randn(gt_data_len).to(device).requires_grad_(True) for i in range(n)]\n",
        "    dummy_label = [torch.randn(gt_onehot_label_len).to(device).requires_grad_(True) for i in range(n)]\n",
        "    optimizer = torch.optim.LBFGS(dummy_data+dummy_label)\n",
        "\n",
        "    global opt_steps; opt_steps = 0\n",
        "    for iters in range(100):\n",
        "\n",
        "        # closure function needed for LBFGS optimizer\n",
        "        def closure():\n",
        "            global opt_steps; opt_steps += 1\n",
        "\n",
        "            # compute gradient of dummy data/label\n",
        "            optimizer.zero_grad()\n",
        "            for i in range(n):\n",
        "                pred = net(dummy_data[i]) \n",
        "                #print(f\"prediction: {pred} from data: {dummy_data.data} and label: {dummy_label}\") # uncomment to see optimization updates\n",
        "                dummy_onehot_label = F.softmax(dummy_label[i], dim=-1)\n",
        "                dummy_loss = criterion(pred, dummy_onehot_label) if (i == 0) else dummy_loss + criterion(pred, dummy_onehot_label)\n",
        "            \n",
        "            dummy_loss /= n\n",
        "            dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
        "            \n",
        "            # compute loss function, i.e. the SE of the gradients\n",
        "            grad_diff = 0\n",
        "            grad_count = 0\n",
        "            for gx, gy in zip(dummy_dy_dx, original_dy_dx):\n",
        "                grad_diff += ((gx - gy) ** 2).sum()\n",
        "                grad_count += gx.nelement()\n",
        "\n",
        "            grad_diff.backward()\n",
        "            return grad_diff\n",
        "        \n",
        "        # perform GD and log information\n",
        "        optimizer.step(closure)\n",
        "        current_loss = closure()\n",
        "        if (verbose == 2):\n",
        "            print('current loss: ', iters, \"%.4f\" % current_loss.item())\n",
        "            print('dummy data: ', dummy_data)\n",
        "            print('dummy labels: ', dummy_label)\n",
        "        \n",
        "        # if current_loss is small enough, then the model has 'converged'\n",
        "        if (closure() < 1e-9):\n",
        "            break\n",
        "        #if (opt_steps >= 80): # setting an upper limit on the number of optimization steps (e.g. limited attacking capability)\n",
        "        #    break\n",
        "    \n",
        "    return dummy_data, opt_steps"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find best linear sum assignment\n",
        "def assign_guess(guess, gt_dataset, n, verbose = False):\n",
        "    cost_matrix = [[torch.sum((guess[i]-gt_dataset[j])**2).item() for j in range(n)] for i in range(n)]\n",
        "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
        "    best_MSE = sum([cost_matrix[row_ind[i]][col_ind[i]] for i in range(n)]) / n\n",
        "    if (verbose):\n",
        "        print('best guessed-actual assignment: ', col_ind)\n",
        "        print('best_MSE: ', best_MSE)\n",
        "\n",
        "    guess_perm = [None] * n\n",
        "    for i in range(n):\n",
        "        guess_perm[col_ind[i]] = guess[i]\n",
        "\n",
        "    return guess_perm"
      ],
      "metadata": {
        "id": "N9F7n7IR7MdX"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aokP-jhal96-"
      },
      "source": [
        "# testing Batch-DLG on n random flowers\n",
        "def test_rand(n = 10, verbose = False):\n",
        "    length = dst.data.shape[0]\n",
        "    perm = list(range(length))\n",
        "    shuffle(perm)\n",
        "    flower_indices = perm[0:n]\n",
        "    if (verbose):\n",
        "        print('flowers: ', flower_indices)\n",
        "\n",
        "    original_dy_dx, gt_dataset, gt_labels = batch_grad(flower_indices, 0)\n",
        "    guess, steps = batch_DLG(original_dy_dx, n, gt_dataset[0].size(), label_to_onehot(gt_labels[0]).size(), 1)\n",
        "    if (verbose):\n",
        "        print(f\"Original data: {gt_dataset}\")\n",
        "        print(f\"Predicted data: {guess}\")\n",
        "        print('steps: ', steps)\n",
        "\n",
        "    guess_perm = assign_guess(guess, gt_dataset, n, verbose)\n",
        "\n",
        "    if (verbose):\n",
        "        print('side by side comparison of guessed to actual input data: ')\n",
        "    avg_cos_angle = 0\n",
        "    cos_angles = []\n",
        "    SEs = []\n",
        "    n_errors = []\n",
        "    best_MSE = 0\n",
        "    for i in range(n):\n",
        "        SE = torch.sum((guess_perm[i]-gt_dataset[i])**2).item()\n",
        "        cos_angle = (torch.sum(guess_perm[i]*gt_dataset[i]).item() / (torch.linalg.norm(gt_dataset[i]) * torch.linalg.norm(guess_perm[i]))).item()\n",
        "        cos_angles.append(cos_angle); avg_cos_angle += cos_angle\n",
        "        best_MSE += SE; SEs.append(SE)\n",
        "        n_error = (torch.sum((guess_perm[i]-gt_dataset[i])**2) / (torch.linalg.norm(gt_dataset[i])**2)).item(); n_errors.append(n_error)\n",
        "\n",
        "        if (verbose):\n",
        "            print(i, ':', gt_dataset[i].tolist(), guess_perm[i].tolist())\n",
        "            print('SE: ', SE, 'cos(angle): ', cos_angle)\n",
        "\n",
        "    avg_cos_angle /= n\n",
        "    best_MSE /= n\n",
        "    if (verbose):\n",
        "        print('average cos(angle): ', avg_cos_angle)\n",
        "        print('MSE: ', best_MSE)\n",
        "        print(cos_angles)\n",
        "        print(SEs)\n",
        "        print(n_errors)\n",
        "    \n",
        "    return SEs, cos_angles, n_errors, steps"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing batch-DLG on 20 groups of 10 flowers\n",
        "test_len = 5\n",
        "errors = []\n",
        "cos_angles = []\n",
        "n_errors = []\n",
        "optimization_steps = []\n",
        "for i in range(test_len):\n",
        "    terrors, tcos_angles, tn_errors, steps = test_rand(10, False)\n",
        "    #print(terrors, tcos_angles)\n",
        "    errors += terrors\n",
        "    optimization_steps.append(steps)\n",
        "    cos_angles += tcos_angles\n",
        "    n_errors += tn_errors\n",
        "    \n",
        "print(errors)\n",
        "print(optimization_steps)\n",
        "print(cos_angles)\n",
        "print(n_errors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_cCVDkdlAyt",
        "outputId": "a414595d-8286-49eb-d841-e4fdc416fb8f"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[71.97690738740079, 73.08386773001092, 60.55103630897374, 56.74437346302798, 78.08473695584902, 83.37112213894602, 51.160970099069786, 46.30542188563271, 66.82553898658894, 64.41675203445163, 84.8018292331946, 99.3010119294346, 80.67740082779684, 89.55729321001517, 62.40158325555652, 85.67480604640866, 81.78850588840066, 101.81348609421485, 70.67511714953869, 60.32316884106615, 52.77329517272462, 102.43549895361929, 113.02956647621883, 106.96385177192543, 83.6987031804959, 43.79172106508773, 64.03780086634666, 81.91357637017578, 76.19784659568796, 87.41787360307283, 8432.848458838245, 628.704132116467, 79.77403715299316, 52121.52110698439, 8430.763844555117, 877.4898616980054, 369627.11103524035, 1010.8163550701688, 28.399823939505318, 100402.85169034167, 61.33772453436384, 30.38210841841004, 64.1720657132855, 44.94289944827831, 81.9585838440767, 61.5822452385606, 65.58686779594376, 76.15174783520911, 66.73866229168732, 64.53119710473666]\n",
            "[324, 320, 312, 364, 314]\n",
            "[-0.2928278485282718, -0.5783123230526864, -0.25171892748588254, -0.3926703404088362, 0.8112220535851475, -0.0009486081496386893, 0.430901841134989, 0.4875155581489219, 0.9215090827218553, 0.7852579786684922, -0.08798039858558092, 0.14722809372559648, -0.23524103823572354, -0.4658446600396681, -0.3496472968121756, -0.20117091369781326, -0.32068873877830373, 0.5080926585693899, -0.7700595338233917, 0.518368178242488, 0.599444001887817, -0.03321622672126932, 0.16056379606033652, -0.32754604568941925, 0.7402316742545623, -0.4727324664033535, -0.20945949009500836, -0.36462157357251024, 0.6566553582413588, 0.30435454526265504, 0.06912979540551746, 0.020939256309235536, -0.05172421948178484, 0.10122784123848175, 0.8676875187480063, -0.02605473059723153, 0.8529717949538006, 0.09241819101654107, 0.5393592477904923, 0.16226840388892044, 0.03250907925184239, 0.6154653337132221, 0.06987692521532808, -0.14297246205951492, 0.5456246611755887, -0.578615624053861, 0.24925338674506936, -0.8960604304584081, 0.5724009734464393, 0.4431664730255552]\n",
            "[1.328232282476486, 1.2635523466461087, 1.1126614536746369, 1.3361048613851656, 0.6805956328410095, 1.1082164314627945, 0.8154442157964583, 0.8041928080172406, 0.7360451479963533, 0.7828017017189408, 1.0606857940362053, 0.9800731536659553, 1.2834457656346936, 1.215160016418116, 1.2308004586894776, 1.2647594633364134, 1.2201776202954, 0.8358384869404386, 2.3740381978346887, 0.8207233855927366, 0.7143109795983299, 1.0837441700552186, 0.9742248446493607, 1.1022655788533122, 0.6779418692734155, 1.6029180477704146, 1.2396012556396956, 1.1777652964798817, 0.8221606236047471, 0.9141260441605438, 235.02922126082063, 11.636204555181697, 1.0797785212911903, 1127.6832779529293, 106.93510711003444, 25.740389020182032, 4287.022860533985, 28.148603594268128, 0.7092863121754575, 3675.0677778309546, 1.0111725112819625, 0.7044309858198478, 1.0305454587005862, 1.2837160653607056, 0.7570532407544496, 1.577818222868578, 0.9413932509823997, 1.8279344175518266, 0.6910194894562779, 0.8577854194435288]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def graph_results(errors, optimization_steps, cos_angles, n_errors):\n",
        "    # visually represent errors in a histogram\n",
        "    plt.hist([math.log(elt) for elt in errors], 50)\n",
        "    plt.title('Distribution of log(SE) of Guessed to Real Input on with 80-100 steps')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.xlabel('Squared Error (cm^2)')\n",
        "    print('*** change caption This graph was generated on the entire IRIS dataset consisting of 150 flowers.\\nIt utilizes a randomly initialized fully connected NN as its prediction algorithm.')\n",
        "    #plt.savefig('batch-dlg-SE-t.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # visually represent normalized errors in a histogram (SE / true norm squared)\n",
        "    plt.hist(n_errors, 50)\n",
        "    plt.title('Distribution of normalized errors with 80-100 steps')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.xlabel('normalized error (SE / true norm squared)')\n",
        "    #plt.savefig('batch-dlg-PE-t.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # visually represent number of optimization steps\n",
        "    plt.hist(optimization_steps, 10)\n",
        "    plt.title('Distribution of Optimization Steps of DLG with 80-100 steps')\n",
        "    plt.xlabel('Number of Optimization Steps')\n",
        "    plt.ylabel('Frequency')\n",
        "    #plt.savefig('batch-dlg-steps-t.png', dpi=300)\n",
        "    print('Note that the number of optimization steps is measured in terms of the number of times the closure function is called in the LBFGS optimizer')\n",
        "    plt.show()\n",
        "\n",
        "    # visually represent avg_cos_angles\n",
        "    plt.hist(cos_angles, 50)\n",
        "    plt.title('Distribution of cos(angles) of DLG with 80-100 steps')\n",
        "    plt.xlabel('cos(angle) similarity')\n",
        "    plt.ylabel('Frequency')\n",
        "    #plt.savefig('batch-dlg-cangles-t.png', dpi=300)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "P9169qMxmAWG"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_results(errors, optimization_steps, cos_angles, n_errors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4COPiX7zmWPo",
        "outputId": "a0625c3a-a4e0-4abe-f3cb-48817fef7def"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** change caption This graph was generated on the entire IRIS dataset consisting of 150 flowers.\n",
            "It utilizes a randomly initialized fully connected NN as its prediction algorithm.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAEWCAYAAADVW8iBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debgcVZ3/8feHBEgCYc0V2UJYAxHZDKADCAI+gz/WmUEGBGTTuKGI8GMZcMw4LrijAiIiBtkR2VGHiAZlZAub7IsQQgiQG/aENfCdP87ppNLpu3bnVtfN5/U8/dxaT32ruqq+darOrVZEYGZmVgVLlR2AmZlZbzlpmZlZZThpmZlZZThpmZlZZThpmZlZZThpmZlZZbQkaUk6U9JXW1TWaElzJA3J/VMkfaoVZefyfi/pkFaV14flfkPSbEnPNhi3k6QZLVzWRZL2aUE5e0q6pIn5h0u6RtLLkn7TbDztSNI0SbuWHUdfSBojKSQNLTuWdiNpB0kPdzPe265kPSatfFC+LulVSS9J+pukz0qaP29EfDYi/ruXZXV7gEfE9IhYPiLe6d0qdLu8iZLOryv/YxFxbrNl9zGO0cAxwLiIeO9iXtZmwObAVbl/GUk/kDQjXwxMk3RqYfra9zun8DkNICKuAd6Xy+yPfYHVgFUj4uNdxLuhpIsldUp6RdKjkn4qaa1+LrNtSJok6RtNzD9F0hv5O5kt6XJJq7cyxi6WOyCJuNHxWbaI+GtEjK31N7stJC2bL+qfk/RCvohbszB+FUlXSJor6UlJn+ihvP+WdK+keZImNhj/iVzOXElXSlqlv8vqYvmlJ+3e1rT2jIiRwDrAKcDxwC9bHcwgvnoZDTwfEbMGYFmfAS6IBf81fiIwHtgGGAnsBNxZN8+e+UKh9jmyMO4iYEI/Y1kHeCQi5jUaKWkD4FZgJrBlRKwAbAf8A9i+n8scbI6MiOWBDYDlge+XHI/1zVHAh4DNgDWAF4GfFsafDrxFurg7EPiZpPd1U95jwHHAdfUj8nw/Bw7O5b0GnNHEstpTRHT7AaYBu9YN2wZ4F9g0908CvpG7RwHXAi8BLwB/JSXH8/I8rwNzSBt+DBDAEcB04C+FYUNzeVOAbwO3Aa+QahCr5HE7ATMaxQvsRvqC3s7Lu6dQ3qdy91LAycCTwCzg18CKeVwtjkNybLOBk7rZTivm+TtzeSfn8nfN6/xujmNSg3kXWg9gkxznS8D9wF6FcasC1+RtcTvwDeCmwvjHge0L/dcCX+7L91s3fjvgiW7GN4wV+K+67X9Eg3nPB67pYf87tLh+eVgAG+TuZUkn8unAc8CZwPDu9sU87njgaeBV4GFgl8I+cQIpcT4PXFrb3/L4g/P3+zxwUlfbj5To387bYE5tPbv7bhuUMYW8r+b+zwP3F/o3BibndXsY2K8wbnfgrryfPAVMLIwbQ+EY626fqG3/vI1fBJ4APlYXY8uOz97uX4XzzumkE/irpAug9bso51zgmNy9Zl7/L+T+9fM2XKoYM92fs3p7XvgZ8N267+Xh3L1c3gYbFcafB5zS3TFROHYm1g37FnBhoX/9XP7Ivi6LdI6fmr/T54Af5uHT8/rPyZ8P5eGHAw/mfeR/gHXqjtcvkc5Ns4HvseA43AC4EXg5j7ukx3XvxcaZRuODcjrwucLOU0ta3yadOJbOnx0ANSqrsAP8Om/U4TROWk8Dm+Zpfguc39NBkbsn1qZtdCLIG/oxYD3SVezlwHl1sf0ix7U58CawSRfb6dekA3ZknvcR8om6UZx1884fn7fZY8B/AMsAO5MOyLF5/MX5MwIYRzoh3VQ4CALoKJR9cv6uPg+8v/Zd9PT9FsavkstcocG4nmJdZPvXzf8scGgP+9+hdJ+0fgRcneMcSUro3+5uXwTG5u22RuG7Xj93HwXcAqxFSog/By7K48aRDtQP53E/BOZ1tf0oHBe92V4N5p/Cgn11VeCPwFWF7/op4DBgKLAl6aAfV9in3k86EW9GOvHsU7dv9zZpvQ18GhgCfI5UM1YhxpYdn33cvyaRLh62ydvgAuDiLso6nAUXDp8gXZRcUhh3VaOY6fqc1dvzwnjgf0m1rBHAhcCpedyWwGt10x9LDxdyebpGSesq4Pi6YXOAD/R1WcDNwMG5e3ngg13tO8De+XvaJH8PJwN/qzte/0w6RkeTzo21/foi0sXfUsAwChfcXX2aaYgxMwdR721gdVKmfTvSPeLooayJETE3Il7vYvx5EXFfRMwFvgrsV2uo0aQDSVcQj0fEHNKttP3rblP+V0S8HhH3APeQdtKF5Fj2B06MiFcjYhrwA9JVeV99kLSTnBIRb0XEn0i1hQPycv4N+FpEvBYRD5CuIGtWyn9fLQz7NvCdvK5TgacbNES5Mj+vrH0+XRhXK2slFtVlrL1c11GkxAWApCPz8udI+kVPM0sSqUZzdES8EBGvkq4298+TdLUvvkNKOuMkLR0R0yLiH3mez5KunGdExJukE+u+eZ/YF7g2Iv6Sx32VdCXeW/3ZXj+RVLsKHQV8MQ/fA5gWEb+KiHkRcRcpYXwcICKmRMS9EfFuRPyddHLYsQ+xFj0ZEb+I9Jz5XNI2Xa0wfnEdn73ZXldExG2RbkFfAGzRRVk3AtvnZ/EfBr5LuosAabvc2MfYejwvZI+SLi6eJtVaNgG+nsctn4cVvUy6+OqP5fP8jcrr67LeBjaQNCoi5kTELd0s97OkC8UH8/fwLWALSesUpvlOPkanA6ey4Dt8m/QYYY2IeCMibuphHZtKWmuSqtT1vkfKutdLelzSCb0o66k+jH+SdAU2qldRdm+NXF6x7KEsfEAWW/u9Rvry643KMdWXtWaDaXsT01MRUTwZ1srqyPEVt0ex+6X8d/6OGBHvRMTpEbEdKfF8EzhH0iaF+faJiJUKn2LCqJX1EovqLtbeeJ50AqzFelpErETaqZfuxfwdpKvXO2oJF/hDHg5d7IsR8RjwZVJCmpUbgqyR51kHuKJQ3oOkJLdabX0L8c7N69Bb/dleX4qIFUm1pZVJNcBanNsWLzZIFybvBZC0raQ/5wYuL5NOLP09ZuYfAxHxWu4sHgeL8/jsaXv15vgkX5TMJSW1HUjJb6aksfQvafVquaTbl8uSasrLke7m/D6PmwOsUDf9CuQLRUn3FxpH7dCLmLorr9tlNXAEsBHwkKTbJe3RzXLXAX5c2A9fIN3RKH5P9ftI7Xg7Lk97W17fw7tZDtDPpCVp6xzQIlkx1zSOiYj1gL2Ar0japTa6iyJ7qomtXegeTcrOs0k74YhCXENYcMLqTbkzSRu8WPY80q2UvpjNgiuGYllP97GcWkxrq9A6s1BWZ46v2LJu/rbJJ9F/kHa2ReQrw9NJ953H9TKeTUhX9PVXaT3F2hs3AP/awzT133Gx9eVs0vOG9xUS7oqRGi50uy9GxIURsT3pOwtSbRTSwfWxuiQ+LCKeBp6hsL0ljSCdjLpSv//1e3tFxL2k55en5xrmU8CNdXEuHxGfy7NcSLptunZOemeSTg6Lw+I8PpvZv+rdSKotL5O/zxtJz6ZWBu7uYp6eYuzJFqTn2C/k2vlPgW0kjSLdJhsqacPC9JuTnt0REe+LBY2j/tqLZd1PocYnaT1Swnykp2XVi4hHI+IA4D2kY+MySbXHD/WeAj5Tty8Oj4i/Faap30dm5uU8GxGfjog1SI3IzsgNtLrUp6QlaYWccS8m3Yu+t8E0e0jaIB9YL5OuUmtXSs+Rnh/11UGSxuWTxNeBy/KtikeAYZJ2l7Q06V7qsoX5ngPG1O30RRcBR0taV9LypGrtJdFFa7eu5FguBb4paWSuFn+FdN+5r24lXbkdJ2lpSTsBe5Lu1b9DulKbKGmEpI2BT9bN/zsKt4EkfVnp/8CGSxqabw2OJD2k740dWXBl2OtYe1n2RGAHST9UbgacD+ZiLfAeUrP7LSQNy/MAkK/AfwH8SNJ78vxrSvrn3N1wX5Q0VtLOkpYF3mBBQxlIJ/dv1m5tSOqQtHcedxmwh6TtJS1D2he7O4bq9/dmt9e5pBrfXqSawkaSDs5lLS1p60INeiTwQkS8IWkb0nOcxWVxHZ/Nbq96NwJHkhp8QXoedyTpmWlX/2LT33NWze3AJyWtmLfB54GZETE7X2ReDnxd0nKStiM9Hzqvq8LydhhG2u+GShpWuBV7AbCn0v+aLUf6Li7PF299WpakgyR15GOsdpflXdKF87t12+RM4ETlloh5Xev/xeX/S1pZ0tqk58aX5Gk/rgX/3vIiKSl2f8s9en7gN410UL9KOvBvBr4ADClMM4kFDTGOzvPMBWYAX42FH9hNzxvhWBo/1FtoGIu2TroGGFWY/lDSFfCsXOY0FjzoXZVUG3wRuLNQXrH14H+SrhQ6SUlm5UZx1M/bYDutnOfvzOX9JwtayOxELxti5P73saBFzQPAvxTGdZBaS9VaD34HuKEwflPS1VPtQfkE4I5c1kt5O+7R4PudU/hcURh/L7B5N7F3F+tEunnQnqcZS0r4s1nQku+npBpCbZqT8vingINYuCHGMNLFxuN5mzxIuqUGXeyLpFttt+XlvUBKALVGGUuRLjgezuP/AXyrEMshpH2429aDedoNSVfwLwFX9rS9Gsy/yP5GavU4tbDtriPtc88DfwK2yOP2Jd2GeTWv32ksaCAxhj62HqwbX9z+U2jh8dnH/WsSCzd02Ynuj7OxOfZDcv+KpDsXx3dVBr07Zy3yPRXGrUpKJrNyGTcB2xTGrwJcSdpHpwOf6OF4mZSXX/wcWhj/iVzOXAotOfu6LNK5bBbpfHA/uRFPHvd10j73EgsaaBxMOlfUWqueU7e/1FoPPk963j8kj/suqeY8h3SsTehu/SNi/onNKkrSd4D3RsQhhWEXApdGxJVNlr0nqQXRfk2GaYOUpCmkZHh22bFYe5IUwIaRniU3bbD+M++glW8JLkO6qtma9MB0oddcRURLbgVFeiPGNa0oy8ysFZy0qmck6VncGqT77T8gv7LJzGyw8+1BMzOrDP80iZmZVUalbw+OGjUqxowZU3YYZmaVcscdd8yOiI6ep2w/lU5aY8aMYerUqWWHYWZWKZKe7Hmq9uTbg2ZmVhlOWmZmVhlOWmZmVhlOWmZmVhlOWmZmVhlOWmZmVhlOWmZmVhlOWmZmVhlOWmZmVhmVfiNGuxtzwnV9mn7aKbsvpkjMzAYH17TMzKwynLTMzKwynLTMzKwynLTMzKwynLTMzKwynLTMzKwynLTMzKwynLTMzKwynLTMzKwynLTMzKwynLTMzKwySklaks6RNEvSfYVh35P0kKS/S7pC0kplxGZmZu2rrJrWJGC3umGTgU0jYjPgEeDEgQ7KzMzaWylJKyL+ArxQN+z6iJiXe28B1hrwwMzMrK216zOtw4Hflx2EmZm1l7ZLWpJOAuYBF3QxfoKkqZKmdnZ2DmxwZmZWqrZKWpIOBfYADoyIaDRNRJwVEeMjYnxHR8eAxmdmZuVqm18ulrQbcBywY0S8VnY8ZmbWfspq8n4RcDMwVtIMSUcApwEjgcmS7pZ0ZhmxmZlZ+yqlphURBzQY/MsBD8TMzCqlrZ5pmZmZdcdJy8zMKsNJy8zMKsNJy8zMKsNJy8zMKsNJy8zMKsNJy8zMKsNJy8zMKsNJy8zMKsNJy8zMKsNJy8zMKsNJy8zMKsNJy8zMKsNJy8zMKsNJy8zMKsNJy8zMKsNJy8zMKsNJy8zMKsNJy8zMKsNJy8zMKsNJy8zMKsNJy8zMKsNJy8zMKqOUpCXpHEmzJN1XGLaKpMmSHs1/Vy4jNjMza19l1bQmAbvVDTsBuCEiNgRuyP1mZmbzlZK0IuIvwAt1g/cGzs3d5wL7DGhQZmbW9trpmdZqEfFM7n4WWK3MYMzMrP20U9KaLyICiEbjJE2QNFXS1M7OzgGOzMzMytROSes5SasD5L+zGk0UEWdFxPiIGN/R0TGgAZqZWbnaKWldDRySuw8BrioxFjMza0NlNXm/CLgZGCtphqQjgFOAj0p6FNg195uZmc03tIyFRsQBXYzaZUADMTOzSmmn24NmZmbdctIyM7PKcNIyM7PKcNIyM7PKcNIyM7PKcNIyM7PKcNIyM7PKcNIyM7PKcNIyM7PKcNIyM7PKcNIyM7PKcNIyM7PKcNIyM7PKcNIyM7PKcNIyM7PKcNIyM7PKcNIyM7PKcNIyM7PKcNIyM7PKcNIyM7PKcNIyM7PKcNIyM7PKaCppSXp/qwIxMzPrSbM1rTMk3Sbp85JWbEVAko6WdL+k+yRdJGlYK8o1M7PqayppRcQOwIHA2sAdki6U9NH+lidpTeBLwPiI2BQYAuzfTIxmZjZ4NP1MKyIeBU4Gjgd2BH4i6SFJ/9rPIocCwyUNBUYAM5uN0czMBodmn2ltJulHwIPAzsCeEbFJ7v5RX8uLiKeB7wPTgWeAlyPi+rplTpA0VdLUzs7OZsI3M7OKabam9VPgTmDziPhCRNwJEBEzSbWvPpG0MrA3sC6wBrCcpIOK00TEWRExPiLGd3R0NBm+mZlVSbNJa3fgwoh4HUDSUpJGAETEef0ob1fgiYjojIi3gcuBf2oyRjMzGySaTVp/BIYX+kfkYf01HfigpBGSBOxCuvVoZmbWdNIaFhFzaj25e0R/C4uIW4HLSLcc783xndVkjGZmNkgMbXL+uZK2qj3LkvQB4PVmCoyIrwFfazIuMzMbhJpNWl8GfiNpJiDgvcC/Nx2VmZlZA00lrYi4XdLGwNg86OHcgMLMzKzlmq1pAWwNjMllbSWJiPh1C8o1MzNbSFNJS9J5wPrA3cA7eXAATlpmZtZyzda0xgPjIiJaEYyZmVl3mm3yfh+p8YWZmdli12xNaxTwgKTbgDdrAyNirybLNTMzW0SzSWtiK4IwMzPrjWabvN8oaR1gw4j4Y37v4JDWhGZmZrawZn+a5NOk1y79PA9aE7iy2aDMzMwaabYhxheA7YBXYP4PQr6n2aDMzMwaaTZpvRkRb9V68q8Nu/m7mZktFs0mrRsl/QcwXNJHgd8A1zQflpmZ2aKaTVonAJ2knxH5DPA7+vGLxWZmZr3RbOvBd4Ff5I+Zmdli1ey7B5+gwTOsiFivmXLNzMwaacW7B2uGAR8HVmmyTDMzs4aaeqYVEc8XPk9HxKnA7i2KzczMbCHN3h7cqtC7FKnm1Yrf6DIzM1tEswnmB4XuecA0YL8myzQzM2uo2daDH2lVIGZmZj1p9vbgV7obHxE/bKZ8MzOzola0HtwauDr37wncBjzaZLlmZmaLaDZprQVsFRGvAkiaCFwXEQf1t0BJKwFnA5uS/gfs8Ii4uck4zcxsEGg2aa0GvFXofysPa8aPgT9ExL6SlgFGNFmemZkNEs0mrV8Dt0m6IvfvA5zb38IkrQh8GDgUIL9B/q3u5jEzsyVHs/9c/E3gMODF/DksIr7VRJHrkl7A+ytJd0k6W9JyxQkkTZA0VdLUzs7OJhZlZmZV0+xb3iHdvnslIn4MzJC0bhNlDQW2An4WEVsCc0lvkp8vIs6KiPERMb6jo6OJRZmZWdU0lbQkfQ04HjgxD1oaOL+JImcAMyLi1tx/GSmJmZmZNV3T+hdgL1KNiIiYCYzsb2ER8SzwlKSxedAuwANNxmhmZoNEsw0x3oqIkBQA9c+f+umLwAW55eDjpGdmZmZmTSetSyX9HFhJ0qeBw2nyByEj4m4W/skTMzMzoImkJUnAJcDGwCvAWOA/I2Jyi2IzMzNbSL+TVr4t+LuIeD/gRGVmZotdsw0x7pS0dUsiMTMz60Gzz7S2BQ6SNI3UglCkSthmzQZmZmZWr19JS9LoiJgO/HOL4zEzM+tSf2taV5Le7v6kpN9GxL+1MigzM7NG+vtMS4Xu9VoRiJmZWU/6m7Sii24zM7PFpr+3BzeX9AqpxjU8d8OChhgrtCQ6MzOzgn4lrYgY0upAzMzMetJsk3cDxpxw3WItZ9opu7ekfDOzqmvF72mZmZkNCCctMzOrDCctMzOrDCctMzOrDCctMzOrDCctMzOrDCctMzOrDCctMzOrDCctMzOrDCctMzOrDCctMzOrDCctMzOrjLZLWpKGSLpL0rVlx2JmZu2l7ZIWcBTwYNlBmJlZ+2mrpCVpLWB34OyyYzEzs/bTVkkLOBU4Dni3qwkkTZA0VdLUzs7OgYvMzMxK1zZJS9IewKyIuKO76SLirIgYHxHjOzo6Big6MzNrB22TtIDtgL0kTQMuBnaWdH65IZmZWTtpm6QVESdGxFoRMQbYH/hTRBxUclhmZtZG2iZpmZmZ9WRo2QE0EhFTgCklh2FmZm3GNS0zM6sMJy0zM6sMJy0zM6sMJy0zM6sMJy0zM6sMJy0zM6sMJy0zM6sMJy0zM6sMJy0zM6sMJy0zM6uMtnyNU7sac8J1ZYdgZrZEc03LzMwqw0nLzMwqw0nLzMwqw0nLzMwqw0nLzMwqw0nLzMwqw0nLzMwqw0nLzMwqw0nLzMwqw0nLzMwqw0nLzMwqw0nLzMwqo62SlqS1Jf1Z0gOS7pd0VNkxmZlZ+2i3t7zPA46JiDsljQTukDQ5Ih4oOzAzMytfW9W0IuKZiLgzd78KPAisWW5UZmbWLtqtpjWfpDHAlsCtdcMnABMARo8e3e/yu/ttrGmn7N7vcm3x6up783e2gLeRDWZtVdOqkbQ88FvgyxHxSnFcRJwVEeMjYnxHR0c5AZqZWSnaLmlJWpqUsC6IiMvLjsfMzNpHWyUtSQJ+CTwYET8sOx4zM2svbZW0gO2Ag4GdJd2dP/+v7KDMzKw9tFVDjIi4CVDZcZiZWXtqt5qWmZlZl5y0zMysMpy0zMysMpy0zMysMpy0zMysMpy0zMysMpy0zMysMpy0zMysMpy0zMysMpy0zMysMtrqNU7W2GD+faTBvG7Weot7f2nH/bEdYyqTa1pmZlYZTlpmZlYZTlpmZlYZTlpmZlYZTlpmZlYZTlpmZlYZTlpmZlYZTlpmZlYZTlpmZlYZTlpmZlYZTlpmZlYZTlpmZlYZbZe0JO0m6WFJj0k6oex4zMysfbRV0pI0BDgd+BgwDjhA0rhyozIzs3bRVkkL2AZ4LCIej4i3gIuBvUuOyczM2oQiouwY5pO0L7BbRHwq9x8MbBsRRxammQBMyL1jgYcHPNCujQJmlx1EyZb0beD19/pXYf3XiYiOsoPoj8r9CGREnAWcVXYcjUiaGhHjy46jTEv6NvD6e/2X5PUfCO12e/BpYO1C/1p5mJmZWdslrduBDSWtK2kZYH/g6pJjMjOzNtFWtwcjYp6kI4H/AYYA50TE/SWH1RdtedtygC3p28Drv2Rb0td/sWurhhhmZmbdabfbg2ZmZl1y0jIzs8pw0mohSUMk3SXp2rJjGWiSVpJ0maSHJD0o6UNlxzSQJB0t6X5J90m6SNKwsmNa3CSdI2mWpPsKw1aRNFnSo/nvymXGuDh1sf7fy8fA3yVdIWmlMmMcjJy0Wuso4MGygyjJj4E/RMTGwOYsQdtB0prAl4DxEbEpqRHR/uVGNSAmAbvVDTsBuCEiNgRuyP2D1SQWXf/JwKYRsRnwCHDiQAc12DlptYiktYDdgbPLjmWgSVoR+DDwS4CIeCsiXio3qgE3FBguaSgwAphZcjyLXUT8BXihbvDewLm5+1xgnwENagA1Wv+IuD4i5uXeW0j/a2ot5KTVOqcCxwHvlh1ICdYFOoFf5dujZ0taruygBkpEPA18H5gOPAO8HBHXlxtVaVaLiGdy97PAamUGU7LDgd+XHcRg46TVApL2AGZFxB1lx1KSocBWwM8iYktgLoP7ttBC8nObvUnJew1gOUkHlRtV+SL9P80S+T81kk4C5gEXlB3LYOOk1RrbAXtJmkZ6M/3Oks4vN6QBNQOYERG35v7LSElsSbEr8EREdEbE28DlwD+VHFNZnpO0OkD+O6vkeAacpEOBPYADw/8I23JOWi0QESdGxFoRMYb0AP5PEbHEXGlHxLPAU5LG5kG7AA+UGNJAmw58UNIISSKt/xLTEKXO1cAhufsQ4KoSYxlwknYjPSbYKyJeKzuewaitXuNklfZF4IL8zsjHgcNKjmfARMStki4D7iTdErqLJeB1PpIuAnYCRkmaAXwNOAW4VNIRwJPAfuVFuHh1sf4nAssCk9P1C7dExGdLC3IQ8muczMysMnx70MzMKsNJy8zMKsNJy8zMKsNJy8zMKsNJy8zMKsNJy0on6aT8hvS/S7pb0rZlxwTpn0QlndbF8M4ca+0zbjHGMVzSjZKGtKi8oZKukzRb0qZ14xq+pVzS+yVNasXyzZrhpGWlyj9hsgewVX4z9q7AU4t5ma04+V8SEVsUPgv9M3V+cW6X/d3E1mi6w4HLI+Kd/oe7kJ8BD5FeZntJftlzTcO3lEfEvcBakka3KAazfnHSsrKtDsyOiDcBImJ2RMyE9HaBfNV/p6Sf1H6nTNJEScfWCsi/YTUmd18p6Y5cc5tQmGaOpB9Iugf4kKSDJN2Wa0k/ryUySYdJekTSbaTXc/WapJ0k/VXS1cADDfqHSfqVpHvzi4U/kuc7VNLVkv5E+jmPegdSeLOEpONzGfdIOiUPmyLpR5KmKv2e2daSLs+/a/WNwrxfI73Q95iIuAn4FHBRflN/T28pv4Yl4ydXrJ1FhD/+lPYBlgfuJl3VnwHsmIcPI9W4NgQEXApcm8dNBI4tlHEfMCZ3r5L/Ds/DV839AeyXuzchnYCXzv1nAJ8kJdDpQAewDPC/wGkNYj6U9Fb7uwuf4aS3I8wF1s3T1fcfA5yTuzfOyxqWy5tRi71uWcsAzxb6Pwb8DRhRt75TgO/k7qNIP42yOuntDDNq26GP3801wEGF/u2Aa8reZ/xZsj+uaVmpImIO8AFgAikRXJJfOLox6SW0j0ZEAL19AfGXcm3qFmBtUtIDeAf4be7eJS/zdkl35/71gG2BKZFefPsWcEk3y6m/Pfh6Hn5bRDxRmK7Yv31tPSLiIdJrjjbK4yZHRP1vUwGMAoq/TbYr8KvI77Wrm+fq/Pde4P6IeCZSDfbxvC16rYu3lM8ivcXerDR+96CVLtKzminAFEn3kl60enc3s8xj4VvbwyDdniOd1D8UEa9JmlIbB7wRCzJVJQwAAAGaSURBVJ4JCTg3Ihb6VVlJrfjBwrk99Pd2vprXWbAOPXkz/3230F3r7/WxXnhL+S75gqFmWI7HrDSuaVmpJI2VtGFh0BakGshDwBhJ6+fhBxSmmUb+6RNJW5F+xwpgReDFnLA2Bj7YxWJvAPaV9J5cxiqS1gFuBXaUtKqkpYGPN72CC/sr6fkUkjYCRgMPdzdDRLwIDJFUS1yTgcMkjajF3soAe3hL+UakW65mpXHSsrItD5wr6QFJfwfGARMj4g3SLcPrJN3Jwr/L9FtgFUn3A0eSnocB/AEYKulB0tvGb2m0wEgt/U4Grs/LnAysHukXdycCN5OeZ3X38yL/XtfkvTe/n3UGsFSuTV4CHJpv3/XketKtRSLiD6TbgFPzrc1ju5uxH04DRpLeUn63pDML4z4CXNfi5Zn1id/ybpWQb/0dGxF7lB3LQMu1yaMj4uASY1gWuBHYPha0LjQbcK5pmbW5iLgT+HOr/rm4n0YDJzhhWdlc0zIzs8pwTcvMzCrDScvMzCrDScvMzCrDScvMzCrDScvMzCrj/wAyMsm2zfE9JwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note that the number of optimization steps is measured in terms of the number of times the closure function is called in the LBFGS optimizer\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Todo\n",
        "# try to train a good model and then check if it makes a difference of attackability of input data\n",
        "# consider baseline feature set to the dlg model\n",
        "# see whether dlg is possible on model that is being updated"
      ],
      "metadata": {
        "id": "gLZEAjIwTnUb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}