{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgozon/DLG-UROP/blob/main/Batch_DLG_Iris_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch-DLG - Iris Dataset\n",
        "This notebook modifies the code in [Deep Leakage from Gradients](https://gist.github.com/Lyken17/91b81526a8245a028d4f85ccc9191884) to work with the Iris Dataset. In addition, it explores whether it is possible to repeat the same procedure on the batch input gradient."
      ],
      "metadata": {
        "id": "EFXvpWu88EO4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWa7Xo6PkIl3",
        "outputId": "cc27d516-bacc-42de-cdb6-0b196eec7a28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# setting up libraries and device\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad\n",
        "torch.manual_seed(100) # for generating the same random weights\n",
        "\n",
        "from random import randint\n",
        "from random import shuffle\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "dst = load_iris()\n",
        "\n",
        "print(torch.__version__)\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "print(\"Running on %s\" % device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n",
            "Running on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjKWqs2akepH"
      },
      "source": [
        "# auxiliary functions for NN - conver to onehot and loss function\n",
        "def label_to_onehot(target, num_classes = 3):\n",
        "    target = torch.unsqueeze(target, 1)\n",
        "    onehot_target = torch.zeros(target.size(0), num_classes, device=target.device)\n",
        "    onehot_target.scatter_(1, target, 1)\n",
        "    return onehot_target\n",
        "\n",
        "def cross_entropy_for_onehot(pred, target):\n",
        "    return torch.mean(torch.sum(- target * F.log_softmax(pred, dim=-1), 1))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AorI020iVjjS"
      },
      "source": [
        "# a random fully connected neural network with random weights and biases\n",
        "def weights_init(m):\n",
        "    if hasattr(m, \"weight\"):\n",
        "        m.weight.data.uniform_(-0.5, 0.5)\n",
        "    if hasattr(m, \"bias\"):\n",
        "        m.bias.data.uniform_(-0.5, 0.5)\n",
        "    \n",
        "class FcNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FcNet, self).__init__()\n",
        "        act = nn.Sigmoid\n",
        "        self.body = nn.Sequential(\n",
        "            nn.Linear(4, 100),\n",
        "            act(),\n",
        "            nn.Linear(100, 100),\n",
        "            act(),\n",
        "            nn.Linear(100, 100),\n",
        "            act(),\n",
        "            nn.Linear(100, 3),\n",
        "            act(),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.body(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        return out\n",
        "    \n",
        "net = FcNet().to(device)\n",
        "    \n",
        "net.apply(weights_init)\n",
        "criterion = cross_entropy_for_onehot"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mSgR4GClV-8"
      },
      "source": [
        "# DLG algorithm on a given set of flowers and returns the hypothesized input\n",
        "def Batch_DLG(flower_indices, verbose = 0):\n",
        "    n = len(flower_indices)\n",
        "\n",
        "    gt_dataset = []\n",
        "    gt_labels = []\n",
        "    for flower_index in flower_indices:\n",
        "        gt_data = torch.tensor(dst.data[flower_index, :]).to(device)\n",
        "        gt_data = gt_data.view(1, *gt_data.size())\n",
        "        gt_dataset.append(gt_data)\n",
        "        gt_label = torch.tensor(dst.target[flower_index]).to(device)\n",
        "        gt_label = gt_label.view(1)\n",
        "        gt_labels.append(gt_label)\n",
        "        gt_onehot_label = label_to_onehot(gt_label, num_classes=3)\n",
        "\n",
        "        # print out (data, label) and verify onehot\n",
        "        if (verbose == 2):\n",
        "            print(f\"gt_data: {gt_data}\")\n",
        "            print(f\"gt_label: {gt_label}\")\n",
        "            print(f\"gt_onehot_label: {gt_onehot_label}\")\n",
        "            print(f\"flower {flower_index} has label (gt, onehot) = ({gt_label.item()}, {torch.argmax(gt_onehot_label, dim=-1).item()})\")\n",
        "\n",
        "        # compute original gradient \n",
        "        out = net(gt_data.float())\n",
        "        y = criterion(out, gt_onehot_label)\n",
        "\n",
        "        if (flower_index == flower_indices[0]):\n",
        "          batch_dy_dx = torch.autograd.grad(y, net.parameters())\n",
        "        else:\n",
        "          batch_dy_dx = tuple(map(sum, zip(batch_dy_dx, torch.autograd.grad(y, net.parameters()))))\n",
        "\n",
        "    #print(batch_dy_dx)\n",
        "    batch_dy_dx = tuple(part/n for part in batch_dy_dx)\n",
        "    # share the gradients with other clients\n",
        "    original_dy_dx = list((_.detach().clone() for _ in batch_dy_dx))\n",
        "\n",
        "    # verifying dy_dx is average of list of flowers\n",
        "    if (verbose == 3):\n",
        "      print(original_dy_dx)\n",
        "\n",
        "    # generate dummy data and label\n",
        "    dummy_data = [torch.randn(gt_data.size()).to(device).requires_grad_(True) for i in range(n)]\n",
        "    dummy_label = [torch.randn(gt_onehot_label.size()).to(device).requires_grad_(True) for i in range(n)]\n",
        "\n",
        "    # if (verbose):\n",
        "    #     print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())\n",
        "\n",
        "    # torch documentation - all parameters must be on one device\n",
        "    optimizer = torch.optim.LBFGS(dummy_data+dummy_label)\n",
        "    # identify (data, label) using LBFGS on the squared difference between the original and guessed gradient\n",
        "    global opt_steps\n",
        "    opt_steps = 0\n",
        "    for iters in range(100):\n",
        "\n",
        "        def closure():\n",
        "            global opt_steps\n",
        "            opt_steps += 1\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # compute loss\n",
        "            for i in range(n):\n",
        "                pred = net(dummy_data[i]) \n",
        "                #print(f\"prediction: {pred} from data: {dummy_data.data} and label: {dummy_label}\") # uncomment to see optimization updates\n",
        "                dummy_onehot_label = F.softmax(dummy_label[i], dim=-1)\n",
        "                dummy_loss = criterion(pred, dummy_onehot_label) if (i == 0) else dummy_loss + criterion(pred, dummy_onehot_label)\n",
        "            \n",
        "            dummy_loss /= n\n",
        "\n",
        "            dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
        "            \n",
        "            grad_diff = 0\n",
        "            grad_count = 0\n",
        "            for gx, gy in zip(dummy_dy_dx, original_dy_dx):\n",
        "                grad_diff += ((gx - gy) ** 2).sum()\n",
        "                grad_count += gx.nelement()\n",
        "\n",
        "            grad_diff.backward()\n",
        "            \n",
        "            return grad_diff\n",
        "        \n",
        "        optimizer.step(closure)\n",
        "        current_loss = closure()\n",
        "        if (verbose == 2):\n",
        "            print(iters, \"%.4f\" % current_loss.item())\n",
        "            print('dummy data: ', dummy_data) #[dummy_data[i].tolist() for i in range(n)])\n",
        "            print('dummy labels: ', dummy_label) #[dummy_label[i].tolist() for i in range(n)])\n",
        "        \n",
        "        # if current_loss is small enough, then the model has 'converged'\n",
        "        if (current_loss < 1e-9):\n",
        "            break\n",
        "    \n",
        "    # compare results\n",
        "    if (verbose):\n",
        "        print(f\"Original data: {gt_dataset}\")\n",
        "        print(f\"Predicted data: {dummy_data}\")\n",
        "        print(f\"Original label: {gt_labels}\")\n",
        "        #print(f\"Predicted label: {torch.argmax(dummy_label).item()}\")\n",
        "        #print(f\"Label SE: {((gt_data - dummy_data)**2).sum()}\")\n",
        "    \n",
        "    return dummy_data, sum([torch.sum((gt_dataset[i] - dummy_data[i])**2).item() for i in range(n)]), opt_steps"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Batch_DLG([1, 2, 3, 4], 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPXhp3rpCAC8",
        "outputId": "d7736592-9e92-4cd1-cc8a-517a68af345c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data: [tensor([[4.9000, 3.0000, 1.4000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[4.7000, 3.2000, 1.3000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[4.6000, 3.1000, 1.5000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[5.0000, 3.6000, 1.4000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64)]\n",
            "Predicted data: [tensor([[4.7822, 3.3280, 1.4883, 0.1979]], device='cuda:0', requires_grad=True), tensor([[4.8446, 3.3618, 1.2867, 0.1608]], device='cuda:0', requires_grad=True), tensor([[4.7313, 2.8686, 1.4372, 0.2003]], device='cuda:0', requires_grad=True), tensor([[4.8426, 3.3387, 1.3860, 0.2410]], device='cuda:0', requires_grad=True)]\n",
            "Original label: [tensor([0], device='cuda:0'), tensor([0], device='cuda:0'), tensor([0], device='cuda:0'), tensor([0], device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([tensor([[4.7822, 3.3280, 1.4883, 0.1979]], device='cuda:0', requires_grad=True),\n",
              "  tensor([[4.8446, 3.3618, 1.2867, 0.1608]], device='cuda:0', requires_grad=True),\n",
              "  tensor([[4.7313, 2.8686, 1.4372, 0.2003]], device='cuda:0', requires_grad=True),\n",
              "  tensor([[4.8426, 3.3387, 1.3860, 0.2410]], device='cuda:0', requires_grad=True)],\n",
              " 0.3477381586873449,\n",
              " 232)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aokP-jhal96-",
        "outputId": "9423b596-aee2-459d-b5c2-380c027ea8f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# testing Batch-DLG on n random flowers\n",
        "length = dst.data.shape[0]\n",
        "perm = list(range(length))\n",
        "shuffle(perm)\n",
        "n = 5\n",
        "print('flowers: ', perm[0:n])\n",
        "\n",
        "guess, SE, steps = Batch_DLG(perm[0:n], verbose=1)\n",
        "print('guess: ', [guess[i].tolist() for i in range(n)])\n",
        "print('SE: ', SE)\n",
        "print('steps: ', steps)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flowers:  [105, 71, 122, 72, 142]\n",
            "Original data: [tensor([[7.6000, 3.0000, 6.6000, 2.1000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[6.1000, 2.8000, 4.0000, 1.3000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[7.7000, 2.8000, 6.7000, 2.0000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[6.3000, 2.5000, 4.9000, 1.5000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[5.8000, 2.7000, 5.1000, 1.9000]], device='cuda:0',\n",
            "       dtype=torch.float64)]\n",
            "Predicted data: [tensor([[6.1588, 2.8142, 4.0480, 1.3340]], device='cuda:0', requires_grad=True), tensor([[7.9202, 2.9347, 6.8994, 2.0789]], device='cuda:0', requires_grad=True), tensor([[6.2176, 2.4807, 4.8081, 1.4439]], device='cuda:0', requires_grad=True), tensor([[5.8837, 2.7400, 5.1919, 1.9511]], device='cuda:0', requires_grad=True), tensor([[7.3471, 2.8490, 6.3712, 1.9922]], device='cuda:0', requires_grad=True)]\n",
            "Original label: [tensor([2], device='cuda:0'), tensor([1], device='cuda:0'), tensor([2], device='cuda:0'), tensor([1], device='cuda:0'), tensor([2], device='cuda:0')]\n",
            "guess:  [[[6.158847332000732, 2.8142004013061523, 4.048013687133789, 1.3340020179748535]], [[7.92018985748291, 2.9347479343414307, 6.899439811706543, 2.0788979530334473]], [[6.217596530914307, 2.480658531188965, 4.80806827545166, 1.4439380168914795]], [[5.8836517333984375, 2.7399814128875732, 5.191910743713379, 1.9511035680770874]], [[7.347107410430908, 2.8490231037139893, 6.371194362640381, 1.9921563863754272]]]\n",
            "SE:  32.30344091826157\n",
            "steps:  253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Batch_DLG([71], 1)"
      ],
      "metadata": {
        "id": "QRMMm3Y5QNkq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d9250cd-dab2-4d69-fed8-882d45db1396"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data: [tensor([[6.1000, 2.8000, 4.0000, 1.3000]], device='cuda:0',\n",
            "       dtype=torch.float64)]\n",
            "Predicted data: [tensor([[6.0999, 2.8000, 3.9999, 1.3000]], device='cuda:0', requires_grad=True)]\n",
            "Original label: [tensor([1], device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([tensor([[6.0999, 2.8000, 3.9999, 1.3000]], device='cuda:0', requires_grad=True)],\n",
              " 1.53976907312483e-08,\n",
              " 14)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N0mxwiRzNXXG"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}