{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgozon/DLG-UROP/blob/main/DLG_Iris_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DLG - Iris Dataset\n",
        "This notebook modifies the code in [Deep Leakage from Gradients](https://gist.github.com/Lyken17/91b81526a8245a028d4f85ccc9191884) to work with the Iris Dataset."
      ],
      "metadata": {
        "id": "EFXvpWu88EO4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWa7Xo6PkIl3",
        "outputId": "d76bafa5-ccf3-4f8d-d043-bda6771ac5f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad\n",
        "import torchvision\n",
        "from torchvision import models, datasets, transforms\n",
        "torch.manual_seed(50)\n",
        "\n",
        "print(torch.__version__, torchvision.__version__)"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113 0.13.1+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjKWqs2akepH",
        "outputId": "4ad2516b-d5aa-44e5-8d34-5e05faabd424",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "dst = load_iris()\n",
        "\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "print(\"Running on %s\" % device)\n",
        "\n",
        "def label_to_onehot(target, num_classes = 3):\n",
        "    target = torch.unsqueeze(target, 1)\n",
        "    onehot_target = torch.zeros(target.size(0), num_classes, device=target.device)\n",
        "    onehot_target.scatter_(1, target, 1)\n",
        "    return onehot_target\n",
        "\n",
        "def cross_entropy_for_onehot(pred, target):\n",
        "    return torch.mean(torch.sum(- target * F.log_softmax(pred, dim=-1), 1))"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AorI020iVjjS"
      },
      "source": [
        "def weights_init(m):\n",
        "    if hasattr(m, \"weight\"):\n",
        "        m.weight.data.uniform_(-0.5, 0.5)\n",
        "    if hasattr(m, \"bias\"):\n",
        "        m.bias.data.uniform_(-0.5, 0.5)\n",
        "    \n",
        "# architecture of NN is a fully connected neural network\n",
        "# f(x) = \\sigma_L(A_L \\sigma (A_{L-1} (... (\\sigma (A_{1} x + b) + ...  )+b_{L-1})+b_L)\n",
        "class FcNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FcNet, self).__init__()\n",
        "        act = nn.Sigmoid\n",
        "        self.body = nn.Sequential(\n",
        "            nn.Linear(4, 100),\n",
        "            act(),\n",
        "            nn.Linear(100, 100),\n",
        "            act(),\n",
        "            nn.Linear(100, 100),\n",
        "            act(),\n",
        "            nn.Linear(100, 3),\n",
        "            act(),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.body(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        return out\n",
        "    \n",
        "net = FcNet().to(device)\n",
        "    \n",
        "net.apply(weights_init)\n",
        "criterion = cross_entropy_for_onehot"
      ],
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mSgR4GClV-8",
        "outputId": "16addc32-45e3-4428-ed6c-2613703c77cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "######### honest partipant #########\n",
        "from random import randint\n",
        "flower_index = randint(0, 149)\n",
        "\n",
        "gt_data = torch.tensor(dst.data[flower_index, :]).to(device)\n",
        "gt_data = gt_data.view(1, *gt_data.size())\n",
        "gt_label = torch.tensor(dst.target[flower_index]).to(device)\n",
        "gt_label = gt_label.view(1)\n",
        "gt_onehot_label = label_to_onehot(gt_label, num_classes=3)\n",
        "\n",
        "# print out (data, label) and verify onehot\n",
        "print(f\"gt_data: {gt_data}\")\n",
        "print(f\"gt_label: {gt_label}\")\n",
        "print(f\"gt_onehot_label: {gt_onehot_label}\")\n",
        "print(f\"flower {flower_index} has label (gt, onehot) = ({gt_label.item()}, {torch.argmax(gt_onehot_label, dim=-1).item()})\")\n",
        "\n",
        "# compute original gradient \n",
        "out = net(gt_data.float())\n",
        "y = criterion(out, gt_onehot_label)\n",
        "dy_dx = torch.autograd.grad(y, net.parameters())\n",
        "\n",
        "# share the gradients with other clients\n",
        "original_dy_dx = list((_.detach().clone() for _ in dy_dx))"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gt_data: tensor([[5.6000, 3.0000, 4.1000, 1.3000]], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "gt_label: tensor([1], device='cuda:0')\n",
            "gt_onehot_label: tensor([[0., 1., 0.]], device='cuda:0')\n",
            "flower 88 has label (gt, onehot) = (1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWIbBjVPVLeq",
        "outputId": "5678b748-d393-48ee-eecf-b8051af133b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# generate dummy data and label\n",
        "dummy_data = torch.randn(gt_data.size()).to(device).requires_grad_(True)\n",
        "dummy_label = torch.randn(gt_onehot_label.size()).to(device).requires_grad_(True)\n",
        "\n",
        "print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy label is 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZNuuwTFlYr0",
        "outputId": "445f4d87-0b88-4247-fcf2-4c87b3a4e36e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# identify (data, label) using gradient descent on the squared difference between the original and guessed gradient\n",
        "optimizer = torch.optim.LBFGS([dummy_data, dummy_label] )\n",
        "\n",
        "for iters in range(5):\n",
        "    def closure():\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        pred = net(dummy_data) \n",
        "        print(f\"prediction: {pred} from data: {dummy_data.data} and label: {dummy_label}\")\n",
        "        dummy_onehot_label = F.softmax(dummy_label, dim=-1)\n",
        "        dummy_loss = criterion(pred, dummy_onehot_label) # TODO: fix the gt_label to dummy_label in both code and slides.\n",
        "        dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
        "        \n",
        "        grad_diff = 0\n",
        "        grad_count = 0\n",
        "        for gx, gy in zip(dummy_dy_dx, original_dy_dx): # TODO: fix the variablas here\n",
        "            grad_diff += ((gx - gy) ** 2).sum()\n",
        "            grad_count += gx.nelement()\n",
        "        # grad_diff = grad_diff / grad_count * 1000\n",
        "        grad_diff.backward()\n",
        "        \n",
        "        return grad_diff\n",
        "    \n",
        "    optimizer.step(closure)\n",
        "    current_loss = closure()\n",
        "    print(iters, \"%.4f\" % current_loss.item())\n",
        "        "
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction: tensor([[0.3383, 0.7384, 0.3646]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[ 0.6411,  0.6207, -0.9301, -1.5124]], device='cuda:0') and label: tensor([[-2.1449, -1.0588, -0.9202]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3383, 0.7381, 0.3647]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[ 0.6451,  0.6096, -0.9308, -1.5087]], device='cuda:0') and label: tensor([[-2.1794, -0.5685, -1.3759]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3385, 0.7360, 0.3670]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[ 0.7057,  0.5408, -0.8855, -1.4733]], device='cuda:0') and label: tensor([[-2.4976,  0.3149, -1.9412]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3385, 0.7344, 0.3693]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[ 0.7745,  0.5056, -0.8203, -1.4341]], device='cuda:0') and label: tensor([[-2.5987,  0.5456, -2.0707]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3382, 0.7298, 0.3784]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[ 1.0290,  0.4354, -0.5535, -1.2859]], device='cuda:0') and label: tensor([[-2.7730,  0.9491, -2.2999]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3387, 0.7209, 0.4029]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[ 1.6100,  0.3845,  0.1130, -0.9214]], device='cuda:0') and label: tensor([[-2.9849,  1.4685, -2.6075]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3543, 0.7121, 0.4546]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[3.0811, 0.8198, 2.0318, 0.2712]], device='cuda:0') and label: tensor([[-3.3591,  2.4497, -3.2145]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3650, 0.7255, 0.4443]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[3.9060, 2.2182, 2.8103, 0.9034]], device='cuda:0') and label: tensor([[-3.6115,  3.0311, -3.5434]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3742, 0.7244, 0.4421]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[4.6968, 2.5607, 3.2371, 1.2315]], device='cuda:0') and label: tensor([[-3.7130,  3.3154, -3.7263]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3751, 0.7301, 0.4420]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.3311, 2.9774, 4.0252, 1.1051]], device='cuda:0') and label: tensor([[-3.8172,  3.6047, -3.9113]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3792, 0.7276, 0.4416]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.5727, 2.9929, 4.0702, 1.3069]], device='cuda:0') and label: tensor([[-3.8360,  3.6693, -3.9572]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3794, 0.7275, 0.4417]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.6008, 2.9950, 4.0967, 1.3128]], device='cuda:0') and label: tensor([[-3.8390,  3.6792, -3.9641]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3795, 0.7275, 0.4419]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.6086, 2.9930, 4.1081, 1.3117]], device='cuda:0') and label: tensor([[-3.8399,  3.6821, -3.9661]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3795, 0.7275, 0.4419]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.6082, 2.9920, 4.1082, 1.3109]], device='cuda:0') and label: tensor([[-3.8400,  3.6821, -3.9659]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3795, 0.7275, 0.4419]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.6077, 2.9914, 4.1078, 1.3105]], device='cuda:0') and label: tensor([[-3.8403,  3.6822, -3.9657]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3795, 0.7275, 0.4419]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.6073, 2.9909, 4.1075, 1.3102]], device='cuda:0') and label: tensor([[-3.8411,  3.6828, -3.9655]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3795, 0.7275, 0.4419]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.6063, 2.9898, 4.1066, 1.3094]], device='cuda:0') and label: tensor([[-3.8450,  3.6859, -3.9648]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3794, 0.7274, 0.4419]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.6049, 2.9883, 4.1054, 1.3082]], device='cuda:0') and label: tensor([[-3.8550,  3.6947, -3.9635]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3794, 0.7274, 0.4419]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.6026, 2.9863, 4.1034, 1.3062]], device='cuda:0') and label: tensor([[-3.8826,  3.7193, -3.9606]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3794, 0.7274, 0.4419]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.5996, 2.9842, 4.1008, 1.3035]], device='cuda:0') and label: tensor([[-3.9463,  3.7770, -3.9546]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3793, 0.7275, 0.4419]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.5967, 2.9839, 4.0985, 1.3007]], device='cuda:0') and label: tensor([[-4.0752,  3.8953, -3.9439]], device='cuda:0', requires_grad=True)\n",
            "0 0.0000\n",
            "prediction: tensor([[0.3793, 0.7275, 0.4419]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.5967, 2.9839, 4.0985, 1.3007]], device='cuda:0') and label: tensor([[-4.0752,  3.8953, -3.9439]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3793, 0.7275, 0.4418]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.5963, 2.9874, 4.0988, 1.2996]], device='cuda:0') and label: tensor([[-4.2926,  4.0966, -3.9278]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3793, 0.7276, 0.4417]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.6023, 2.9947, 4.0990, 1.2994]], device='cuda:0') and label: tensor([[-4.5641,  4.3493, -3.9090]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3793, 0.7276, 0.4417]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.5990, 2.9986, 4.1032, 1.3045]], device='cuda:0') and label: tensor([[-4.8121,  4.5800, -3.8917]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3793, 0.7276, 0.4417]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.6016, 2.9993, 4.1031, 1.3037]], device='cuda:0') and label: tensor([[-4.8977,  4.6595, -3.8856]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3793, 0.7277, 0.4417]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.6031, 2.9998, 4.1024, 1.3025]], device='cuda:0') and label: tensor([[-5.0837,  4.8316, -3.8718]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3793, 0.7277, 0.4417]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.6026, 2.9996, 4.1015, 1.3014]], device='cuda:0') and label: tensor([[-5.3375,  5.0663, -3.8526]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3793, 0.7277, 0.4417]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.6009, 2.9991, 4.1007, 1.3007]], device='cuda:0') and label: tensor([[-5.6703,  5.3741, -3.8275]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3793, 0.7277, 0.4417]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.5998, 2.9990, 4.1004, 1.3005]], device='cuda:0') and label: tensor([[-5.9865,  5.6666, -3.8039]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3793, 0.7277, 0.4417]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.5995, 2.9992, 4.1003, 1.3004]], device='cuda:0') and label: tensor([[-6.3062,  5.9626, -3.7802]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3793, 0.7277, 0.4417]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.5997, 2.9995, 4.1003, 1.3003]], device='cuda:0') and label: tensor([[-6.6749,  6.3041, -3.7529]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3793, 0.7277, 0.4417]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.5998, 2.9996, 4.0999, 1.3003]], device='cuda:0') and label: tensor([[-7.0659,  6.6661, -3.7239]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3793, 0.7277, 0.4417]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.6001, 2.9998, 4.1001, 1.3002]], device='cuda:0') and label: tensor([[-7.4323,  7.0055, -3.6968]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3793, 0.7277, 0.4417]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.6001, 2.9999, 4.1001, 1.3001]], device='cuda:0') and label: tensor([[-7.8154,  7.3602, -3.6684]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3793, 0.7277, 0.4417]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.6001, 2.9999, 4.1001, 1.3001]], device='cuda:0') and label: tensor([[-7.8154,  7.3602, -3.6684]], device='cuda:0', requires_grad=True)\n",
            "1 0.0000\n",
            "prediction: tensor([[0.3793, 0.7277, 0.4417]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.6001, 2.9999, 4.1001, 1.3001]], device='cuda:0') and label: tensor([[-7.8154,  7.3602, -3.6684]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3793, 0.7277, 0.4417]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.6001, 2.9999, 4.1001, 1.3001]], device='cuda:0') and label: tensor([[-7.8154,  7.3602, -3.6684]], device='cuda:0', requires_grad=True)\n",
            "2 0.0000\n",
            "prediction: tensor([[0.3793, 0.7277, 0.4417]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.6001, 2.9999, 4.1001, 1.3001]], device='cuda:0') and label: tensor([[-7.8154,  7.3602, -3.6684]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3793, 0.7277, 0.4417]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.6001, 2.9999, 4.1001, 1.3001]], device='cuda:0') and label: tensor([[-7.8154,  7.3602, -3.6684]], device='cuda:0', requires_grad=True)\n",
            "3 0.0000\n",
            "prediction: tensor([[0.3793, 0.7277, 0.4417]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.6001, 2.9999, 4.1001, 1.3001]], device='cuda:0') and label: tensor([[-7.8154,  7.3602, -3.6684]], device='cuda:0', requires_grad=True)\n",
            "prediction: tensor([[0.3793, 0.7277, 0.4417]], device='cuda:0', grad_fn=<ViewBackward0>) from data: tensor([[5.6001, 2.9999, 4.1001, 1.3001]], device='cuda:0') and label: tensor([[-7.8154,  7.3602, -3.6684]], device='cuda:0', requires_grad=True)\n",
            "4 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aokP-jhal96-",
        "outputId": "c6de39a9-f1d9-4ca4-c9f2-99f3c3b5bf57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# compare results\n",
        "print(f\"Original data: {gt_data}\")\n",
        "print(f\"Predicted data: {dummy_data}\")\n",
        "print(f\"Original label: {gt_label.item()}\")\n",
        "print(f\"Predicted label: {torch.argmax(dummy_label).item()}\")\n",
        "print(f\"Label SE: {((gt_data - dummy_data)**2).sum()}\");"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data: tensor([[5.6000, 3.0000, 4.1000, 1.3000]], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "Predicted data: tensor([[5.6001, 2.9999, 4.1001, 1.3001]], device='cuda:0', requires_grad=True)\n",
            "Original label: 1\n",
            "Predicted label: 1\n",
            "Label SE: 5.050050106105812e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xPUFlCRMMGQB"
      },
      "execution_count": 249,
      "outputs": []
    }
  ]
}